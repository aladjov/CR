{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0184150c",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [2]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170e9855",
   "metadata": {
    "papermill": {
     "duration": 0.00403,
     "end_time": "2026-01-22T14:18:06.180591",
     "exception": false,
     "start_time": "2026-01-22T14:18:06.176561",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Chapter 4: Relationship Analysis\n",
    "\n",
    "**Purpose:** Explore feature correlations, relationships with the target, and identify predictive signals.\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to interpret correlation matrices and identify multicollinearity\n",
    "- How to visualize feature distributions by target class\n",
    "- How to identify which features have the strongest relationship with retention\n",
    "- How to analyze categorical features for predictive power\n",
    "\n",
    "**Outputs:**\n",
    "- Correlation heatmap with multicollinearity detection\n",
    "- Feature distributions by retention status (box plots)\n",
    "- Retention rates by categorical features\n",
    "- Feature-target correlation rankings\n",
    "\n",
    "---\n",
    "\n",
    "## Understanding Feature Relationships\n",
    "\n",
    "| Analysis | What It Tells You | Action |\n",
    "|----------|------------------|--------|\n",
    "| **High Correlation** (r > 0.7) | Features carry redundant information | Consider removing one |\n",
    "| **Target Correlation** | Feature's predictive power | Prioritize high-correlation features |\n",
    "| **Class Separation** | How different retained vs churned look | Good separation = good predictor |\n",
    "| **Categorical Rates** | Retention varies by category | Use for segmentation and encoding |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb27767",
   "metadata": {
    "papermill": {
     "duration": 0.002621,
     "end_time": "2026-01-22T14:18:06.186225",
     "exception": false,
     "start_time": "2026-01-22T14:18:06.183604",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.1 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "009f24b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T14:18:06.192884Z",
     "iopub.status.busy": "2026-01-22T14:18:06.192757Z",
     "iopub.status.idle": "2026-01-22T14:18:07.636754Z",
     "shell.execute_reply": "2026-01-22T14:18:07.636374Z"
    },
    "papermill": {
     "duration": 1.448764,
     "end_time": "2026-01-22T14:18:07.637622",
     "exception": false,
     "start_time": "2026-01-22T14:18:06.188858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from customer_retention.analysis.auto_explorer import ExplorationFindings, RecommendationRegistry\n",
    "from customer_retention.analysis.visualization import ChartBuilder, display_figure, display_table\n",
    "from customer_retention.core.config.column_config import ColumnType\n",
    "from customer_retention.stages.profiling import (\n",
    "    RelationshipRecommender, RecommendationCategory\n",
    ")\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df223234",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b213d3b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T14:18:07.644441Z",
     "iopub.status.busy": "2026-01-22T14:18:07.644245Z",
     "iopub.status.idle": "2026-01-22T14:18:07.778615Z",
     "shell.execute_reply": "2026-01-22T14:18:07.778230Z"
    },
    "papermill": {
     "duration": 0.139302,
     "end_time": "2026-01-22T14:18:07.779463",
     "exception": true,
     "start_time": "2026-01-22T14:18:07.640161",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No findings files found in ../experiments/findings. Run notebook 01 first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m findings_files = [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m FINDINGS_DIR.glob(\u001b[33m\"\u001b[39m\u001b[33m*_findings.yaml\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmulti_dataset\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m f.name]\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m findings_files:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo findings files found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFINDINGS_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Run notebook 01 first.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m findings_files.sort(key=\u001b[38;5;28;01mlambda\u001b[39;00m f: f.stat().st_mtime, reverse=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     15\u001b[39m FINDINGS_PATH = \u001b[38;5;28mstr\u001b[39m(findings_files[\u001b[32m0\u001b[39m])\n",
      "\u001b[31mFileNotFoundError\u001b[39m: No findings files found in ../experiments/findings. Run notebook 01 first."
     ]
    }
   ],
   "source": [
    "# === CONFIGURATION ===\n",
    "# Option 1: Set the exact path from notebook 01 output\n",
    "# FINDINGS_PATH = \"../experiments/findings/customer_retention_retail_abc123_findings.yaml\"\n",
    "\n",
    "# Option 2: Auto-discover the most recent findings file\n",
    "from pathlib import Path\n",
    "\n",
    "FINDINGS_DIR = Path(\"../experiments/findings\")\n",
    "\n",
    "findings_files = [f for f in FINDINGS_DIR.glob(\"*_findings.yaml\") if \"multi_dataset\" not in f.name]\n",
    "if not findings_files:\n",
    "    raise FileNotFoundError(f\"No findings files found in {FINDINGS_DIR}. Run notebook 01 first.\")\n",
    "\n",
    "findings_files.sort(key=lambda f: f.stat().st_mtime, reverse=True)\n",
    "FINDINGS_PATH = str(findings_files[0])\n",
    "RECOMMENDATIONS_PATH = FINDINGS_PATH.replace(\"_findings.yaml\", \"_recommendations.yaml\")\n",
    "\n",
    "print(f\"Found {len(findings_files)} findings file(s)\")\n",
    "print(f\"Using: {FINDINGS_PATH}\")\n",
    "\n",
    "findings = ExplorationFindings.load(FINDINGS_PATH)\n",
    "\n",
    "# Load data with snapshot preference (uses temporal snapshots if available)\n",
    "from customer_retention.stages.temporal import load_data_with_snapshot_preference, TEMPORAL_METADATA_COLS\n",
    "df, data_source = load_data_with_snapshot_preference(findings, output_dir=\"../experiments/findings\")\n",
    "charts = ChartBuilder()\n",
    "\n",
    "if Path(RECOMMENDATIONS_PATH).exists():\n",
    "    with open(RECOMMENDATIONS_PATH, \"r\") as f:\n",
    "        registry = RecommendationRegistry.from_dict(yaml.safe_load(f))\n",
    "    print(f\"Loaded existing recommendations: {len(registry.all_recommendations)} total\")\n",
    "else:\n",
    "    registry = RecommendationRegistry()\n",
    "    registry.init_bronze(findings.source_path)\n",
    "    registry.init_silver(findings.entity_column or \"entity_id\")\n",
    "    registry.init_gold(findings.target_column or \"target\")\n",
    "    print(\"Initialized new recommendation registry\")\n",
    "\n",
    "print(f\"\\nLoaded {len(df):,} rows from: {data_source}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc9082c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4.2 Numeric Correlation Matrix\n",
    "\n",
    "**üìñ How to Read the Heatmap:**\n",
    "- **Red (+1)**: Perfect positive correlation - features move together\n",
    "- **Blue (-1)**: Perfect negative correlation - features move opposite\n",
    "- **White (0)**: No linear relationship\n",
    "\n",
    "**‚ö†Ô∏è Multicollinearity Warning:**\n",
    "- Pairs with |r| > 0.7 may cause issues in linear models\n",
    "- Consider removing one feature from highly correlated pairs\n",
    "- Tree-based models are more robust to multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9ce3e0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    name for name, col in findings.columns.items()\n",
    "    if col.inferred_type in [ColumnType.NUMERIC_CONTINUOUS, ColumnType.NUMERIC_DISCRETE, ColumnType.TARGET]\n",
    "    and name not in TEMPORAL_METADATA_COLS\n",
    "]\n",
    "\n",
    "if len(numeric_cols) >= 2:\n",
    "    corr_matrix = df[numeric_cols].corr()\n",
    "    fig = charts.heatmap(\n",
    "        corr_matrix.values,\n",
    "        x_labels=numeric_cols,\n",
    "        y_labels=numeric_cols,\n",
    "        title=\"Numeric Correlation Matrix\"\n",
    "    )\n",
    "    display_figure(fig)\n",
    "else:\n",
    "    print(\"Not enough numeric columns for correlation analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59d4c1b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4.3 High Correlation Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5838bf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "high_corr_threshold = 0.7\n",
    "high_corr_pairs = []\n",
    "\n",
    "if len(numeric_cols) >= 2:\n",
    "    corr_matrix = df[numeric_cols].corr()\n",
    "    for i in range(len(numeric_cols)):\n",
    "        for j in range(i+1, len(numeric_cols)):\n",
    "            corr_val = corr_matrix.iloc[i, j]\n",
    "            if abs(corr_val) >= high_corr_threshold:\n",
    "                high_corr_pairs.append({\n",
    "                    \"Column 1\": numeric_cols[i],\n",
    "                    \"Column 2\": numeric_cols[j],\n",
    "                    \"Correlation\": f\"{corr_val:.3f}\"\n",
    "                })\n",
    "\n",
    "if high_corr_pairs:\n",
    "    print(f\"High Correlation Pairs (|r| >= {high_corr_threshold}):\")\n",
    "    display(pd.DataFrame(high_corr_pairs))\n",
    "    print(\"\\nConsider removing one of each pair to reduce multicollinearity.\")\n",
    "else:\n",
    "    print(\"No high correlation pairs detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0232696",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4.4 Feature Distributions by Retention Status\n",
    "\n",
    "**üìñ How to Interpret Box Plots:**\n",
    "- **Box** = Middle 50% of data (IQR)\n",
    "- **Line inside box** = Median\n",
    "- **Whiskers** = 1.5 √ó IQR from box edges\n",
    "- **Points outside** = Outliers\n",
    "\n",
    "**‚ö†Ô∏è What Makes a Good Predictor:**\n",
    "- **Clear separation** between retained (green) and churned (red) boxes\n",
    "- **Different medians** = Feature values differ between classes\n",
    "- **Minimal overlap** = Easier to distinguish classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e574aa5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature Distributions by Retention Status\n",
    "if findings.target_column and findings.target_column in df.columns:\n",
    "    target = findings.target_column\n",
    "    \n",
    "    feature_cols = [\n",
    "        name for name, col in findings.columns.items()\n",
    "        if col.inferred_type in [ColumnType.NUMERIC_CONTINUOUS, ColumnType.NUMERIC_DISCRETE]\n",
    "        and name != target\n",
    "        and name not in TEMPORAL_METADATA_COLS\n",
    "    ]\n",
    "    \n",
    "    if feature_cols:\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"FEATURE DISTRIBUTIONS BY TARGET: {target}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Calculate summary statistics by target\n",
    "        summary_by_target = []\n",
    "        for col in feature_cols:\n",
    "            for target_val, label in [(0, \"Churned\"), (1, \"Retained\")]:\n",
    "                subset = df[df[target] == target_val][col].dropna()\n",
    "                if len(subset) > 0:\n",
    "                    summary_by_target.append({\n",
    "                        \"Feature\": col,\n",
    "                        \"Group\": label,\n",
    "                        \"Count\": len(subset),\n",
    "                        \"Mean\": subset.mean(),\n",
    "                        \"Median\": subset.median(),\n",
    "                        \"Std\": subset.std()\n",
    "                    })\n",
    "        \n",
    "        if summary_by_target:\n",
    "            summary_df = pd.DataFrame(summary_by_target)\n",
    "            \n",
    "            # Display summary table\n",
    "            print(\"\\nüìä Summary Statistics by Retention Status:\")\n",
    "            display_summary = summary_df.pivot(index=\"Feature\", columns=\"Group\", values=[\"Mean\", \"Median\"])\n",
    "            display_summary.columns = [f\"{stat} ({group})\" for stat, group in display_summary.columns]\n",
    "            display(display_summary.round(3))\n",
    "        \n",
    "        # Calculate effect size (Cohen's d) for each feature\n",
    "        print(\"\\nüìà Feature Importance Indicators (Effect Size - Cohen's d):\")\n",
    "        print(\"-\" * 70)\n",
    "        effect_sizes = []\n",
    "        for col in feature_cols:\n",
    "            churned = df[df[target] == 0][col].dropna()\n",
    "            retained = df[df[target] == 1][col].dropna()\n",
    "            \n",
    "            if len(churned) > 0 and len(retained) > 0:\n",
    "                # Cohen's d\n",
    "                pooled_std = np.sqrt(((len(churned)-1)*churned.std()**2 + (len(retained)-1)*retained.std()**2) / \n",
    "                                     (len(churned) + len(retained) - 2))\n",
    "                if pooled_std > 0:\n",
    "                    d = (retained.mean() - churned.mean()) / pooled_std\n",
    "                else:\n",
    "                    d = 0\n",
    "                \n",
    "                # Interpret effect size\n",
    "                abs_d = abs(d)\n",
    "                if abs_d >= 0.8:\n",
    "                    interpretation = \"Large effect\"\n",
    "                    emoji = \"üî¥\"\n",
    "                elif abs_d >= 0.5:\n",
    "                    interpretation = \"Medium effect\"\n",
    "                    emoji = \"üü°\"\n",
    "                elif abs_d >= 0.2:\n",
    "                    interpretation = \"Small effect\"\n",
    "                    emoji = \"üü¢\"\n",
    "                else:\n",
    "                    interpretation = \"Negligible\"\n",
    "                    emoji = \"‚ö™\"\n",
    "                \n",
    "                effect_sizes.append({\n",
    "                    \"feature\": col,\n",
    "                    \"cohens_d\": d,\n",
    "                    \"abs_d\": abs_d,\n",
    "                    \"interpretation\": interpretation\n",
    "                })\n",
    "                \n",
    "                direction = \"‚Üë Higher in retained\" if d > 0 else \"‚Üì Lower in retained\"\n",
    "                print(f\"  {emoji} {col}: d={d:+.3f} ({interpretation}) {direction}\")\n",
    "        \n",
    "        # Sort by effect size for identifying important features\n",
    "        if effect_sizes:\n",
    "            effect_df = pd.DataFrame(effect_sizes).sort_values(\"abs_d\", ascending=False)\n",
    "            important_features = effect_df[effect_df[\"abs_d\"] >= 0.2][\"feature\"].tolist()\n",
    "            if important_features:\n",
    "                print(f\"\\n‚≠ê Features with notable effect (|d| ‚â• 0.2): {', '.join(important_features)}\")\n",
    "        else:\n",
    "            print(\"  No effect sizes could be calculated (insufficient data in one or both groups)\")\n",
    "    else:\n",
    "        print(\"No numeric feature columns found for distribution analysis.\")\n",
    "else:\n",
    "    print(\"Target column not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69905058",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Interpreting Effect Sizes (Cohen's d)\n",
    "\n",
    "| Effect Size | Interpretation | What It Means for Modeling |\n",
    "|-------------|----------------|---------------------------|\n",
    "| \\|d\\| ‚â• 0.8 | Large | Strong discriminator - prioritize this feature |\n",
    "| \\|d\\| = 0.5-0.8 | Medium | Useful predictor - include in model |\n",
    "| \\|d\\| = 0.2-0.5 | Small | Weak but may help in combination with others |\n",
    "| \\|d\\| < 0.2 | Negligible | Limited predictive value alone |\n",
    "\n",
    "**üéØ Actionable Insights:**\n",
    "- **Features with large effects** are your best predictors - ensure they're included in your model\n",
    "- **Direction matters**: \"Higher in retained\" means customers with high values tend to stay; use this for threshold-based business rules\n",
    "- **Features with small/negligible effects** may still be useful in combination or as interaction terms\n",
    "\n",
    "**‚ö†Ô∏è Cautions:**\n",
    "- Effect size assumes roughly normal distributions - check skewness in notebook 03\n",
    "- Large effects could be due to confounding variables - validate with domain knowledge\n",
    "- Correlation ‚â† causation: high engagement may not *cause* retention\n",
    "\n",
    "### Box Plot Visualization\n",
    "\n",
    "**üìà How to Read the Box Plots Below:**\n",
    "- **Well-separated boxes** (little/no overlap) ‚Üí Feature clearly distinguishes retained vs churned\n",
    "- **Different medians** (center lines at different heights) ‚Üí Groups have different typical values\n",
    "- **Many outliers in one group** ‚Üí May indicate subpopulations worth investigating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8e4b96",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Box Plots: Visual comparison of distributions\n",
    "if findings.target_column and findings.target_column in df.columns:\n",
    "    target = findings.target_column\n",
    "    \n",
    "    feature_cols = [\n",
    "        name for name, col in findings.columns.items()\n",
    "        if col.inferred_type in [ColumnType.NUMERIC_CONTINUOUS, ColumnType.NUMERIC_DISCRETE]\n",
    "        and name != target\n",
    "        and name not in TEMPORAL_METADATA_COLS\n",
    "    ]\n",
    "    \n",
    "    if feature_cols:\n",
    "        # Create box plots - one subplot per feature for better control\n",
    "        n_features = min(len(feature_cols), 6)\n",
    "        \n",
    "        fig = make_subplots(\n",
    "            rows=1, cols=n_features,\n",
    "            subplot_titles=feature_cols[:n_features],\n",
    "            horizontal_spacing=0.05\n",
    "        )\n",
    "        \n",
    "        for i, col in enumerate(feature_cols[:n_features]):\n",
    "            col_num = i + 1\n",
    "            \n",
    "            # Retained (1) - Green\n",
    "            retained_data = df[df[target] == 1][col].dropna()\n",
    "            fig.add_trace(\n",
    "                go.Box(\n",
    "                    y=retained_data,\n",
    "                    name='Retained',\n",
    "                    fillcolor='rgba(46, 204, 113, 0.7)',\n",
    "                    line=dict(color='#1e8449', width=2),\n",
    "                    marker=dict(\n",
    "                        color='rgba(46, 204, 113, 0.5)',  # Light green outliers\n",
    "                        size=5,\n",
    "                        line=dict(color='#1e8449', width=1)\n",
    "                    ),\n",
    "                    boxpoints='outliers',\n",
    "                    width=0.35,\n",
    "                    showlegend=(i == 0),\n",
    "                    legendgroup='retained',\n",
    "                    offsetgroup='retained'\n",
    "                ),\n",
    "                row=1, col=col_num\n",
    "            )\n",
    "            \n",
    "            # Churned (0) - Red\n",
    "            churned_data = df[df[target] == 0][col].dropna()\n",
    "            fig.add_trace(\n",
    "                go.Box(\n",
    "                    y=churned_data,\n",
    "                    name='Churned',\n",
    "                    fillcolor='rgba(231, 76, 60, 0.7)',\n",
    "                    line=dict(color='#922b21', width=2),\n",
    "                    marker=dict(\n",
    "                        color='rgba(231, 76, 60, 0.5)',  # Light red outliers\n",
    "                        size=5,\n",
    "                        line=dict(color='#922b21', width=1)\n",
    "                    ),\n",
    "                    boxpoints='outliers',\n",
    "                    width=0.35,\n",
    "                    showlegend=(i == 0),\n",
    "                    legendgroup='churned',\n",
    "                    offsetgroup='churned'\n",
    "                ),\n",
    "                row=1, col=col_num\n",
    "            )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            height=450,\n",
    "            title_text=\"Feature Distributions: Retained (Green) vs Churned (Red)\",\n",
    "            template='plotly_white',\n",
    "            showlegend=True,\n",
    "            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.05, xanchor=\"center\", x=0.5),\n",
    "            boxmode='group',\n",
    "            boxgap=0.3,\n",
    "            boxgroupgap=0.1\n",
    "        )\n",
    "        \n",
    "        # Center the boxes by removing x-axis tick labels (title is above each subplot)\n",
    "        fig.update_xaxes(showticklabels=False)\n",
    "        \n",
    "        display_figure(fig)\n",
    "        \n",
    "        # Print mean comparison\n",
    "        print(\"\\nüìä MEAN COMPARISON BY RETENTION STATUS:\")\n",
    "        print(\"-\" * 70)\n",
    "        for col in feature_cols[:n_features]:\n",
    "            retained_mean = df[df[target] == 1][col].mean()\n",
    "            churned_mean = df[df[target] == 0][col].mean()\n",
    "            diff_pct = ((retained_mean - churned_mean) / churned_mean * 100) if churned_mean != 0 else 0\n",
    "            print(f\"  {col}:\")\n",
    "            print(f\"     Retained: {retained_mean:.2f}  |  Churned: {churned_mean:.2f}  |  Diff: {diff_pct:+.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5da053",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4.5 Feature-Target Correlations\n",
    "\n",
    "Features ranked by absolute correlation with the target variable.\n",
    "\n",
    "**üìñ Interpretation:**\n",
    "- **Positive correlation**: Higher values = more likely retained\n",
    "- **Negative correlation**: Higher values = more likely churned\n",
    "- **|r| > 0.3**: Moderately predictive\n",
    "- **|r| > 0.5**: Strongly predictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8320ac4a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if findings.target_column and findings.target_column in df.columns:\n",
    "    target = findings.target_column\n",
    "    feature_cols = [\n",
    "        name for name, col in findings.columns.items()\n",
    "        if col.inferred_type in [ColumnType.NUMERIC_CONTINUOUS, ColumnType.NUMERIC_DISCRETE]\n",
    "        and name != target\n",
    "        and name not in TEMPORAL_METADATA_COLS\n",
    "    ]\n",
    "    \n",
    "    if feature_cols:\n",
    "        correlations = []\n",
    "        for col in feature_cols:\n",
    "            corr = df[[col, target]].corr().iloc[0, 1]\n",
    "            correlations.append({\"Feature\": col, \"Correlation\": corr})\n",
    "        \n",
    "        corr_df = pd.DataFrame(correlations).sort_values(\"Correlation\", key=abs, ascending=False)\n",
    "        \n",
    "        fig = charts.bar_chart(\n",
    "            corr_df[\"Feature\"].tolist(),\n",
    "            corr_df[\"Correlation\"].tolist(),\n",
    "            title=f\"Feature Correlations with {target}\"\n",
    "        )\n",
    "        display_figure(fig)\n",
    "else:\n",
    "    print(\"Target column not available for correlation analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee16181f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4.6 Categorical Feature Analysis\n",
    "\n",
    "Retention rates by category help identify which segments are at higher risk.\n",
    "\n",
    "**üìñ What to Look For:**\n",
    "- Categories with **low retention rates** = high-risk segments for intervention\n",
    "- **Large variation** across categories = strong predictive feature\n",
    "- **Small categories** with extreme rates may be unreliable (small sample size)\n",
    "\n",
    "**üìä Metrics Explained:**\n",
    "- **Retention Rate**: % of customers in category who were retained\n",
    "- **Lift**: How much better/worse than overall retention rate (>1 = better, <1 = worse)\n",
    "- **Cram√©r's V**: Strength of association (0-1 scale, like correlation for categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964e86c6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from customer_retention.stages.profiling import CategoricalTargetAnalyzer\n",
    "\n",
    "if findings.target_column:\n",
    "    target = findings.target_column\n",
    "    overall_retention = df[target].mean()\n",
    "    \n",
    "    categorical_cols = [\n",
    "        name for name, col in findings.columns.items()\n",
    "        if col.inferred_type in [ColumnType.CATEGORICAL_NOMINAL, ColumnType.CATEGORICAL_ORDINAL]\n",
    "        and name not in TEMPORAL_METADATA_COLS\n",
    "    ]\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"CATEGORICAL FEATURE ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Overall retention rate: {overall_retention:.1%}\")\n",
    "    \n",
    "    if categorical_cols:\n",
    "        # Use framework analyzer for summary\n",
    "        cat_analyzer = CategoricalTargetAnalyzer(min_samples_per_category=10)\n",
    "        summary_df = cat_analyzer.analyze_multiple(df, categorical_cols, target)\n",
    "        \n",
    "        print(\"\\nüìà Categorical Feature Strength (Cram√©r's V):\")\n",
    "        print(\"-\" * 60)\n",
    "        for _, row in summary_df.iterrows():\n",
    "            if row[\"cramers_v\"] >= 0.3:\n",
    "                strength = \"Strong\"\n",
    "                emoji = \"üî¥\"\n",
    "            elif row[\"cramers_v\"] >= 0.1:\n",
    "                strength = \"Moderate\"\n",
    "                emoji = \"üü°\"\n",
    "            else:\n",
    "                strength = \"Weak\"\n",
    "                emoji = \"üü¢\"\n",
    "            sig = \"***\" if row[\"p_value\"] < 0.001 else \"**\" if row[\"p_value\"] < 0.01 else \"*\" if row[\"p_value\"] < 0.05 else \"\"\n",
    "            print(f\"  {emoji} {row['feature']}: V={row['cramers_v']:.3f} ({strength}) {sig}\")\n",
    "        \n",
    "        # Detailed analysis for each categorical feature\n",
    "        for col_name in categorical_cols[:5]:\n",
    "            result = cat_analyzer.analyze(df, col_name, target)\n",
    "            \n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"üìä {col_name.upper()}\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            # Display stats table\n",
    "            if len(result.category_stats) > 0:\n",
    "                display_stats = result.category_stats[['category', 'total_count', 'retention_rate', 'lift', 'pct_of_total']].copy()\n",
    "                display_stats['retention_rate'] = display_stats['retention_rate'].apply(lambda x: f\"{x:.1%}\")\n",
    "                display_stats['lift'] = display_stats['lift'].apply(lambda x: f\"{x:.2f}x\")\n",
    "                display_stats['pct_of_total'] = display_stats['pct_of_total'].apply(lambda x: f\"{x:.1%}\")\n",
    "                display_stats.columns = [col_name, 'Count', 'Retention Rate', 'Lift', '% of Data']\n",
    "                display(display_stats)\n",
    "                \n",
    "                # Stacked bar chart\n",
    "                cat_stats = result.category_stats\n",
    "                categories = cat_stats['category'].tolist()\n",
    "                retained_counts = cat_stats['retained_count'].tolist()\n",
    "                churned_counts = cat_stats['churned_count'].tolist()\n",
    "                \n",
    "                fig = go.Figure()\n",
    "                \n",
    "                fig.add_trace(go.Bar(\n",
    "                    name='Retained',\n",
    "                    x=categories,\n",
    "                    y=retained_counts,\n",
    "                    marker_color='rgba(46, 204, 113, 0.8)',\n",
    "                    text=[f\"{r/(r+c)*100:.0f}%\" for r, c in zip(retained_counts, churned_counts)],\n",
    "                    textposition='inside',\n",
    "                    textfont=dict(color='white', size=12)\n",
    "                ))\n",
    "                \n",
    "                fig.add_trace(go.Bar(\n",
    "                    name='Churned',\n",
    "                    x=categories,\n",
    "                    y=churned_counts,\n",
    "                    marker_color='rgba(231, 76, 60, 0.8)',\n",
    "                    text=[f\"{c/(r+c)*100:.0f}%\" for r, c in zip(retained_counts, churned_counts)],\n",
    "                    textposition='inside',\n",
    "                    textfont=dict(color='white', size=12)\n",
    "                ))\n",
    "                \n",
    "                fig.update_layout(\n",
    "                    barmode='stack',\n",
    "                    title=f\"Retention by {col_name}\",\n",
    "                    xaxis_title=col_name,\n",
    "                    yaxis_title=\"Count\",\n",
    "                    template='plotly_white',\n",
    "                    height=350,\n",
    "                    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"center\", x=0.5)\n",
    "                )\n",
    "                display_figure(fig)\n",
    "                \n",
    "                # Flag high-risk categories from framework result\n",
    "                if result.high_risk_categories:\n",
    "                    print(f\"\\n  ‚ö†Ô∏è High-risk categories (lift < 0.9x):\")\n",
    "                    for cat in result.high_risk_categories:\n",
    "                        cat_row = cat_stats[cat_stats['category'] == cat].iloc[0]\n",
    "                        print(f\"     ‚Ä¢ {cat}: {cat_row['retention_rate']:.1%} retention ({cat_row['lift']:.2f}x lift)\")\n",
    "    else:\n",
    "        print(\"\\n  ‚ÑπÔ∏è No categorical columns detected.\")\n",
    "else:\n",
    "    print(\"No target column available for categorical analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a71257",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4.7 Scatter Plot Matrix (Sample)\n",
    "\n",
    "Visual exploration of pairwise relationships between numeric features.\n",
    "\n",
    "**üìñ How to Read the Scatter Matrix:**\n",
    "- **Diagonal**: Distribution of each feature (histogram or density)\n",
    "- **Off-diagonal**: Scatter plot showing relationship between two features\n",
    "- Each row/column represents one feature\n",
    "\n",
    "**üîç What to Look For:**\n",
    "\n",
    "| Pattern | What It Means | Action |\n",
    "|---------|--------------|--------|\n",
    "| **Linear trend** (diagonal line of points) | Strong correlation | Check if redundant; may cause multicollinearity |\n",
    "| **Curved pattern** | Non-linear relationship | Consider polynomial features or transformations |\n",
    "| **Clusters/groups** | Natural segments in data | May benefit from segment-aware modeling |\n",
    "| **Fan shape** (spreading out) | Heteroscedasticity | May need log transform or robust methods |\n",
    "| **Random scatter** | No relationship | Features are independent |\n",
    "\n",
    "**‚ö†Ô∏è Cautions:**\n",
    "- Sample shown (max 1000 points) for performance - patterns may differ in full data\n",
    "- Look for the same patterns in correlation matrix (section 4.2) to confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12c56b8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_numeric = numeric_cols[:4] if len(numeric_cols) > 4 else numeric_cols\n",
    "\n",
    "if len(top_numeric) >= 2:\n",
    "    fig = charts.scatter_matrix(\n",
    "        df[top_numeric].sample(min(1000, len(df))),\n",
    "        title=\"Scatter Plot Matrix (Sample)\"\n",
    "    )\n",
    "    display_figure(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58431b2a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Interpreting the Scatter Matrix Above\n",
    "\n",
    "**üéØ Key Questions to Answer:**\n",
    "\n",
    "1. **Are any features redundant?**\n",
    "   - Look for tight linear patterns ‚Üí high correlation ‚Üí consider dropping one\n",
    "   - Cross-reference with high correlation pairs in section 4.3\n",
    "\n",
    "2. **Are there natural customer segments?**\n",
    "   - Distinct clusters suggest different customer types\n",
    "   - Links to segment-aware outlier analysis in notebook 03\n",
    "\n",
    "3. **Do relationships suggest feature engineering?**\n",
    "   - Curved patterns ‚Üí polynomial or interaction terms may help\n",
    "   - Ratios between correlated features may be more predictive\n",
    "\n",
    "4. **Are distributions suitable for linear models?**\n",
    "   - Fan shapes or heavy skew ‚Üí consider transformations\n",
    "   - Outlier clusters ‚Üí verify with segment analysis\n",
    "\n",
    "**üí° Pro Tip:** Hover over points in the interactive plot to see exact values. Look for outliers that appear across multiple scatter plots - these may be influential observations worth investigating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b762072b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4.8 Datetime Feature Analysis\n",
    "\n",
    "Temporal patterns can reveal important retention signals - when customers joined, their last activity, and seasonal patterns.\n",
    "\n",
    "**üìñ What to Look For:**\n",
    "- **Cohort effects**: Do customers who joined in certain periods have different retention?\n",
    "- **Recency patterns**: How does time since last activity relate to retention?\n",
    "- **Seasonal trends**: Are there monthly or quarterly patterns?\n",
    "\n",
    "**üìä Common Temporal Features:**\n",
    "| Feature Type | Example | Typical Insight |\n",
    "|-------------|---------|-----------------|\n",
    "| **Tenure** | Days since signup | Longer tenure often = higher retention |\n",
    "| **Recency** | Days since last order | Recent activity = engaged customer |\n",
    "| **Cohort** | Signup month/year | Economic conditions affect cohorts |\n",
    "| **Day of Week** | Signup day | Weekend vs weekday patterns |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf45e278",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from customer_retention.stages.profiling import TemporalTargetAnalyzer\n",
    "\n",
    "datetime_cols = [\n",
    "    name for name, col in findings.columns.items()\n",
    "    if col.inferred_type == ColumnType.DATETIME\n",
    "]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATETIME FEATURE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Detected datetime columns: {datetime_cols}\")\n",
    "\n",
    "if datetime_cols and findings.target_column:\n",
    "    target = findings.target_column\n",
    "    overall_retention = df[target].mean()\n",
    "    \n",
    "    # Use framework analyzer\n",
    "    temporal_analyzer = TemporalTargetAnalyzer(min_samples_per_period=10)\n",
    "    \n",
    "    for col_name in datetime_cols[:3]:\n",
    "        result = temporal_analyzer.analyze(df, col_name, target)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üìÖ {col_name.upper()}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        if result.n_valid_dates == 0:\n",
    "            print(\"  No valid dates found\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  Date range: {result.min_date} to {result.max_date}\")\n",
    "        print(f\"  Valid dates: {result.n_valid_dates:,}\")\n",
    "        \n",
    "        # 1. Retention by Year (from framework result)\n",
    "        if len(result.yearly_stats) > 1:\n",
    "            print(f\"\\n  üìä Retention by Year: Trend is {result.yearly_trend}\")\n",
    "            \n",
    "            year_stats = result.yearly_stats\n",
    "            \n",
    "            fig = make_subplots(rows=1, cols=2, subplot_titles=[\"Retention Rate by Year\", \"Customer Count by Year\"],\n",
    "                               column_widths=[0.6, 0.4])\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=year_stats['period'].astype(str),\n",
    "                    y=year_stats['retention_rate'],\n",
    "                    mode='lines+markers',\n",
    "                    name='Retention Rate',\n",
    "                    line=dict(color='#3498db', width=3),\n",
    "                    marker=dict(size=10)\n",
    "                ),\n",
    "                row=1, col=1\n",
    "            )\n",
    "            fig.add_hline(y=overall_retention, line_dash=\"dash\", line_color=\"gray\",\n",
    "                         annotation_text=f\"Overall: {overall_retention:.1%}\", row=1, col=1)\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    x=year_stats['period'].astype(str),\n",
    "                    y=year_stats['count'],\n",
    "                    name='Count',\n",
    "                    marker_color='rgba(52, 152, 219, 0.6)'\n",
    "                ),\n",
    "                row=1, col=2\n",
    "            )\n",
    "            \n",
    "            fig.update_layout(height=350, template='plotly_white', showlegend=False)\n",
    "            fig.update_yaxes(tickformat='.0%', row=1, col=1)\n",
    "            display_figure(fig)\n",
    "        \n",
    "        # 2. Retention by Month (from framework result)\n",
    "        if len(result.monthly_stats) > 1:\n",
    "            print(f\"\\n  üìä Retention by Month (Seasonality):\")\n",
    "            \n",
    "            month_stats = result.monthly_stats\n",
    "            colors = ['rgba(46, 204, 113, 0.7)' if r >= overall_retention else 'rgba(231, 76, 60, 0.7)' \n",
    "                     for r in month_stats['retention_rate']]\n",
    "            \n",
    "            fig = go.Figure()\n",
    "            fig.add_trace(go.Bar(\n",
    "                x=month_stats['month_name'],\n",
    "                y=month_stats['retention_rate'],\n",
    "                marker_color=colors,\n",
    "                text=[f\"{r:.0%}\" for r in month_stats['retention_rate']],\n",
    "                textposition='outside'\n",
    "            ))\n",
    "            fig.add_hline(y=overall_retention, line_dash=\"dash\", line_color=\"gray\",\n",
    "                         annotation_text=f\"Overall: {overall_retention:.1%}\")\n",
    "            \n",
    "            fig.update_layout(\n",
    "                title=f\"Monthly Retention Pattern ({col_name})\",\n",
    "                xaxis_title=\"Month\",\n",
    "                yaxis_title=\"Retention Rate\",\n",
    "                template='plotly_white',\n",
    "                height=350,\n",
    "                yaxis_tickformat='.0%'\n",
    "            )\n",
    "            display_figure(fig)\n",
    "            \n",
    "            # Seasonal insights from framework\n",
    "            if result.seasonal_spread > 0.05:\n",
    "                print(f\"  üìà Seasonal spread: {result.seasonal_spread:.1%}\")\n",
    "                print(f\"     Best month: {result.best_month}\")\n",
    "                print(f\"     Worst month: {result.worst_month}\")\n",
    "        \n",
    "        # 3. Retention by Day of Week (from framework result)\n",
    "        if len(result.dow_stats) > 1:\n",
    "            print(f\"\\n  üìä Retention by Day of Week:\")\n",
    "            \n",
    "            dow_stats = result.dow_stats\n",
    "            colors = ['rgba(46, 204, 113, 0.7)' if r >= overall_retention else 'rgba(231, 76, 60, 0.7)' \n",
    "                     for r in dow_stats['retention_rate']]\n",
    "            \n",
    "            fig = go.Figure()\n",
    "            fig.add_trace(go.Bar(\n",
    "                x=dow_stats['day_name'],\n",
    "                y=dow_stats['retention_rate'],\n",
    "                marker_color=colors,\n",
    "                text=[f\"{r:.0%}\" for r in dow_stats['retention_rate']],\n",
    "                textposition='outside'\n",
    "            ))\n",
    "            fig.add_hline(y=overall_retention, line_dash=\"dash\", line_color=\"gray\")\n",
    "            \n",
    "            fig.update_layout(\n",
    "                title=f\"Day of Week Pattern ({col_name})\",\n",
    "                xaxis_title=\"Day of Week\",\n",
    "                yaxis_title=\"Retention Rate\",\n",
    "                template='plotly_white',\n",
    "                height=300,\n",
    "                yaxis_tickformat='.0%'\n",
    "            )\n",
    "            display_figure(fig)\n",
    "else:\n",
    "    if not datetime_cols:\n",
    "        print(\"\\n  ‚ÑπÔ∏è No datetime columns detected in this dataset.\")\n",
    "        print(\"     Consider adding date parsing in notebook 01 if dates exist as strings.\")\n",
    "    else:\n",
    "        print(\"\\n  ‚ÑπÔ∏è No target column available for retention analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdb65ed",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4.9 Actionable Recommendations Summary\n",
    "\n",
    "This section consolidates all relationship analysis findings into **actionable recommendations** organized by their impact on the modeling pipeline.\n",
    "\n",
    "**üìã Recommendation Categories:**\n",
    "\n",
    "| Category | Purpose | Impact |\n",
    "|----------|---------|--------|\n",
    "| **Feature Selection** | Which features to keep/drop | Reduces noise, improves interpretability |\n",
    "| **Feature Engineering** | New features to create | Captures interactions, improves accuracy |\n",
    "| **Stratification** | Train/test split strategy | Ensures fair evaluation, prevents leakage |\n",
    "| **Model Selection** | Which algorithms to try | Matches model to data characteristics |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7611a2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate comprehensive actionable recommendations\n",
    "recommender = RelationshipRecommender()\n",
    "\n",
    "# Gather columns by type\n",
    "numeric_features = [\n",
    "    name for name, col in findings.columns.items()\n",
    "    if col.inferred_type in [ColumnType.NUMERIC_CONTINUOUS, ColumnType.NUMERIC_DISCRETE]\n",
    "    and name != findings.target_column\n",
    "    and name not in TEMPORAL_METADATA_COLS\n",
    "]\n",
    "categorical_features = [\n",
    "    name for name, col in findings.columns.items()\n",
    "    if col.inferred_type in [ColumnType.CATEGORICAL_NOMINAL, ColumnType.CATEGORICAL_ORDINAL]\n",
    "    and name not in TEMPORAL_METADATA_COLS\n",
    "]\n",
    "\n",
    "# Run comprehensive analysis\n",
    "analysis_summary = recommender.analyze(\n",
    "    df,\n",
    "    numeric_cols=numeric_features,\n",
    "    categorical_cols=categorical_features,\n",
    "    target_col=findings.target_column,\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ACTIONABLE RECOMMENDATIONS FROM RELATIONSHIP ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Group recommendations by category\n",
    "grouped_recs = analysis_summary.recommendations_by_category\n",
    "high_priority = analysis_summary.high_priority_actions\n",
    "\n",
    "if high_priority:\n",
    "    print(f\"\\nüî¥ HIGH PRIORITY ACTIONS ({len(high_priority)}):\")\n",
    "    print(\"-\" * 60)\n",
    "    for rec in high_priority:\n",
    "        print(f\"\\n  üìå {rec.title}\")\n",
    "        print(f\"     {rec.description}\")\n",
    "        print(f\"     ‚Üí Action: {rec.action}\")\n",
    "        if rec.affected_features:\n",
    "            print(f\"     ‚Üí Features: {', '.join(rec.affected_features[:5])}\")\n",
    "\n",
    "# Persist recommendations to registry\n",
    "for pair in analysis_summary.multicollinear_pairs:\n",
    "    registry.add_gold_drop_multicollinear(\n",
    "        column=pair[\"feature1\"], correlated_with=pair[\"feature2\"],\n",
    "        correlation=pair[\"correlation\"],\n",
    "        rationale=f\"High correlation ({pair['correlation']:.2f}) - consider dropping one\",\n",
    "        source_notebook=\"04_relationship_analysis\"\n",
    "    )\n",
    "\n",
    "for predictor in analysis_summary.strong_predictors:\n",
    "    registry.add_gold_prioritize_feature(\n",
    "        column=predictor[\"feature\"], effect_size=predictor[\"effect_size\"],\n",
    "        correlation=predictor[\"correlation\"],\n",
    "        rationale=f\"Strong predictor with effect size {predictor['effect_size']:.2f}\",\n",
    "        source_notebook=\"04_relationship_analysis\"\n",
    "    )\n",
    "\n",
    "for weak_col in analysis_summary.weak_predictors[:10]:\n",
    "    registry.add_gold_drop_weak(\n",
    "        column=weak_col, effect_size=0.0, correlation=0.0,\n",
    "        rationale=\"Negligible predictive power\",\n",
    "        source_notebook=\"04_relationship_analysis\"\n",
    "    )\n",
    "\n",
    "# Persist ratio feature recommendations\n",
    "for rec in grouped_recs.get(RecommendationCategory.FEATURE_ENGINEERING, []):\n",
    "    if \"ratio\" in rec.title.lower() and len(rec.affected_features) >= 2:\n",
    "        registry.add_silver_ratio(\n",
    "            column=f\"{rec.affected_features[0]}_to_{rec.affected_features[1]}_ratio\",\n",
    "            numerator=rec.affected_features[0], denominator=rec.affected_features[1],\n",
    "            rationale=rec.description, source_notebook=\"04_relationship_analysis\"\n",
    "        )\n",
    "    elif \"interaction\" in rec.title.lower() and len(rec.affected_features) >= 2:\n",
    "        for i, f1 in enumerate(rec.affected_features[:3]):\n",
    "            for f2 in rec.affected_features[i+1:4]:\n",
    "                registry.add_silver_interaction(\n",
    "                    column=f\"{f1}_x_{f2}\", features=[f1, f2],\n",
    "                    rationale=rec.description, source_notebook=\"04_relationship_analysis\"\n",
    "                )\n",
    "\n",
    "# Store for findings metadata\n",
    "findings.metadata[\"relationship_analysis\"] = {\n",
    "    \"n_recommendations\": len(analysis_summary.recommendations),\n",
    "    \"n_high_priority\": len(high_priority),\n",
    "    \"strong_predictors\": [p[\"feature\"] for p in analysis_summary.strong_predictors],\n",
    "    \"weak_predictors\": analysis_summary.weak_predictors[:5],\n",
    "    \"multicollinear_pairs\": [(p[\"feature1\"], p[\"feature2\"]) for p in analysis_summary.multicollinear_pairs],\n",
    "}\n",
    "\n",
    "print(f\"\\n‚úÖ Persisted {len(analysis_summary.multicollinear_pairs)} multicollinearity recommendations\")\n",
    "print(f\"‚úÖ Persisted {len(analysis_summary.strong_predictors)} strong predictor recommendations\")\n",
    "print(f\"‚úÖ Persisted {min(len(analysis_summary.weak_predictors), 10)} weak predictor recommendations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fc1fc3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### 4.9.1 Feature Selection Recommendations\n",
    "\n",
    "**What these recommendations tell you:**\n",
    "- Which features to **prioritize** (strong predictors)\n",
    "- Which features to **consider dropping** (weak predictors, redundant features)\n",
    "- Which feature pairs cause **multicollinearity** issues\n",
    "\n",
    "**üìä Decision Guide:**\n",
    "\n",
    "| Finding | Linear Models | Tree-Based Models |\n",
    "|---------|--------------|-------------------|\n",
    "| Strong predictors | Include - will have high coefficients | Include - will appear early in splits |\n",
    "| Weak predictors | Consider dropping | May help in interactions |\n",
    "| Multicollinear pairs | Drop one feature | Can keep both (trees handle it) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70878968",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature Selection Recommendations\n",
    "selection_recs = grouped_recs.get(RecommendationCategory.FEATURE_SELECTION, [])\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"FEATURE SELECTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Strong predictors summary\n",
    "if analysis_summary.strong_predictors:\n",
    "    print(\"\\n‚úÖ STRONG PREDICTORS (prioritize these):\")\n",
    "    strong_df = pd.DataFrame(analysis_summary.strong_predictors)\n",
    "    strong_df[\"effect_size\"] = strong_df[\"effect_size\"].apply(lambda x: f\"{x:+.3f}\")\n",
    "    strong_df[\"correlation\"] = strong_df[\"correlation\"].apply(lambda x: f\"{x:+.3f}\")\n",
    "    strong_df = strong_df.sort_values(\"effect_size\", key=lambda x: x.str.replace(\"+\", \"\").astype(float).abs(), ascending=False)\n",
    "    display(strong_df)\n",
    "    \n",
    "    print(\"\\n   üí° These features show strong discrimination between retained/churned customers.\")\n",
    "    print(\"   ‚Üí Ensure they're included in your model\")\n",
    "    print(\"   ‚Üí Check for data quality issues that could inflate their importance\")\n",
    "\n",
    "# Weak predictors summary\n",
    "if analysis_summary.weak_predictors:\n",
    "    print(f\"\\n‚ö™ WEAK PREDICTORS (consider dropping): {', '.join(analysis_summary.weak_predictors[:5])}\")\n",
    "    print(\"   ‚Üí Low individual predictive power, but may help in combination\")\n",
    "\n",
    "# Multicollinearity summary\n",
    "if analysis_summary.multicollinear_pairs:\n",
    "    print(\"\\n‚ö†Ô∏è MULTICOLLINEAR PAIRS (drop one from each pair for linear models):\")\n",
    "    for pair in analysis_summary.multicollinear_pairs:\n",
    "        print(f\"   ‚Ä¢ {pair['feature1']} ‚Üî {pair['feature2']}: r = {pair['correlation']:.2f}\")\n",
    "    print(\"\\n   üí° For each pair, keep the feature with:\")\n",
    "    print(\"      - Stronger business meaning\")\n",
    "    print(\"      - Higher target correlation\")\n",
    "    print(\"      - Fewer missing values\")\n",
    "\n",
    "# Display all feature selection recommendations\n",
    "if selection_recs:\n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(\"DETAILED RECOMMENDATIONS:\")\n",
    "    for rec in selection_recs:\n",
    "        priority_icon = \"üî¥\" if rec.priority == \"high\" else \"üü°\" if rec.priority == \"medium\" else \"üü¢\"\n",
    "        print(f\"\\n{priority_icon} {rec.title}\")\n",
    "        print(f\"   {rec.description}\")\n",
    "        print(f\"   ‚Üí {rec.action}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8649aa53",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### 4.9.2 Stratification Recommendations\n",
    "\n",
    "**What these recommendations tell you:**\n",
    "- How to **split your data** for training and testing\n",
    "- Which **segments require special attention** in sampling\n",
    "- **High-risk segments** that need adequate representation\n",
    "\n",
    "**‚ö†Ô∏è Why This Matters:**\n",
    "- Random splits can under-represent rare segments\n",
    "- High-risk segments may be systematically excluded\n",
    "- Model evaluation will be biased without proper stratification\n",
    "\n",
    "**üìä Implementation:**\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Stratified split by target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Multi-column stratification (for categorical segments)\n",
    "df['stratify_col'] = df['target'].astype(str) + '_' + df['segment']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b567578c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stratification Recommendations\n",
    "strat_recs = grouped_recs.get(RecommendationCategory.STRATIFICATION, [])\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STRATIFICATION (Train/Test Split Strategy)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# High-risk segments\n",
    "if analysis_summary.high_risk_segments:\n",
    "    print(\"\\nüéØ HIGH-RISK SEGMENTS (ensure representation in training data):\")\n",
    "    risk_df = pd.DataFrame(analysis_summary.high_risk_segments)\n",
    "    risk_df[\"retention_rate\"] = risk_df[\"retention_rate\"].apply(lambda x: f\"{x:.1%}\")\n",
    "    risk_df[\"lift\"] = risk_df[\"lift\"].apply(lambda x: f\"{x:.2f}x\")\n",
    "    display(risk_df[[\"feature\", \"segment\", \"count\", \"retention_rate\", \"lift\"]])\n",
    "    \n",
    "    print(\"\\n   üí° These segments have below-average retention.\")\n",
    "    print(\"   ‚Üí Ensure they're adequately represented in both train and test sets\")\n",
    "    print(\"   ‚Üí Consider oversampling or class weights in modeling\")\n",
    "\n",
    "# Display all stratification recommendations\n",
    "if strat_recs:\n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(\"STRATIFICATION RECOMMENDATIONS:\")\n",
    "    for rec in strat_recs:\n",
    "        priority_icon = \"üî¥\" if rec.priority == \"high\" else \"üü°\" if rec.priority == \"medium\" else \"üü¢\"\n",
    "        print(f\"\\n{priority_icon} {rec.title}\")\n",
    "        print(f\"   {rec.description}\")\n",
    "        print(f\"   ‚Üí {rec.action}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ No special stratification requirements detected.\")\n",
    "    print(\"   Standard stratified split by target variable is sufficient.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5226c4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### 4.9.3 Model Selection Recommendations\n",
    "\n",
    "**What these recommendations tell you:**\n",
    "- Which **model types** are well-suited for your data characteristics\n",
    "- **Linear vs non-linear** based on relationship patterns\n",
    "- **Ensemble considerations** based on feature interactions\n",
    "\n",
    "**üìä Model Selection Guide Based on Data Characteristics:**\n",
    "\n",
    "| Data Characteristic | Recommended Models | Reason |\n",
    "|---------------------|-------------------|--------|\n",
    "| Strong linear relationships | Logistic Regression, Linear SVM | Interpretable, fast, less overfit risk |\n",
    "| Non-linear patterns | Random Forest, XGBoost, LightGBM | Capture complex interactions |\n",
    "| High multicollinearity | Tree-based models | Robust to correlated features |\n",
    "| Many categorical features | CatBoost, LightGBM | Native categorical handling |\n",
    "| Imbalanced classes | Any with class_weight='balanced' | Adjust for minority class |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afae7434",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model Selection Recommendations\n",
    "model_recs = grouped_recs.get(RecommendationCategory.MODEL_SELECTION, [])\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MODEL SELECTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if model_recs:\n",
    "    for rec in model_recs:\n",
    "        priority_icon = \"üî¥\" if rec.priority == \"high\" else \"üü°\" if rec.priority == \"medium\" else \"üü¢\"\n",
    "        print(f\"\\n{priority_icon} {rec.title}\")\n",
    "        print(f\"   {rec.description}\")\n",
    "        print(f\"   ‚Üí {rec.action}\")\n",
    "\n",
    "# Summary recommendations based on data characteristics\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"RECOMMENDED MODELING APPROACH:\")\n",
    "\n",
    "has_multicollinearity = len(analysis_summary.multicollinear_pairs) > 0\n",
    "has_strong_linear = len([p for p in analysis_summary.strong_predictors if abs(p.get(\"effect_size\", 0)) >= 0.5]) > 0\n",
    "has_categoricals = len(categorical_features) > 0\n",
    "\n",
    "if has_strong_linear and not has_multicollinearity:\n",
    "    print(\"\\n‚úÖ RECOMMENDED: Start with Logistic Regression\")\n",
    "    print(\"   ‚Ä¢ Strong linear relationships detected\")\n",
    "    print(\"   ‚Ä¢ Interpretable coefficients for business insights\")\n",
    "    print(\"   ‚Ä¢ Fast training and inference\")\n",
    "    print(\"   ‚Ä¢ Then compare with tree-based ensemble for potential improvement\")\n",
    "elif has_multicollinearity:\n",
    "    print(\"\\n‚úÖ RECOMMENDED: Start with Random Forest or XGBoost\")\n",
    "    print(\"   ‚Ä¢ Multicollinearity present - tree models handle it naturally\")\n",
    "    print(\"   ‚Ä¢ Can keep all features without VIF analysis\")\n",
    "    print(\"   ‚Ä¢ Use feature importance to understand contributions\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ RECOMMENDED: Compare Linear and Tree-Based Models\")\n",
    "    print(\"   ‚Ä¢ No clear linear dominance - test both approaches\")\n",
    "    print(\"   ‚Ä¢ Logistic Regression for interpretability baseline\")\n",
    "    print(\"   ‚Ä¢ Random Forest/XGBoost for potential accuracy gain\")\n",
    "\n",
    "if has_categoricals:\n",
    "    print(\"\\nüí° CATEGORICAL HANDLING:\")\n",
    "    print(\"   ‚Ä¢ For tree models: Consider CatBoost or LightGBM with native categorical support\")\n",
    "    print(\"   ‚Ä¢ For linear models: Use target encoding for high-cardinality features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1cf184",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### 4.9.4 Feature Engineering Recommendations\n",
    "\n",
    "**What these recommendations tell you:**\n",
    "- **Interaction features** to create based on correlation patterns\n",
    "- **Ratio features** that may capture relative relationships\n",
    "- **Polynomial features** for non-linear patterns\n",
    "\n",
    "**üìä Common Feature Engineering Patterns:**\n",
    "\n",
    "| Pattern Found | Feature to Create | Example |\n",
    "|---------------|------------------|---------|\n",
    "| Moderate correlation | Ratio feature | `feature_a / feature_b` |\n",
    "| Both features predictive | Interaction term | `feature_a * feature_b` |\n",
    "| Curved scatter pattern | Polynomial | `feature_a ** 2` |\n",
    "| Related semantics | Difference | `total_orders - returned_orders` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556b8b77",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature Engineering Recommendations\n",
    "eng_recs = grouped_recs.get(RecommendationCategory.FEATURE_ENGINEERING, [])\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if eng_recs:\n",
    "    for rec in eng_recs:\n",
    "        priority_icon = \"üî¥\" if rec.priority == \"high\" else \"üü°\" if rec.priority == \"medium\" else \"üü¢\"\n",
    "        print(f\"\\n{priority_icon} {rec.title}\")\n",
    "        print(f\"   {rec.description}\")\n",
    "        print(f\"   ‚Üí {rec.action}\")\n",
    "        if rec.affected_features:\n",
    "            print(f\"   ‚Üí Features: {', '.join(rec.affected_features[:5])}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ No specific feature engineering recommendations based on correlation patterns.\")\n",
    "    print(\"   Consider domain-specific features based on business knowledge.\")\n",
    "\n",
    "# Additional suggestions based on strong predictors\n",
    "if analysis_summary.strong_predictors:\n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(\"POTENTIAL INTERACTION FEATURES:\")\n",
    "    strong_features = [p[\"feature\"] for p in analysis_summary.strong_predictors[:5]]\n",
    "    if len(strong_features) >= 2:\n",
    "        print(f\"\\n   Based on strong predictors, consider interactions between:\")\n",
    "        for i, f1 in enumerate(strong_features[:3]):\n",
    "            for f2 in strong_features[i+1:4]:\n",
    "                print(f\"   ‚Ä¢ {f1} √ó {f2}\")\n",
    "        print(\"\\n   üí° Tree-based models discover interactions automatically.\")\n",
    "        print(\"   ‚Üí For linear models, create explicit interaction columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd570fee",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### 4.9.5 Recommendations Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85919c5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create summary table of all recommendations\n",
    "all_recs_data = []\n",
    "for rec in analysis_summary.recommendations:\n",
    "    all_recs_data.append({\n",
    "        \"Category\": rec.category.value.replace(\"_\", \" \").title(),\n",
    "        \"Priority\": rec.priority.upper(),\n",
    "        \"Recommendation\": rec.title,\n",
    "        \"Action\": rec.action[:80] + \"...\" if len(rec.action) > 80 else rec.action\n",
    "    })\n",
    "\n",
    "if all_recs_data:\n",
    "    recs_df = pd.DataFrame(all_recs_data)\n",
    "    \n",
    "    # Sort by priority\n",
    "    priority_order = {\"HIGH\": 0, \"MEDIUM\": 1, \"LOW\": 2}\n",
    "    recs_df[\"_sort\"] = recs_df[\"Priority\"].map(priority_order)\n",
    "    recs_df = recs_df.sort_values(\"_sort\").drop(\"_sort\", axis=1)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"ALL RECOMMENDATIONS SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nTotal: {len(recs_df)} recommendations\")\n",
    "    print(f\"  üî¥ High priority: {len(recs_df[recs_df['Priority'] == 'HIGH'])}\")\n",
    "    print(f\"  üü° Medium priority: {len(recs_df[recs_df['Priority'] == 'MEDIUM'])}\")\n",
    "    print(f\"  üü¢ Low priority: {len(recs_df[recs_df['Priority'] == 'LOW'])}\")\n",
    "    \n",
    "    display(recs_df)\n",
    "\n",
    "# Save updated findings and recommendations registry\n",
    "findings.save(FINDINGS_PATH)\n",
    "with open(RECOMMENDATIONS_PATH, \"w\") as f:\n",
    "    yaml.dump(registry.to_dict(), f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Findings updated with relationship analysis: {FINDINGS_PATH}\")\n",
    "print(f\"‚úÖ Recommendations registry saved: {RECOMMENDATIONS_PATH}\")\n",
    "print(f\"   Total recommendations in registry: {len(registry.all_recommendations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbcb32c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Summary: What We Learned\n",
    "\n",
    "In this notebook, we analyzed feature relationships and generated **actionable recommendations** for modeling.\n",
    "\n",
    "### Analysis Performed\n",
    "\n",
    "**Numeric Features:**\n",
    "1. **Correlation Matrix** - Identified multicollinearity issues between feature pairs\n",
    "2. **Effect Sizes (Cohen's d)** - Quantified how well features discriminate retained vs churned\n",
    "3. **Box Plots** - Visualized distribution differences between classes\n",
    "4. **Feature-Target Correlations** - Ranked features by predictive power\n",
    "\n",
    "**Categorical Features:**\n",
    "5. **Cram√©r's V** - Measured association strength for categorical variables\n",
    "6. **Retention by Category** - Identified high-risk segments\n",
    "7. **Lift Analysis** - Found categories performing above/below average\n",
    "\n",
    "**Datetime Features:**\n",
    "8. **Cohort Analysis** - Retention trends by signup year\n",
    "9. **Seasonality** - Monthly patterns in retention\n",
    "\n",
    "### Actionable Recommendations Generated\n",
    "\n",
    "| Category | What It Tells You | Impact on Pipeline |\n",
    "|----------|-------------------|-------------------|\n",
    "| **Feature Selection** | Which features to prioritize/drop | Reduces noise, improves interpretability |\n",
    "| **Stratification** | How to split train/test | Ensures fair evaluation |\n",
    "| **Model Selection** | Which algorithms to try first | Matches model to data |\n",
    "| **Feature Engineering** | Interactions to create | Captures non-linear patterns |\n",
    "\n",
    "### Key Metrics Reference\n",
    "\n",
    "| Data Type | Effect Measure | Strong Signal |\n",
    "|-----------|---------------|---------------|\n",
    "| Numeric | Cohen's d | \\|d\\| ‚â• 0.8 |\n",
    "| Numeric | Correlation | \\|r\\| ‚â• 0.5 |\n",
    "| Categorical | Cram√©r's V | V ‚â• 0.3 |\n",
    "| Categorical | Lift | < 0.9x or > 1.1x |\n",
    "\n",
    "---\n",
    "\n",
    "## Recommended Actions Checklist\n",
    "\n",
    "Based on the analysis above, here are the key actions to take:\n",
    "\n",
    "- [ ] **Feature Selection**: Review strong/weak predictors and multicollinear pairs\n",
    "- [ ] **Stratification**: Use stratified sampling with identified high-risk segments\n",
    "- [ ] **Model Selection**: Start with recommended model type based on data characteristics\n",
    "- [ ] **Feature Engineering**: Create interaction features between strong predictors\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Continue to **05_feature_opportunities.ipynb** to:\n",
    "- Generate derived features (tenure, recency, engagement scores)\n",
    "- Identify interaction features based on relationships found here\n",
    "- Create business-relevant composite scores\n",
    "- Review automated feature recommendations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2.445955,
   "end_time": "2026-01-22T14:18:08.100129",
   "environment_variables": {},
   "exception": true,
   "input_path": "exploration_notebooks/04_relationship_analysis.ipynb",
   "output_path": "docs/tutorial/executed/04_relationship_analysis.ipynb",
   "parameters": {},
   "start_time": "2026-01-22T14:18:05.654174",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}