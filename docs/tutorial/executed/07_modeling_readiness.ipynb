{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5430a049",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [2]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794bf7a6",
   "metadata": {
    "papermill": {
     "duration": 0.001737,
     "end_time": "2026-01-22T14:18:13.645352",
     "exception": false,
     "start_time": "2026-01-22T14:18:13.643615",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Chapter 7: Modeling Readiness\n",
    "\n",
    "**Purpose:** Validate that data is ready for machine learning and identify potential pitfalls.\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to assess if your data is ready for modeling\n",
    "- How to detect potential data leakage before it ruins your model\n",
    "- How to handle class imbalance in binary classification\n",
    "- What preprocessing steps are needed before training\n",
    "\n",
    "**Outputs:**\n",
    "- Pre-modeling validation checklist with pass/fail status\n",
    "- Detailed leakage risk assessment (including temporal leakage)\n",
    "- Class imbalance analysis with strategy recommendations\n",
    "- Overall readiness score\n",
    "\n",
    "---\n",
    "\n",
    "## Why Modeling Readiness Matters\n",
    "\n",
    "| Issue | Impact | Detection |\n",
    "|-------|--------|-----------|\n",
    "| **Data Leakage** | Overly optimistic results that fail in production | High correlation with target, future information |\n",
    "| **Class Imbalance** | Model ignores minority class | Ratio > 3:1 between classes |\n",
    "| **Missing Values** | Model failures or bias | >50% missing in any column |\n",
    "| **Insufficient Data** | Overfitting, poor generalization | <100 rows for simple models |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fed508",
   "metadata": {
    "papermill": {
     "duration": 0.001014,
     "end_time": "2026-01-22T14:18:13.647894",
     "exception": false,
     "start_time": "2026-01-22T14:18:13.646880",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7.1 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "221973b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T14:18:13.651217Z",
     "iopub.status.busy": "2026-01-22T14:18:13.651088Z",
     "iopub.status.idle": "2026-01-22T14:18:14.981960Z",
     "shell.execute_reply": "2026-01-22T14:18:14.981451Z"
    },
    "papermill": {
     "duration": 1.333725,
     "end_time": "2026-01-22T14:18:14.982701",
     "exception": false,
     "start_time": "2026-01-22T14:18:13.648976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from customer_retention.analysis.auto_explorer import ExplorationFindings\n",
    "from customer_retention.analysis.visualization import ChartBuilder, display_figure, display_table\n",
    "from customer_retention.core.config.column_config import ColumnType\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9391d37",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bf84905",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T14:18:14.985769Z",
     "iopub.status.busy": "2026-01-22T14:18:14.985607Z",
     "iopub.status.idle": "2026-01-22T14:18:15.119333Z",
     "shell.execute_reply": "2026-01-22T14:18:15.118827Z"
    },
    "papermill": {
     "duration": 0.135942,
     "end_time": "2026-01-22T14:18:15.119990",
     "exception": true,
     "start_time": "2026-01-22T14:18:14.984048",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No findings files found in ../experiments/findings. Run notebook 01 first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m findings_files = [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m FINDINGS_DIR.glob(\u001b[33m\"\u001b[39m\u001b[33m*_findings.yaml\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmulti_dataset\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m f.name]\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m findings_files:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo findings files found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFINDINGS_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Run notebook 01 first.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m findings_files.sort(key=\u001b[38;5;28;01mlambda\u001b[39;00m f: f.stat().st_mtime, reverse=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     11\u001b[39m FINDINGS_PATH = \u001b[38;5;28mstr\u001b[39m(findings_files[\u001b[32m0\u001b[39m])\n",
      "\u001b[31mFileNotFoundError\u001b[39m: No findings files found in ../experiments/findings. Run notebook 01 first."
     ]
    }
   ],
   "source": [
    "# === CONFIGURATION ===\n",
    "from pathlib import Path\n",
    "\n",
    "FINDINGS_DIR = Path(\"../experiments/findings\")\n",
    "\n",
    "findings_files = [f for f in FINDINGS_DIR.glob(\"*_findings.yaml\") if \"multi_dataset\" not in f.name]\n",
    "if not findings_files:\n",
    "    raise FileNotFoundError(f\"No findings files found in {FINDINGS_DIR}. Run notebook 01 first.\")\n",
    "\n",
    "findings_files.sort(key=lambda f: f.stat().st_mtime, reverse=True)\n",
    "FINDINGS_PATH = str(findings_files[0])\n",
    "\n",
    "print(f\"Found {len(findings_files)} findings file(s)\")\n",
    "print(f\"Using: {FINDINGS_PATH}\")\n",
    "\n",
    "findings = ExplorationFindings.load(FINDINGS_PATH)\n",
    "\n",
    "# Load data with snapshot preference (uses temporal snapshots if available)\n",
    "from customer_retention.stages.temporal import load_data_with_snapshot_preference, TEMPORAL_METADATA_COLS\n",
    "df, data_source = load_data_with_snapshot_preference(findings, output_dir=\"../experiments/findings\")\n",
    "charts = ChartBuilder()\n",
    "\n",
    "print(f\"\\nLoaded {len(df):,} rows from: {data_source}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788b914f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 7.2 Modeling Readiness Checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826cc2d6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checklist = []\n",
    "\n",
    "has_target = findings.target_column is not None\n",
    "checklist.append({\"Check\": \"Target column identified\", \"Status\": \"Pass\" if has_target else \"Fail\"})\n",
    "\n",
    "has_features = len([c for c in findings.columns.values() \n",
    "                   if c.inferred_type not in [ColumnType.IDENTIFIER, ColumnType.TARGET]]) > 0\n",
    "checklist.append({\"Check\": \"Feature columns available\", \"Status\": \"Pass\" if has_features else \"Fail\"})\n",
    "\n",
    "high_missing = any(c.universal_metrics.get(\"null_percentage\", 0) > 50 \n",
    "                   for c in findings.columns.values())\n",
    "checklist.append({\"Check\": \"No columns with >50% missing\", \"Status\": \"Fail\" if high_missing else \"Pass\"})\n",
    "\n",
    "good_quality = findings.overall_quality_score >= 70\n",
    "checklist.append({\"Check\": \"Quality score >= 70\", \"Status\": \"Pass\" if good_quality else \"Warn\"})\n",
    "\n",
    "sufficient_rows = findings.row_count >= 100\n",
    "checklist.append({\"Check\": \"Sufficient sample size (>=100)\", \"Status\": \"Pass\" if sufficient_rows else \"Fail\"})\n",
    "\n",
    "print(\"Modeling Readiness Checklist:\")\n",
    "print(\"=\"*50)\n",
    "checklist_df = pd.DataFrame(checklist)\n",
    "display(checklist_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12578fe",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 7.3 Class Imbalance Analysis\n",
    "\n",
    "**ðŸ“– Understanding Class Imbalance:**\n",
    "- **Ratio < 3:1** - Mild imbalance, standard methods work\n",
    "- **Ratio 3:1 to 10:1** - Moderate imbalance, use stratified sampling + class weights\n",
    "- **Ratio > 10:1** - Severe imbalance, consider SMOTE, undersampling, or focal loss\n",
    "\n",
    "**âš ï¸ Why It Matters:**\n",
    "- Imbalanced data causes models to predict the majority class\n",
    "- Accuracy is misleading (80% accuracy when 80% is majority = useless model)\n",
    "- Use F1-score, Precision, Recall, and AUC instead of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5a8de5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if findings.target_column:\n",
    "    target = findings.target_column\n",
    "    target_series = df[target]\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"CLASS IMBALANCE ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"\\nTarget Column: {target}\")\n",
    "    print(f\"Target Type: {findings.target_type}\")\n",
    "    print(f\"Missing Values: {target_series.isnull().sum()}\")\n",
    "    \n",
    "    if findings.target_type == \"binary\":\n",
    "        value_counts = target_series.value_counts()\n",
    "        majority_class = value_counts.idxmax()\n",
    "        minority_class = value_counts.idxmin()\n",
    "        majority_count = value_counts.max()\n",
    "        minority_count = value_counts.min()\n",
    "        imbalance_ratio = majority_count / minority_count\n",
    "        \n",
    "        print(f\"\\nðŸ“Š CLASS DISTRIBUTION:\")\n",
    "        print(f\"  Majority Class ({majority_class}): {majority_count:,} ({majority_count/len(df)*100:.1f}%)\")\n",
    "        print(f\"  Minority Class ({minority_class}): {minority_count:,} ({minority_count/len(df)*100:.1f}%)\")\n",
    "        print(f\"  Imbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
    "        \n",
    "        # Determine severity and recommendations\n",
    "        print(f\"\\nðŸŽ¯ IMBALANCE ASSESSMENT:\")\n",
    "        if imbalance_ratio > 10:\n",
    "            severity = \"SEVERE\"\n",
    "            color = \"#d62728\"\n",
    "            recommendations = [\n",
    "                \"Use SMOTE or ADASYN for oversampling\",\n",
    "                \"Consider undersampling majority class\",\n",
    "                \"Use focal loss for neural networks\",\n",
    "                \"Use class_weight='balanced' in sklearn models\"\n",
    "            ]\n",
    "        elif imbalance_ratio > 3:\n",
    "            severity = \"MODERATE\"\n",
    "            color = \"#ffbb00\"\n",
    "            recommendations = [\n",
    "                \"Use stratified train/test split\",\n",
    "                \"Use class_weight='balanced' in sklearn models\",\n",
    "                \"Monitor Precision-Recall instead of just accuracy\",\n",
    "                \"Consider threshold tuning\"\n",
    "            ]\n",
    "        else:\n",
    "            severity = \"MILD\"\n",
    "            color = \"#2ca02c\"\n",
    "            recommendations = [\n",
    "                \"Standard methods should work\",\n",
    "                \"Use stratified cross-validation\",\n",
    "                \"Monitor both classes in evaluation\"\n",
    "            ]\n",
    "        \n",
    "        print(f\"  Severity: {severity}\")\n",
    "        print(f\"\\nðŸ“‹ RECOMMENDATIONS:\")\n",
    "        for i, rec in enumerate(recommendations, 1):\n",
    "            print(f\"  {i}. {rec}\")\n",
    "        \n",
    "        # Visualize\n",
    "        fig = go.Figure(go.Bar(\n",
    "            x=['Churned (0)', 'Retained (1)'],\n",
    "            y=[value_counts.get(0, 0), value_counts.get(1, 0)],\n",
    "            marker_color=['#d62728', '#2ca02c'],\n",
    "            text=[f'{value_counts.get(0, 0):,}<br>({value_counts.get(0, 0)/len(df)*100:.1f}%)',\n",
    "                  f'{value_counts.get(1, 0):,}<br>({value_counts.get(1, 0)/len(df)*100:.1f}%)'],\n",
    "            textposition='outside'\n",
    "        ))\n",
    "        fig.update_layout(\n",
    "            title=f'Target Class Distribution (Imbalance: {imbalance_ratio:.1f}:1 - {severity})',\n",
    "            xaxis_title='Class',\n",
    "            yaxis_title='Count',\n",
    "            template='plotly_white',\n",
    "            height=400\n",
    "        )\n",
    "        display_figure(fig)\n",
    "        \n",
    "        # Calculate what balanced class weights would be\n",
    "        print(f\"\\nðŸ’¡ CLASS WEIGHTS FOR SKLEARN:\")\n",
    "        weight_minority = len(df) / (2 * minority_count)\n",
    "        weight_majority = len(df) / (2 * majority_count)\n",
    "        print(f\"  class_weight={{0: {weight_minority:.3f}, 1: {weight_majority:.3f}}}\")\n",
    "        print(f\"  Or use class_weight='balanced'\")\n",
    "else:\n",
    "    print(\"ERROR: No target column identified. Please set one in findings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e776a5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 7.4 Data Leakage Risk Assessment\n",
    "\n",
    "**ðŸ“– Types of Leakage:**\n",
    "- **Target Leakage**: Feature contains information about the target that wouldn't be available at prediction time\n",
    "- **Train-Test Leakage**: Information from test set leaks into training (e.g., scaling before split)\n",
    "- **Temporal Leakage**: Using future information to predict past events\n",
    "\n",
    "**âš ï¸ Warning Signs:**\n",
    "- Correlation > 0.9 with target (suspiciously predictive)\n",
    "- Column names containing 'future', 'outcome', 'result'\n",
    "- Date columns that come after the target determination date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a22b695",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "leakage_risks = []\n",
    "\n",
    "if findings.target_column:\n",
    "    target = findings.target_column\n",
    "    \n",
    "    for col_name, col_info in findings.columns.items():\n",
    "        if col_name == target or col_info.inferred_type == ColumnType.IDENTIFIER:\n",
    "            continue\n",
    "        \n",
    "        if col_info.inferred_type in [ColumnType.NUMERIC_CONTINUOUS, ColumnType.NUMERIC_DISCRETE]:\n",
    "            corr = df[[col_name, target]].corr().iloc[0, 1]\n",
    "            if abs(corr) > 0.9:\n",
    "                leakage_risks.append({\n",
    "                    \"Column\": col_name,\n",
    "                    \"Risk\": \"High\",\n",
    "                    \"Reason\": f\"Very high correlation ({corr:.3f}) - potential leakage\"\n",
    "                })\n",
    "        \n",
    "        if any(kw in col_name.lower() for kw in ['future', 'outcome', 'result', 'after']):\n",
    "            leakage_risks.append({\n",
    "                \"Column\": col_name,\n",
    "                \"Risk\": \"Medium\",\n",
    "                \"Reason\": \"Name suggests post-prediction information\"\n",
    "            })\n",
    "\n",
    "if leakage_risks:\n",
    "    print(\"Potential Leakage Risks:\")\n",
    "    display(pd.DataFrame(leakage_risks))\n",
    "else:\n",
    "    print(\"No obvious leakage risks detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3e8212",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 7.5 Feature Type Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23570140",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "type_summary = {}\n",
    "for col_info in findings.columns.values():\n",
    "    col_type = col_info.inferred_type.value\n",
    "    type_summary[col_type] = type_summary.get(col_type, 0) + 1\n",
    "\n",
    "print(\"Feature Type Distribution:\")\n",
    "for col_type, count in sorted(type_summary.items()):\n",
    "    print(f\"  {col_type}: {count}\")\n",
    "\n",
    "usable_features = sum(1 for c in findings.columns.values() \n",
    "                      if c.inferred_type not in [ColumnType.IDENTIFIER, ColumnType.TARGET])\n",
    "print(f\"\\nUsable features for modeling: {usable_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b575cf3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 7.6 Readiness Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a57c760",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "scores.append(25 if has_target else 0)\n",
    "scores.append(25 if has_features else 0)\n",
    "scores.append(25 if not high_missing else 10)\n",
    "scores.append(25 if good_quality else 15)\n",
    "\n",
    "readiness_score = sum(scores)\n",
    "\n",
    "print(f\"\\nModeling Readiness Score: {readiness_score}/100\")\n",
    "\n",
    "if readiness_score >= 90:\n",
    "    print(\"Status: READY - Proceed to modeling.\")\n",
    "elif readiness_score >= 70:\n",
    "    print(\"Status: MOSTLY READY - Address minor issues before modeling.\")\n",
    "elif readiness_score >= 50:\n",
    "    print(\"Status: NEEDS WORK - Significant issues to resolve.\")\n",
    "else:\n",
    "    print(\"Status: NOT READY - Major issues must be fixed first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d9110e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Summary: What We Learned\n",
    "\n",
    "In this notebook, we validated modeling readiness:\n",
    "\n",
    "1. **Pre-modeling Checklist** - Verified target, features, missing values, and sample size\n",
    "2. **Class Imbalance** - Analyzed distribution and provided mitigation strategies\n",
    "3. **Leakage Assessment** - Checked for suspicious correlations and temporal issues\n",
    "4. **Feature Summary** - Reviewed usable features by type\n",
    "\n",
    "## Key Actions Before Modeling\n",
    "\n",
    "| Action | Priority | Implementation |\n",
    "|--------|----------|----------------|\n",
    "| Use stratified splits | High | `train_test_split(..., stratify=y)` |\n",
    "| Handle imbalance | High | `class_weight='balanced'` or SMOTE |\n",
    "| Scale features | Medium | `StandardScaler` (fit on train only!) |\n",
    "| Encode categoricals | Medium | One-hot or target encoding |\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Continue to **08_baseline_experiments.ipynb** to:\n",
    "- Train baseline models with proper handling\n",
    "- Compare model performance\n",
    "- Analyze feature importance\n",
    "- Evaluate with appropriate metrics (not just accuracy!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2.30497,
   "end_time": "2026-01-22T14:18:15.439007",
   "environment_variables": {},
   "exception": true,
   "input_path": "exploration_notebooks/07_modeling_readiness.ipynb",
   "output_path": "docs/tutorial/executed/07_modeling_readiness.ipynb",
   "parameters": {},
   "start_time": "2026-01-22T14:18:13.134037",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}