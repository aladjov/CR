{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48aef4ae",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [2]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98a0693",
   "metadata": {
    "papermill": {
     "duration": 0.001929,
     "end_time": "2026-01-22T14:18:21.243690",
     "exception": false,
     "start_time": "2026-01-22T14:18:21.241761",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Chapter 10: Pipeline Generation\n",
    "\n",
    "Generate production-ready pipeline code from exploration findings.\n",
    "\n",
    "**Generation Targets:**\n",
    "1. **Local (Feast + MLFlow)** - Local feature store and experiment tracking\n",
    "2. **Databricks (FS + MLFlow)** - Unity Catalog, DLT, Feature Store, MLFlow\n",
    "3. **LLM Documentation** - Markdown files for AI-assisted development\n",
    "\n",
    "**Output Formats:**\n",
    "- Python files (`.py`)\n",
    "- Jupyter notebooks (`.ipynb`)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3c9e5b",
   "metadata": {
    "papermill": {
     "duration": 0.001408,
     "end_time": "2026-01-22T14:18:21.246849",
     "exception": false,
     "start_time": "2026-01-22T14:18:21.245441",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10.1 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dcfeb7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T14:18:21.250960Z",
     "iopub.status.busy": "2026-01-22T14:18:21.250811Z",
     "iopub.status.idle": "2026-01-22T14:18:21.255679Z",
     "shell.execute_reply": "2026-01-22T14:18:21.254650Z"
    },
    "papermill": {
     "duration": 0.008077,
     "end_time": "2026-01-22T14:18:21.256465",
     "exception": false,
     "start_time": "2026-01-22T14:18:21.248388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: customer_churn\n",
      "Target: local\n",
      "Format: py\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "\n",
    "class GenerationTarget(Enum):\n",
    "    LOCAL_FEAST_MLFLOW = \"local\"\n",
    "    DATABRICKS = \"databricks\"\n",
    "    LLM_DOCS = \"llm_docs\"\n",
    "\n",
    "class OutputFormat(Enum):\n",
    "    PYTHON = \"py\"\n",
    "    NOTEBOOK = \"ipynb\"\n",
    "\n",
    "# === USER CONFIGURATION ===\n",
    "PIPELINE_NAME = \"customer_churn\"\n",
    "GENERATION_TARGET = GenerationTarget.LOCAL_FEAST_MLFLOW\n",
    "OUTPUT_FORMAT = OutputFormat.PYTHON\n",
    "\n",
    "# Paths\n",
    "FINDINGS_DIR = Path(\"../experiments/findings\")\n",
    "OUTPUT_BASE_DIR = Path(\"../generated_pipelines\")\n",
    "\n",
    "# Databricks settings (only used when GENERATION_TARGET == DATABRICKS)\n",
    "DATABRICKS_CATALOG = \"main\"\n",
    "DATABRICKS_SCHEMA = \"ml_features\"\n",
    "\n",
    "print(f\"Pipeline: {PIPELINE_NAME}\")\n",
    "print(f\"Target: {GENERATION_TARGET.value}\")\n",
    "print(f\"Format: {OUTPUT_FORMAT.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ce7c29",
   "metadata": {
    "papermill": {
     "duration": 0.001775,
     "end_time": "2026-01-22T14:18:21.260334",
     "exception": false,
     "start_time": "2026-01-22T14:18:21.258559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10.2 Load Findings and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b742a25c",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ef16f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T14:18:21.264307Z",
     "iopub.status.busy": "2026-01-22T14:18:21.264197Z",
     "iopub.status.idle": "2026-01-22T14:18:22.689675Z",
     "shell.execute_reply": "2026-01-22T14:18:22.689094Z"
    },
    "papermill": {
     "duration": 1.428533,
     "end_time": "2026-01-22T14:18:22.690522",
     "exception": true,
     "start_time": "2026-01-22T14:18:21.261989",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No findings in ../experiments/findings. Run exploration notebooks first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     41\u001b[39m             multi_dataset = yaml.safe_load(f)\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m findings, registry, multi_dataset\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m findings, registry, multi_dataset = \u001b[43mload_findings_and_recommendations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFINDINGS_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfindings.source_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     48\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRows: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfindings.row_count\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfindings.column_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mload_findings_and_recommendations\u001b[39m\u001b[34m(findings_dir)\u001b[39m\n\u001b[32m      6\u001b[39m findings_files = \u001b[38;5;28msorted\u001b[39m(\n\u001b[32m      7\u001b[39m     [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m findings_dir.glob(\u001b[33m\"\u001b[39m\u001b[33m*_findings.yaml\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmulti_dataset\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m f.name],\n\u001b[32m      8\u001b[39m     key=\u001b[38;5;28;01mlambda\u001b[39;00m f: f.stat().st_mtime, reverse=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      9\u001b[39m )\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m findings_files:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo findings in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfindings_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Run exploration notebooks first.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m findings = ExplorationFindings.load(\u001b[38;5;28mstr\u001b[39m(findings_files[\u001b[32m0\u001b[39m]))\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Look for recommendations file matching the findings file pattern\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Step 06 saves as: {name}_recommendations.yaml (matching {name}_findings.yaml)\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: No findings in ../experiments/findings. Run exploration notebooks first."
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from customer_retention.analysis.auto_explorer import ExplorationFindings\n",
    "from customer_retention.analysis.auto_explorer.layered_recommendations import RecommendationRegistry\n",
    "\n",
    "def load_findings_and_recommendations(findings_dir: Path):\n",
    "    findings_files = sorted(\n",
    "        [f for f in findings_dir.glob(\"*_findings.yaml\") if \"multi_dataset\" not in f.name],\n",
    "        key=lambda f: f.stat().st_mtime, reverse=True\n",
    "    )\n",
    "    if not findings_files:\n",
    "        raise FileNotFoundError(f\"No findings in {findings_dir}. Run exploration notebooks first.\")\n",
    "    \n",
    "    findings = ExplorationFindings.load(str(findings_files[0]))\n",
    "    \n",
    "    # Look for recommendations file matching the findings file pattern\n",
    "    # Step 06 saves as: {name}_recommendations.yaml (matching {name}_findings.yaml)\n",
    "    findings_name = findings_files[0].stem.replace(\"_findings\", \"\")\n",
    "    recommendations_path = findings_dir / f\"{findings_name}_recommendations.yaml\"\n",
    "    \n",
    "    # Fallback to generic recommendations.yaml if not found\n",
    "    if not recommendations_path.exists():\n",
    "        recommendations_path = findings_dir / \"recommendations.yaml\"\n",
    "    \n",
    "    # Final fallback: find any *_recommendations.yaml\n",
    "    if not recommendations_path.exists():\n",
    "        rec_files = sorted(findings_dir.glob(\"*_recommendations.yaml\"), \n",
    "                          key=lambda f: f.stat().st_mtime, reverse=True)\n",
    "        if rec_files:\n",
    "            recommendations_path = rec_files[0]\n",
    "    \n",
    "    registry = None\n",
    "    if recommendations_path.exists():\n",
    "        with open(recommendations_path) as f:\n",
    "            registry = RecommendationRegistry.from_dict(yaml.safe_load(f))\n",
    "        print(f\"Loaded recommendations from: {recommendations_path.name}\")\n",
    "    \n",
    "    multi_dataset_path = findings_dir / \"multi_dataset_findings.yaml\"\n",
    "    multi_dataset = None\n",
    "    if multi_dataset_path.exists():\n",
    "        with open(multi_dataset_path) as f:\n",
    "            multi_dataset = yaml.safe_load(f)\n",
    "    \n",
    "    return findings, registry, multi_dataset\n",
    "\n",
    "findings, registry, multi_dataset = load_findings_and_recommendations(FINDINGS_DIR)\n",
    "\n",
    "print(f\"Loaded: {findings.source_path}\")\n",
    "print(f\"Rows: {findings.row_count:,} | Columns: {findings.column_count}\")\n",
    "print(f\"Target: {findings.target_column}\")\n",
    "print(f\"Recommendations: {'Loaded' if registry else 'Not found'}\")\n",
    "print(f\"Multi-dataset: {'Loaded' if multi_dataset else 'Not found'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0ffc37",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 10.3 Review Layered Recommendations\n",
    "\n",
    "Recommendations are organized by medallion layer:\n",
    "- **Bronze**: null_handling, outlier_handling, type_conversions, deduplication, filtering, text_processing\n",
    "- **Silver**: joins, aggregations, derived_columns\n",
    "- **Gold**: encoding, scaling, feature_selection, transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e84f5c4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_recommendations(registry: RecommendationRegistry):\n",
    "    if not registry:\n",
    "        print(\"No recommendations loaded. Run notebooks 02-07 first.\")\n",
    "        return\n",
    "    \n",
    "    for layer in [\"bronze\", \"silver\", \"gold\"]:\n",
    "        recs = registry.get_by_layer(layer)\n",
    "        print(f\"\\n{layer.upper()} ({len(recs)} recommendations):\")\n",
    "        print(\"-\" * 50)\n",
    "        for rec in recs[:5]:\n",
    "            print(f\"  [{rec.category}] {rec.target_column}: {rec.action}\")\n",
    "        if len(recs) > 5:\n",
    "            print(f\"  ... and {len(recs) - 5} more\")\n",
    "\n",
    "display_recommendations(registry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d292c18",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 10.4 Generate Pipeline\n",
    "\n",
    "Select generation based on configured target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce77da7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_dir = OUTPUT_BASE_DIR / GENERATION_TARGET.value / PIPELINE_NAME\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3607ce32",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Option A: Local (Feast + MLFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26a653b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if GENERATION_TARGET == GenerationTarget.LOCAL_FEAST_MLFLOW:\n",
    "    from customer_retention.generators.spec_generator import MLflowPipelineGenerator, MLflowConfig\n",
    "    from customer_retention.generators.pipeline_generator import PipelineGenerator\n",
    "    \n",
    "    mlflow_config = MLflowConfig(\n",
    "        tracking_uri=\"./mlruns\",\n",
    "        experiment_name=PIPELINE_NAME,\n",
    "        log_data_quality=True,\n",
    "        nested_runs=True\n",
    "    )\n",
    "    \n",
    "    mlflow_gen = MLflowPipelineGenerator(mlflow_config=mlflow_config, output_dir=str(output_dir))\n",
    "    \n",
    "    if OUTPUT_FORMAT == OutputFormat.PYTHON:\n",
    "        saved = mlflow_gen.save_all(findings)\n",
    "        print(\"Generated MLflow pipeline files:\")\n",
    "        for f in saved:\n",
    "            print(f\"  {f}\")\n",
    "    \n",
    "    if multi_dataset:\n",
    "        pipeline_gen = PipelineGenerator(\n",
    "            findings_dir=str(FINDINGS_DIR),\n",
    "            output_dir=str(output_dir),\n",
    "            pipeline_name=PIPELINE_NAME\n",
    "        )\n",
    "        orch_files = pipeline_gen.generate()\n",
    "        print(\"\\nGenerated pipeline files (Bronze/Silver/Gold/Training):\")\n",
    "        for f in orch_files:\n",
    "            print(f\"  {f}\")\n",
    "else:\n",
    "    print(f\"Skipping Local generation (target is {GENERATION_TARGET.value})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493c3322",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Option B: Databricks (FS + MLFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb55024",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if GENERATION_TARGET == GenerationTarget.DATABRICKS:\n",
    "    from customer_retention.generators.spec_generator import DatabricksSpecGenerator, PipelineSpec, SourceSpec\n",
    "    \n",
    "    spec = PipelineSpec(\n",
    "        name=PIPELINE_NAME,\n",
    "        version=\"1.0.0\",\n",
    "        sources=[SourceSpec(\n",
    "            name=findings.source_path.split(\"/\")[-1].replace(\".csv\", \"\"),\n",
    "            path=findings.source_path,\n",
    "            format=findings.source_format\n",
    "        )]\n",
    "    )\n",
    "    \n",
    "    if findings.target_column:\n",
    "        from customer_retention.generators.spec_generator import ModelSpec\n",
    "        spec.model_config = ModelSpec(\n",
    "            name=f\"{PIPELINE_NAME}_model\",\n",
    "            model_type=\"gradient_boosting\",\n",
    "            target_column=findings.target_column\n",
    "        )\n",
    "    \n",
    "    db_gen = DatabricksSpecGenerator(\n",
    "        catalog=DATABRICKS_CATALOG,\n",
    "        schema=DATABRICKS_SCHEMA,\n",
    "        output_dir=str(output_dir)\n",
    "    )\n",
    "    \n",
    "    saved = db_gen.save_all(spec)\n",
    "    print(\"Generated Databricks artifacts:\")\n",
    "    for f in saved:\n",
    "        print(f\"  {f}\")\n",
    "else:\n",
    "    print(f\"Skipping Databricks generation (target is {GENERATION_TARGET.value})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fdb001",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Option C: LLM Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafcd726",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if GENERATION_TARGET == GenerationTarget.LLM_DOCS:\n",
    "    from customer_retention.analysis.auto_explorer import RecommendationEngine\n",
    "    \n",
    "    recommender = RecommendationEngine()\n",
    "    target_rec = recommender.recommend_target(findings)\n",
    "    feature_recs = recommender.recommend_features(findings)\n",
    "    cleaning_recs = recommender.recommend_cleaning(findings)\n",
    "    \n",
    "    docs_dir = output_dir / \"docs\"\n",
    "    docs_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 1. Overview\n",
    "    overview = f\"\"\"# {PIPELINE_NAME} Pipeline Overview\n",
    "\n",
    "## Data Source\n",
    "- **Path**: {findings.source_path}\n",
    "- **Format**: {findings.source_format}\n",
    "- **Rows**: {findings.row_count:,}\n",
    "- **Columns**: {findings.column_count}\n",
    "- **Quality Score**: {findings.overall_quality_score:.1f}/100\n",
    "\n",
    "## Target Variable\n",
    "- **Column**: {target_rec.column_name}\n",
    "- **Type**: {target_rec.target_type}\n",
    "- **Rationale**: {target_rec.rationale}\n",
    "\n",
    "## Column Types\n",
    "| Column | Type | Nulls | Unique |\n",
    "|--------|------|-------|--------|\n",
    "\"\"\"\n",
    "    for name, col in list(findings.columns.items())[:20]:\n",
    "        overview += f\"| {name} | {col.inferred_type.value} | {col.null_percentage:.1f}% | {col.unique_count} |\\n\"\n",
    "    (docs_dir / \"01_overview.md\").write_text(overview)\n",
    "    \n",
    "    # 2. Bronze layer - separate file per source\n",
    "    if registry and registry.sources:\n",
    "        for source_name, bronze_recs in registry.sources.items():\n",
    "            bronze_doc = f\"\"\"# Bronze Layer - {source_name}\n",
    "\n",
    "## Source File\n",
    "`{bronze_recs.source_file}`\n",
    "\n",
    "## Null Handling\n",
    "\"\"\"\n",
    "            for rec in bronze_recs.null_handling:\n",
    "                bronze_doc += f\"- `{rec.target_column}`: {rec.action} ({rec.parameters.get('strategy', '')}) - {rec.rationale}\\n\"\n",
    "            \n",
    "            bronze_doc += \"\\n## Outlier Handling\\n\"\n",
    "            for rec in bronze_recs.outlier_handling:\n",
    "                bronze_doc += f\"- `{rec.target_column}`: {rec.action} - {rec.rationale}\\n\"\n",
    "            \n",
    "            bronze_doc += \"\\n## Type Conversions\\n\"\n",
    "            for rec in bronze_recs.type_conversions:\n",
    "                bronze_doc += f\"- `{rec.target_column}`: {rec.action} - {rec.rationale}\\n\"\n",
    "            \n",
    "            bronze_doc += \"\\n## Deduplication\\n\"\n",
    "            for rec in bronze_recs.deduplication:\n",
    "                bronze_doc += f\"- `{rec.target_column}`: {rec.action} - {rec.rationale}\\n\"\n",
    "            \n",
    "            bronze_doc += \"\\n## Filtering\\n\"\n",
    "            for rec in bronze_recs.filtering:\n",
    "                bronze_doc += f\"- `{rec.target_column}`: {rec.action} - {rec.rationale}\\n\"\n",
    "            \n",
    "            bronze_doc += \"\\n## Text Processing\\n\"\n",
    "            for rec in bronze_recs.text_processing:\n",
    "                bronze_doc += f\"- `{rec.target_column}`: {rec.action} - {rec.rationale}\\n\"\n",
    "            \n",
    "            safe_name = source_name.replace(\" \", \"_\").lower()\n",
    "            (docs_dir / f\"02_bronze_cleaning_{safe_name}.md\").write_text(bronze_doc)\n",
    "    else:\n",
    "        bronze_doc = f\"\"\"# Bronze Layer - Data Cleaning\n",
    "\n",
    "## Cleaning Recommendations\n",
    "\"\"\"\n",
    "        for rec in cleaning_recs:\n",
    "            bronze_doc += f\"\\n### {rec.column_name}\\n- **Strategy**: {rec.strategy}\\n- **Severity**: {rec.severity}\\n- **Rationale**: {rec.rationale}\\n\"\n",
    "        (docs_dir / \"02_bronze_cleaning.md\").write_text(bronze_doc)\n",
    "    \n",
    "    # 3. Silver layer\n",
    "    silver_doc = \"\"\"# Silver Layer - Feature Engineering\n",
    "\n",
    "## Aggregations and Joins\n",
    "\"\"\"\n",
    "    if registry and registry.silver:\n",
    "        silver_doc += \"\\n### Joins\\n\"\n",
    "        for rec in registry.silver.joins:\n",
    "            silver_doc += f\"- {rec.parameters.get('left_source', '')} ⟷ {rec.parameters.get('right_source', '')} on `{rec.parameters.get('join_keys', [])}`\\n\"\n",
    "        \n",
    "        silver_doc += \"\\n### Aggregations\\n\"\n",
    "        for rec in registry.silver.aggregations:\n",
    "            silver_doc += f\"- `{rec.target_column}`: {rec.action} - windows: {rec.parameters.get('windows', [])}\\n\"\n",
    "        \n",
    "        silver_doc += \"\\n### Derived Columns\\n\"\n",
    "        for rec in registry.silver.derived_columns:\n",
    "            silver_doc += f\"- `{rec.target_column}`: {rec.parameters.get('expression', rec.action)}\\n\"\n",
    "    else:\n",
    "        silver_doc += \"\\nNo silver-layer recommendations found.\\n\"\n",
    "    (docs_dir / \"03_silver_features.md\").write_text(silver_doc)\n",
    "    \n",
    "    # 4. Gold layer\n",
    "    gold_doc = \"\"\"# Gold Layer - ML Features\n",
    "\n",
    "## Feature Recommendations\n",
    "\"\"\"\n",
    "    for rec in feature_recs[:15]:\n",
    "        gold_doc += f\"\\n### {rec.feature_name}\\n- **Source**: {rec.source_column}\\n- **Type**: {rec.feature_type}\\n- **Description**: {rec.description}\\n\"\n",
    "    \n",
    "    if registry and registry.gold:\n",
    "        gold_doc += \"\\n## Encoding\\n\"\n",
    "        for rec in registry.gold.encoding:\n",
    "            gold_doc += f\"- `{rec.target_column}`: {rec.parameters.get('method', rec.action)}\\n\"\n",
    "        \n",
    "        gold_doc += \"\\n## Scaling\\n\"\n",
    "        for rec in registry.gold.scaling:\n",
    "            gold_doc += f\"- `{rec.target_column}`: {rec.parameters.get('method', rec.action)}\\n\"\n",
    "        \n",
    "        gold_doc += \"\\n## Feature Selection\\n\"\n",
    "        for rec in registry.gold.feature_selection:\n",
    "            gold_doc += f\"- `{rec.target_column}`: {rec.action} - {rec.rationale}\\n\"\n",
    "        \n",
    "        gold_doc += \"\\n## Transformations\\n\"\n",
    "        for rec in registry.gold.transformations:\n",
    "            gold_doc += f\"- `{rec.target_column}`: {rec.action} - {rec.parameters}\\n\"\n",
    "    (docs_dir / \"04_gold_ml_features.md\").write_text(gold_doc)\n",
    "    \n",
    "    # 5. Training\n",
    "    training_doc = f\"\"\"# Model Training\n",
    "\n",
    "## Target\n",
    "- **Column**: {target_rec.column_name}\n",
    "- **Type**: {target_rec.target_type}\n",
    "\n",
    "## Recommended Models\n",
    "1. **Gradient Boosting** - Good for tabular data with mixed types\n",
    "2. **Random Forest** - Robust baseline, handles missing values\n",
    "3. **Logistic Regression** - Interpretable, good for imbalanced data\n",
    "\n",
    "## Evaluation Metrics\n",
    "- ROC-AUC (primary)\n",
    "- Precision/Recall at threshold\n",
    "- F1 Score\n",
    "\"\"\"\n",
    "    (docs_dir / \"05_training.md\").write_text(training_doc)\n",
    "    \n",
    "    print(\"Generated LLM documentation:\")\n",
    "    for f in sorted(docs_dir.glob(\"*.md\")):\n",
    "        print(f\"  {f.name}\")\n",
    "else:\n",
    "    print(f\"Skipping LLM docs generation (target is {GENERATION_TARGET.value})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efb23bb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 10.5 Convert to Notebooks (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6741e279",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def py_to_notebook(py_path: Path):\n",
    "    content = py_path.read_text()\n",
    "    cells = []\n",
    "    current_lines = []\n",
    "    \n",
    "    for line in content.split(\"\\n\"):\n",
    "        if line.startswith(\"# %% \") or line.startswith(\"# %%\\n\"):\n",
    "            if current_lines:\n",
    "                cells.append({\"cell_type\": \"code\", \"metadata\": {}, \"source\": current_lines, \"outputs\": [], \"execution_count\": None})\n",
    "                current_lines = []\n",
    "            title = line.replace(\"# %% \", \"\").strip()\n",
    "            if title:\n",
    "                cells.append({\"cell_type\": \"markdown\", \"metadata\": {}, \"source\": [f\"## {title}\"]})\n",
    "        else:\n",
    "            current_lines.append(line + \"\\n\")\n",
    "    \n",
    "    if current_lines:\n",
    "        cells.append({\"cell_type\": \"code\", \"metadata\": {}, \"source\": current_lines, \"outputs\": [], \"execution_count\": None})\n",
    "    \n",
    "    notebook = {\n",
    "        \"cells\": cells,\n",
    "        \"metadata\": {\"kernelspec\": {\"display_name\": \"Python 3\", \"language\": \"python\", \"name\": \"python3\"}},\n",
    "        \"nbformat\": 4, \"nbformat_minor\": 4\n",
    "    }\n",
    "    \n",
    "    out_path = py_path.with_suffix(\".ipynb\")\n",
    "    out_path.write_text(json.dumps(notebook, indent=1))\n",
    "    return out_path\n",
    "\n",
    "if OUTPUT_FORMAT == OutputFormat.NOTEBOOK:\n",
    "    print(\"Converting Python files to notebooks...\")\n",
    "    for py_file in output_dir.rglob(\"*.py\"):\n",
    "        if py_file.name != \"__init__.py\":\n",
    "            nb_path = py_to_notebook(py_file)\n",
    "            print(f\"  {py_file.name} -> {nb_path.name}\")\n",
    "else:\n",
    "    print(\"Output format is Python. Set OUTPUT_FORMAT = OutputFormat.NOTEBOOK to convert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f47b1e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 10.6 Run Pipeline\n",
    "\n",
    "Single command runs everything: Bronze (parallel) → Silver → Gold → Training → MLflow UI (auto-opens browser)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf60789",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uncomment below to run the pipeline after generation\n",
    "# RUN_PIPELINE = True\n",
    "\n",
    "RUN_PIPELINE = False\n",
    "\n",
    "run_all_path = output_dir / \"run_all.py\"\n",
    "\n",
    "if RUN_PIPELINE and GENERATION_TARGET == GenerationTarget.LOCAL_FEAST_MLFLOW:\n",
    "    import subprocess\n",
    "    if run_all_path.exists():\n",
    "        print(f\"Running: python {run_all_path}\")\n",
    "        print(\"Pipeline will run and MLflow UI will open automatically...\")\n",
    "        subprocess.run([\"python\", str(run_all_path)], cwd=run_all_path.parent)\n",
    "    else:\n",
    "        print(f\"run_all.py not found. Generate first by running cells above.\")\n",
    "else:\n",
    "    print(\"To run the complete pipeline:\")\n",
    "    print(f\"\\n  cd {output_dir}\")\n",
    "    print(f\"  python run_all.py\")\n",
    "    print(f\"\\nThis will:\")\n",
    "    print(\"  1. Run Bronze layers (parallel)\")\n",
    "    print(\"  2. Run Silver merge\")\n",
    "    print(\"  3. Run Gold features\")\n",
    "    print(\"  4. Train models with MLflow\")\n",
    "    print(\"  5. Auto-start MLflow UI and open browser\")\n",
    "    print(\"  6. Press Ctrl+C to stop MLflow UI when done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9611343a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 10.7 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e0d251",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Generated Artifacts Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Pipeline: {PIPELINE_NAME}\")\n",
    "print(f\"Target: {GENERATION_TARGET.value}\")\n",
    "print(f\"Format: {OUTPUT_FORMAT.value}\")\n",
    "print(f\"Output: {output_dir}\")\n",
    "print()\n",
    "\n",
    "def show_tree(path: Path, prefix: str = \"\"):\n",
    "    items = sorted(path.iterdir(), key=lambda p: (p.is_file(), p.name))\n",
    "    for i, item in enumerate(items):\n",
    "        is_last = i == len(items) - 1\n",
    "        connector = \"└── \" if is_last else \"├── \"\n",
    "        if item.is_file():\n",
    "            size = item.stat().st_size\n",
    "            print(f\"{prefix}{connector}{item.name} ({size:,} bytes)\")\n",
    "        else:\n",
    "            print(f\"{prefix}{connector}{item.name}/\")\n",
    "            show_tree(item, prefix + (\"    \" if is_last else \"│   \"))\n",
    "\n",
    "if output_dir.exists():\n",
    "    show_tree(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dfe3b1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 10.8 Recommendations Hash\n",
    "\n",
    "The recommendations hash is a unique identifier for the gold layer feature engineering configuration. It enables experiment tracking and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91c5b2e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if registry:\n",
    "    recommendations_hash = registry.compute_recommendations_hash()\n",
    "    print(\"Recommendations Hash\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Hash: {recommendations_hash}\")\n",
    "    print(f\"Full version tag: v1.0.0_{recommendations_hash}\")\n",
    "    print()\n",
    "    print(\"This hash uniquely identifies the gold layer configuration:\")\n",
    "    print(f\"  - Encodings: {len(registry.gold.encoding) if registry.gold else 0}\")\n",
    "    print(f\"  - Scalings: {len(registry.gold.scaling) if registry.gold else 0}\")\n",
    "    print(f\"  - Transformations: {len(registry.gold.transformations) if registry.gold else 0}\")\n",
    "    print(f\"  - Feature selections: {len(registry.gold.feature_selection) if registry.gold else 0}\")\n",
    "    \n",
    "    # Show what's in each layer for debugging\n",
    "    print()\n",
    "    print(\"Recommendations by layer:\")\n",
    "    for layer in [\"bronze\", \"silver\", \"gold\"]:\n",
    "        recs = registry.get_by_layer(layer)\n",
    "        print(f\"  {layer.upper()}: {len(recs)} recommendations\")\n",
    "        if recs and layer == \"gold\":\n",
    "            for rec in recs[:3]:\n",
    "                print(f\"    - [{rec.category}] {rec.target_column}: {rec.action}\")\n",
    "            if len(recs) > 3:\n",
    "                print(f\"    ... and {len(recs) - 3} more\")\n",
    "    \n",
    "    # Check if gold layer exists but is empty\n",
    "    if registry.gold:\n",
    "        print(f\"\\n✓ Gold layer initialized (target: {registry.gold.target_column})\")\n",
    "    else:\n",
    "        print(\"\\n⚠ Gold layer not initialized - run step 06 first\")\n",
    "    \n",
    "    print()\n",
    "    print(\"Use this hash to:\")\n",
    "    print(\"  - Track MLflow experiments (tag: recommendations_hash)\")\n",
    "    print(\"  - Version Feast feature views (tag in feature_store)\")\n",
    "    print(\"  - Return to a specific feature engineering configuration\")\n",
    "else:\n",
    "    print(\"No recommendations loaded - hash not available\")\n",
    "    print(\"Run notebooks 02-07 first, then re-run this notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5be158a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 10.9 Feast Feature Store Validation\n",
    "\n",
    "Check what's registered in Feast after running the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bd767b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 10.10 Next Steps\n",
    "\n",
    "### Run Pipeline (Single Command)\n",
    "```bash\n",
    "cd ../generated_pipelines/local/customer_churn\n",
    "python run_all.py\n",
    "```\n",
    "\n",
    "This single command:\n",
    "1. Runs Bronze layers in **parallel**\n",
    "2. Runs Silver merge\n",
    "3. Runs Gold features  \n",
    "4. Trains models with MLflow tracking\n",
    "5. **Auto-starts MLflow UI** and opens browser\n",
    "6. Press `Ctrl+C` to stop when done\n",
    "\n",
    "### Generated Structure\n",
    "```\n",
    "generated_pipelines/local/{pipeline}/\n",
    "├── run_all.py          # Single entry point\n",
    "├── config.py           # Configuration (includes RECOMMENDATIONS_HASH)\n",
    "├── bronze/\n",
    "│   └── bronze_*.py     # Parallel execution\n",
    "├── silver/\n",
    "│   └── silver_merge.py\n",
    "├── gold/\n",
    "│   └── gold_features.py  # Includes feature version tag\n",
    "├── training/\n",
    "│   └── ml_experiment.py  # MLflow tags with recommendations_hash\n",
    "├── pipeline.py         # Standalone pipeline script\n",
    "└── requirements.txt\n",
    "```\n",
    "\n",
    "### Tracking Your Experiment\n",
    "After running, you can find your experiment by:\n",
    "- **MLflow UI**: Filter by tag `recommendations_hash = <your_hash>`\n",
    "- **Feast**: Check feature view tags for `recommendations_hash`\n",
    "- **Return to config**: The hash uniquely identifies the gold layer settings\n",
    "\n",
    "---\n",
    "\n",
    "## Complete!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2.363435,
   "end_time": "2026-01-22T14:18:23.009882",
   "environment_variables": {},
   "exception": true,
   "input_path": "exploration_notebooks/10_spec_generation.ipynb",
   "output_path": "docs/tutorial/executed/10_spec_generation.ipynb",
   "parameters": {},
   "start_time": "2026-01-22T14:18:20.646447",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}