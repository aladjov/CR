{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67619478",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [2]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9353f13",
   "metadata": {
    "papermill": {
     "duration": 0.004328,
     "end_time": "2026-01-22T14:17:48.523087",
     "exception": false,
     "start_time": "2026-01-22T14:17:48.518759",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Chapter 1c: Temporal Pattern Analysis (Event Bronze Track)\n",
    "\n",
    "**Purpose:** Discover temporal patterns in event-level data that inform feature engineering and model design.\n",
    "\n",
    "**When to use this notebook:**\n",
    "- After completing 01a and 01b (temporal deep dive and quality checks)\n",
    "- Your dataset is EVENT_LEVEL granularity\n",
    "- You want to understand time-based patterns before aggregation\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to detect long-term trends in your data\n",
    "- How to identify seasonality patterns (weekly, monthly)\n",
    "- How cohort analysis reveals customer lifecycle patterns\n",
    "- How recency relates to target outcomes\n",
    "\n",
    "**Pattern Categories:**\n",
    "\n",
    "| Pattern | Description | Feature Engineering Impact |\n",
    "|---------|-------------|---------------------------|\n",
    "| **Trend** | Long-term direction (up/down) | Detrend features, add trend slope |\n",
    "| **Seasonality** | Periodic patterns (weekly, monthly) | Add cyclical encodings, seasonal indicators |\n",
    "| **Cohort Effects** | Behavior varies by join date | Add cohort features, stratify models |\n",
    "| **Recency Effects** | Recent activity predicts outcomes | Prioritize recent time windows |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412ea8a9",
   "metadata": {
    "papermill": {
     "duration": 0.019691,
     "end_time": "2026-01-22T14:17:48.546677",
     "exception": false,
     "start_time": "2026-01-22T14:17:48.526986",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1c.1 Load Findings and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c78905f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T14:17:48.554095Z",
     "iopub.status.busy": "2026-01-22T14:17:48.553978Z",
     "iopub.status.idle": "2026-01-22T14:17:49.987418Z",
     "shell.execute_reply": "2026-01-22T14:17:49.986936Z"
    },
    "papermill": {
     "duration": 1.438231,
     "end_time": "2026-01-22T14:17:49.988355",
     "exception": false,
     "start_time": "2026-01-22T14:17:48.550124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from customer_retention.analysis.auto_explorer import ExplorationFindings\n",
    "from customer_retention.analysis.visualization import ChartBuilder, display_figure, display_table\n",
    "from customer_retention.core.config.column_config import ColumnType, DatasetGranularity\n",
    "from customer_retention.stages.profiling import (\n",
    "    TemporalPatternAnalyzer, TemporalPatternAnalysis,\n",
    "    TrendResult, TrendDirection, SeasonalityResult, RecencyResult,\n",
    "    TemporalFeatureAnalyzer, VelocityResult, MomentumResult,\n",
    "    LagCorrelationResult, PredictivePowerResult, FeatureRecommendation,\n",
    "    CategoricalTargetAnalyzer\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3b0674",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a274bc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T14:17:49.996055Z",
     "iopub.status.busy": "2026-01-22T14:17:49.995907Z",
     "iopub.status.idle": "2026-01-22T14:17:50.128350Z",
     "shell.execute_reply": "2026-01-22T14:17:50.127985Z"
    },
    "papermill": {
     "duration": 0.137314,
     "end_time": "2026-01-22T14:17:50.129422",
     "exception": true,
     "start_time": "2026-01-22T14:17:49.992108",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No findings files found in ../experiments/findings. Run notebook 01 first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m findings_files = [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m FINDINGS_DIR.glob(\u001b[33m\"\u001b[39m\u001b[33m*_findings.yaml\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmulti_dataset\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m f.name]\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m findings_files:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo findings files found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFINDINGS_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Run notebook 01 first.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m findings_files.sort(key=\u001b[38;5;28;01mlambda\u001b[39;00m f: f.stat().st_mtime, reverse=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     11\u001b[39m FINDINGS_PATH = \u001b[38;5;28mstr\u001b[39m(findings_files[\u001b[32m0\u001b[39m])\n",
      "\u001b[31mFileNotFoundError\u001b[39m: No findings files found in ../experiments/findings. Run notebook 01 first."
     ]
    }
   ],
   "source": [
    "# === CONFIGURATION ===\n",
    "from pathlib import Path\n",
    "\n",
    "FINDINGS_DIR = Path(\"../experiments/findings\")\n",
    "\n",
    "findings_files = [f for f in FINDINGS_DIR.glob(\"*_findings.yaml\") if \"multi_dataset\" not in f.name]\n",
    "if not findings_files:\n",
    "    raise FileNotFoundError(f\"No findings files found in {FINDINGS_DIR}. Run notebook 01 first.\")\n",
    "\n",
    "findings_files.sort(key=lambda f: f.stat().st_mtime, reverse=True)\n",
    "FINDINGS_PATH = str(findings_files[0])\n",
    "\n",
    "print(f\"Using: {FINDINGS_PATH}\")\n",
    "findings = ExplorationFindings.load(FINDINGS_PATH)\n",
    "print(f\"Loaded findings for {findings.column_count} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20603e7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get time series configuration\n",
    "ts_meta = findings.time_series_metadata\n",
    "ENTITY_COLUMN = ts_meta.entity_column if ts_meta else None\n",
    "TIME_COLUMN = ts_meta.time_column if ts_meta else None\n",
    "\n",
    "print(f\"Entity column: {ENTITY_COLUMN}\")\n",
    "print(f\"Time column: {TIME_COLUMN}\")\n",
    "\n",
    "# Note: Target column configuration is handled in section 1c.2 below\n",
    "# This allows for event-level to entity-level aggregation when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e2849",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from customer_retention.stages.temporal import load_data_with_snapshot_preference, TEMPORAL_METADATA_COLS\n",
    "\n",
    "# Load source data (prefers snapshots over raw files)\n",
    "df, data_source = load_data_with_snapshot_preference(findings, output_dir=\"../experiments/findings\")\n",
    "charts = ChartBuilder()\n",
    "\n",
    "# Parse time column\n",
    "df[TIME_COLUMN] = pd.to_datetime(df[TIME_COLUMN])\n",
    "\n",
    "print(f\"Loaded {len(df):,} rows x {len(df.columns)} columns\")\n",
    "print(f\"Data source: {data_source}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb43d9b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1c.2 Target Column Configuration\n",
    "\n",
    "**ðŸ“– Event-Level vs Entity-Level Targets:**\n",
    "\n",
    "In time series data, targets can be defined at different granularities:\n",
    "\n",
    "| Target Level | Example | Usage |\n",
    "|--------------|---------|-------|\n",
    "| **Event-level** | \"Did this email get clicked?\" | Exists in raw data |\n",
    "| **Entity-level** | \"Did this customer churn?\" | Need to join from entity table |\n",
    "\n",
    "If your target is entity-level, you may need to join it or configure it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9778704",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === TARGET CONFIGURATION ===\n",
    "# Override these settings to customize target handling\n",
    "\n",
    "# Option 1: Use auto-detected target from findings\n",
    "# TARGET_COLUMN_OVERRIDE = None\n",
    "\n",
    "# Option 2: Specify a different column as target\n",
    "# TARGET_COLUMN_OVERRIDE = \"unsubscribed\"\n",
    "\n",
    "# Option 3: Target will come from another dataset (set in 05_multi_dataset)\n",
    "# TARGET_COLUMN_OVERRIDE = \"DEFER_TO_MULTI_DATASET\"\n",
    "\n",
    "TARGET_COLUMN_OVERRIDE = None  # Change this to override\n",
    "\n",
    "# Aggregation method for event-level targets\n",
    "# Options: \"max\" (any=1 means churned), \"mean\" (proportion), \"last\" (final state), \"sum\" (count)\n",
    "TARGET_AGGREGATION = \"max\"\n",
    "\n",
    "# === AUTO-DETECT TARGET LEVEL ===\n",
    "def detect_target_level(df, target_col, entity_col):\n",
    "    \"\"\"\n",
    "    Detect if target is at event-level or entity-level.\n",
    "    \n",
    "    Returns: (\"entity_level\", None) or (\"event_level\", suggested_aggregation)\n",
    "    \"\"\"\n",
    "    if target_col is None or entity_col is None:\n",
    "        return \"unknown\", None\n",
    "    \n",
    "    if target_col not in df.columns:\n",
    "        return \"missing\", None\n",
    "    \n",
    "    # Check if target varies within entities\n",
    "    target_per_entity = df.groupby(entity_col)[target_col].nunique()\n",
    "    entities_with_variation = (target_per_entity > 1).sum()\n",
    "    total_entities = len(target_per_entity)\n",
    "    variation_pct = entities_with_variation / total_entities * 100 if total_entities > 0 else 0\n",
    "    \n",
    "    # Check value distribution\n",
    "    value_counts = df[target_col].value_counts(normalize=True)\n",
    "    is_binary = len(value_counts) == 2\n",
    "    \n",
    "    # If target is same for all events of an entity, it's entity-level\n",
    "    if variation_pct < 5:  # Less than 5% of entities have variation\n",
    "        return \"entity_level\", None\n",
    "    \n",
    "    # If binary and varies within entities, likely event-level churn indicator\n",
    "    if is_binary and variation_pct > 10:\n",
    "        # Check if it's a \"any positive = churned\" pattern\n",
    "        # (most events are 0, occasional 1)\n",
    "        if value_counts.get(0, 0) > 0.8 or value_counts.get(1, 0) < 0.2:\n",
    "            return \"event_level\", \"max\"\n",
    "    \n",
    "    return \"event_level\", \"max\"\n",
    "\n",
    "# === COMPUTE ENTITY-LEVEL TARGET ===\n",
    "print(\"=\"*70)\n",
    "print(\"TARGET COLUMN ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Determine target column\n",
    "TARGET_COLUMN = None  # Initialize\n",
    "\n",
    "if TARGET_COLUMN_OVERRIDE == \"DEFER_TO_MULTI_DATASET\":\n",
    "    TARGET_COLUMN = None\n",
    "    print(\"\\nâ³ Target deferred to multi-dataset notebook (05)\")\n",
    "    print(\"   Analysis will proceed without target-based comparisons\")\n",
    "elif TARGET_COLUMN_OVERRIDE is not None:\n",
    "    TARGET_COLUMN = TARGET_COLUMN_OVERRIDE\n",
    "    print(f\"\\nðŸ”§ Using override target: {TARGET_COLUMN}\")\n",
    "else:\n",
    "    # Use auto-detected from findings\n",
    "    for col_name, col_info in findings.columns.items():\n",
    "        if col_info.inferred_type == ColumnType.TARGET:\n",
    "            TARGET_COLUMN = col_name\n",
    "            break\n",
    "    \n",
    "    if TARGET_COLUMN:\n",
    "        print(f\"\\nðŸ” Auto-detected target: {TARGET_COLUMN}\")\n",
    "    else:\n",
    "        # Try to find binary columns that could be targets\n",
    "        binary_candidates = []\n",
    "        for col_name, col_info in findings.columns.items():\n",
    "            if col_info.inferred_type == ColumnType.BINARY:\n",
    "                # Check for churn-related names\n",
    "                churn_keywords = ['churn', 'unsub', 'cancel', 'retain', 'active', 'lost', 'leave']\n",
    "                if any(kw in col_name.lower() for kw in churn_keywords):\n",
    "                    binary_candidates.append(col_name)\n",
    "        \n",
    "        if binary_candidates:\n",
    "            TARGET_COLUMN = binary_candidates[0]\n",
    "            print(f\"\\nðŸ” No explicit target detected, using binary candidate: {TARGET_COLUMN}\")\n",
    "            print(f\"   Other candidates: {binary_candidates[1:] if len(binary_candidates) > 1 else 'none'}\")\n",
    "        else:\n",
    "            print(\"\\nðŸ” No target column detected\")\n",
    "\n",
    "# Analyze target level\n",
    "if TARGET_COLUMN and TARGET_COLUMN in df.columns and ENTITY_COLUMN:\n",
    "    target_level, suggested_agg = detect_target_level(df, TARGET_COLUMN, ENTITY_COLUMN)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Target Analysis:\")\n",
    "    print(f\"   Column: {TARGET_COLUMN}\")\n",
    "    print(f\"   Level detected: {target_level.upper()}\")\n",
    "    \n",
    "    if target_level == \"event_level\":\n",
    "        print(f\"\\nâš ï¸  EVENT-LEVEL TARGET DETECTED\")\n",
    "        print(f\"   The target '{TARGET_COLUMN}' varies within entities.\")\n",
    "        print(f\"   This needs to be aggregated to entity-level for proper analysis.\")\n",
    "        \n",
    "        # Show distribution\n",
    "        event_dist = df[TARGET_COLUMN].value_counts()\n",
    "        print(f\"\\n   Event-level distribution:\")\n",
    "        for val, count in event_dist.items():\n",
    "            pct = count / len(df) * 100\n",
    "            print(f\"      {TARGET_COLUMN}={val}: {count:,} events ({pct:.1f}%)\")\n",
    "        \n",
    "        # Compute entity-level target\n",
    "        print(f\"\\n   Aggregating to entity-level using: {TARGET_AGGREGATION}()\")\n",
    "        \n",
    "        if TARGET_AGGREGATION == \"max\":\n",
    "            entity_target = df.groupby(ENTITY_COLUMN)[TARGET_COLUMN].max()\n",
    "        elif TARGET_AGGREGATION == \"mean\":\n",
    "            entity_target = df.groupby(ENTITY_COLUMN)[TARGET_COLUMN].mean()\n",
    "        elif TARGET_AGGREGATION == \"sum\":\n",
    "            entity_target = df.groupby(ENTITY_COLUMN)[TARGET_COLUMN].sum()\n",
    "        elif TARGET_AGGREGATION == \"last\":\n",
    "            entity_target = df.sort_values(TIME_COLUMN).groupby(ENTITY_COLUMN)[TARGET_COLUMN].last()\n",
    "        else:\n",
    "            entity_target = df.groupby(ENTITY_COLUMN)[TARGET_COLUMN].max()\n",
    "        \n",
    "        # Show entity-level distribution\n",
    "        entity_dist = entity_target.value_counts()\n",
    "        print(f\"\\n   Entity-level distribution (after aggregation):\")\n",
    "        for val, count in entity_dist.items():\n",
    "            pct = count / len(entity_target) * 100\n",
    "            label = \"Churned\" if val == 1 else \"Retained\" if val == 0 else str(val)\n",
    "            print(f\"      {label} ({TARGET_COLUMN}={val}): {count:,} entities ({pct:.1f}%)\")\n",
    "        \n",
    "        # Create entity-level target mapping and merge back\n",
    "        entity_target_map = entity_target.reset_index()\n",
    "        entity_target_map.columns = [ENTITY_COLUMN, f\"{TARGET_COLUMN}_entity\"]\n",
    "        df = df.merge(entity_target_map, on=ENTITY_COLUMN, how=\"left\")\n",
    "        \n",
    "        # Update TARGET_COLUMN to use entity-level version\n",
    "        ORIGINAL_TARGET = TARGET_COLUMN\n",
    "        TARGET_COLUMN = f\"{TARGET_COLUMN}_entity\"\n",
    "        print(f\"\\n   âœ“ Created entity-level target: {TARGET_COLUMN}\")\n",
    "        print(f\"   âœ“ Original event-level column preserved: {ORIGINAL_TARGET}\")\n",
    "        \n",
    "    elif target_level == \"entity_level\":\n",
    "        print(f\"\\n   âœ“ Target is already at entity-level (consistent within entities)\")\n",
    "        # Verify it's properly mapped\n",
    "        entity_target = df.groupby(ENTITY_COLUMN)[TARGET_COLUMN].first()\n",
    "        entity_dist = entity_target.value_counts()\n",
    "        print(f\"\\n   Entity-level distribution:\")\n",
    "        for val, count in entity_dist.items():\n",
    "            pct = count / len(entity_target) * 100\n",
    "            label = \"Churned\" if val == 1 else \"Retained\" if val == 0 else str(val)\n",
    "            print(f\"      {label} ({TARGET_COLUMN}={val}): {count:,} entities ({pct:.1f}%)\")\n",
    "\n",
    "elif not TARGET_COLUMN:\n",
    "    print(\"\\n   â„¹ï¸  No target column detected or configured\")\n",
    "    print(\"   Temporal pattern analysis will proceed without target-based comparisons\")\n",
    "    print(\"   To enable comparisons:\")\n",
    "    print(\"   - Set TARGET_COLUMN_OVERRIDE above, or\")\n",
    "    print(\"   - Define target in multi-dataset notebook (05)\")\n",
    "\n",
    "print(\"\\n\" + \"â”€\"*70)\n",
    "print(f\"Final configuration:\")\n",
    "print(f\"   ENTITY_COLUMN: {ENTITY_COLUMN}\")\n",
    "print(f\"   TIME_COLUMN: {TIME_COLUMN}\")\n",
    "print(f\"   TARGET_COLUMN: {TARGET_COLUMN}\")\n",
    "print(\"â”€\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0c1fe4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1c.3 Configure Value Column for Analysis\n",
    "\n",
    "Temporal patterns are analyzed on aggregated metrics. Choose the primary metric to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2537807c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find numeric columns that could be aggregated\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols = [c for c in numeric_cols if c not in [ENTITY_COLUMN]]\n",
    "\n",
    "print(\"Available numeric columns for pattern analysis:\")\n",
    "for col in numeric_cols:\n",
    "    print(f\"   - {col}\")\n",
    "\n",
    "# Default: use event count (most common for pattern detection)\n",
    "# Change this to analyze patterns in a specific metric\n",
    "VALUE_COLUMN = \"_event_count\"  # Special: will aggregate event counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2373f16",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare data for pattern analysis\n",
    "# Aggregate to daily level for trend/seasonality detection\n",
    "\n",
    "if VALUE_COLUMN == \"_event_count\":\n",
    "    # Aggregate event counts by day\n",
    "    daily_data = df.groupby(df[TIME_COLUMN].dt.date).size().reset_index()\n",
    "    daily_data.columns = [TIME_COLUMN, \"value\"]\n",
    "    daily_data[TIME_COLUMN] = pd.to_datetime(daily_data[TIME_COLUMN])\n",
    "    analysis_col = \"value\"\n",
    "    print(\"Analyzing: Daily event counts\")\n",
    "else:\n",
    "    # Aggregate specific column by day\n",
    "    daily_data = df.groupby(df[TIME_COLUMN].dt.date)[VALUE_COLUMN].sum().reset_index()\n",
    "    daily_data.columns = [TIME_COLUMN, \"value\"]\n",
    "    daily_data[TIME_COLUMN] = pd.to_datetime(daily_data[TIME_COLUMN])\n",
    "    analysis_col = \"value\"\n",
    "    print(f\"Analyzing: Daily sum of {VALUE_COLUMN}\")\n",
    "\n",
    "print(f\"\\nDaily data points: {len(daily_data)}\")\n",
    "print(f\"Date range: {daily_data[TIME_COLUMN].min()} to {daily_data[TIME_COLUMN].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39593f1a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1c.4 Trend Detection\n",
    "\n",
    "**ðŸ“– Understanding Trends:**\n",
    "- **Increasing**: Metric growing over time (e.g., expanding customer base)\n",
    "- **Decreasing**: Metric shrinking (e.g., declining engagement)\n",
    "- **Stationary**: No significant trend (stable business)\n",
    "\n",
    "**Impact on ML:**\n",
    "- Strong trends can cause data leakage if not handled\n",
    "- Consider detrending or adding trend as explicit feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24262efc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run trend detection\n",
    "analyzer = TemporalPatternAnalyzer(time_column=TIME_COLUMN)\n",
    "trend_result = analyzer.detect_trend(daily_data, value_column=analysis_col)\n",
    "\n",
    "print(\"\\U0001f4c8 TREND ANALYSIS RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "direction_emoji = {\n",
    "    TrendDirection.INCREASING: \"\\U0001f4c8\",\n",
    "    TrendDirection.DECREASING: \"\\U0001f4c9\",\n",
    "    TrendDirection.STABLE: \"\\u27a1\\ufe0f\",\n",
    "    TrendDirection.UNKNOWN: \"\\u2753\",\n",
    "}\n",
    "\n",
    "print(f\"\\n   Direction: {direction_emoji.get(trend_result.direction, '')} {trend_result.direction.value.upper()}\")\n",
    "print(f\"   Strength (R\\u00b2): {trend_result.strength:.3f}\")\n",
    "print(f\"   Confidence: {trend_result.confidence.upper()}\")\n",
    "\n",
    "if trend_result.slope is not None:\n",
    "    print(f\"   Slope: {trend_result.slope:.4f} per day\")\n",
    "    # Interpret slope\n",
    "    mean_val = daily_data[analysis_col].mean()\n",
    "    daily_pct_change = (trend_result.slope / mean_val) * 100 if mean_val != 0 else 0\n",
    "    print(f\"   Daily % change: {daily_pct_change:+.3f}%\")\n",
    "\n",
    "if trend_result.p_value is not None:\n",
    "    print(f\"   P-value: {trend_result.p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724178fe",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize trend\n",
    "fig = go.Figure()\n",
    "\n",
    "# Actual data\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=daily_data[TIME_COLUMN],\n",
    "    y=daily_data[analysis_col],\n",
    "    mode=\"lines\",\n",
    "    name=\"Daily Values\",\n",
    "    line=dict(color=\"steelblue\", width=1),\n",
    "    opacity=0.7\n",
    "))\n",
    "\n",
    "# Add trend line\n",
    "if trend_result.slope is not None:\n",
    "    x_numeric = (daily_data[TIME_COLUMN] - daily_data[TIME_COLUMN].min()).dt.days\n",
    "    y_trend = trend_result.slope * x_numeric + (\n",
    "        daily_data[analysis_col].mean() - trend_result.slope * x_numeric.mean()\n",
    "    )\n",
    "    \n",
    "    trend_color = {\n",
    "        TrendDirection.INCREASING: \"green\",\n",
    "        TrendDirection.DECREASING: \"red\",\n",
    "        TrendDirection.STABLE: \"gray\",\n",
    "        TrendDirection.UNKNOWN: \"gray\",\n",
    "    }.get(trend_result.direction, \"gray\")\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=daily_data[TIME_COLUMN],\n",
    "        y=y_trend,\n",
    "        mode=\"lines\",\n",
    "        name=f\"Trend ({trend_result.direction.value})\",\n",
    "        line=dict(color=trend_color, width=3, dash=\"dash\")\n",
    "    ))\n",
    "\n",
    "# Add rolling average for smoothing\n",
    "rolling_avg = daily_data[analysis_col].rolling(window=7, center=True).mean()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=daily_data[TIME_COLUMN],\n",
    "    y=rolling_avg,\n",
    "    mode=\"lines\",\n",
    "    name=\"7-day Rolling Avg\",\n",
    "    line=dict(color=\"orange\", width=2)\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Trend Analysis: {trend_result.direction.value.title()} (R\\u00b2={trend_result.strength:.2f}, {trend_result.confidence} confidence)\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Value\",\n",
    "    template=\"plotly_white\",\n",
    "    height=450,\n",
    "    legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01)\n",
    ")\n",
    "display_figure(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aba437",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1c.5 Seasonality Detection\n",
    "\n",
    "**ðŸ“– Understanding Seasonality:**\n",
    "- **Weekly** (period=7): Higher activity on certain days\n",
    "- **Monthly** (period~30): End-of-month patterns, billing cycles\n",
    "- **Quarterly** (period~90): Business cycles, seasonal products\n",
    "\n",
    "**Impact on ML:**\n",
    "- Add day-of-week, month features\n",
    "- Consider seasonal decomposition\n",
    "- Use cyclical encodings (sin/cos) for neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b75611",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run seasonality detection\n",
    "seasonality_results = analyzer.detect_seasonality(daily_data, value_column=analysis_col)\n",
    "\n",
    "print(\"\\U0001f501 SEASONALITY ANALYSIS RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if seasonality_results:\n",
    "    print(f\"\\n   Detected {len(seasonality_results)} seasonal pattern(s):\\n\")\n",
    "    \n",
    "    for i, sr in enumerate(seasonality_results, 1):\n",
    "        strength_label = \"Strong\" if sr.strength > 0.5 else \"Moderate\" if sr.strength > 0.3 else \"Weak\"\n",
    "        period_name = sr.period_name or f\"{sr.period}-day\"\n",
    "        print(f\"   {i}. {period_name.title()} Pattern\")\n",
    "        print(f\"      Period: {sr.period} days\")\n",
    "        print(f\"      Strength: {sr.strength:.3f} ({strength_label})\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"\\n   No significant seasonal patterns detected.\")\n",
    "    print(\"   This could mean:\")\n",
    "    print(\"   - Data is truly non-seasonal\")\n",
    "    print(\"   - Not enough data points for detection\")\n",
    "    print(\"   - High noise obscuring patterns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0232b86e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize day-of-week pattern\n",
    "daily_data[\"day_of_week\"] = daily_data[TIME_COLUMN].dt.day_name()\n",
    "dow_order = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "daily_data[\"day_of_week\"] = pd.Categorical(daily_data[\"day_of_week\"], categories=dow_order, ordered=True)\n",
    "\n",
    "dow_stats = daily_data.groupby(\"day_of_week\")[analysis_col].agg([\"mean\", \"std\"]).reset_index()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=dow_stats[\"day_of_week\"],\n",
    "    y=dow_stats[\"mean\"],\n",
    "    error_y=dict(type=\"data\", array=dow_stats[\"std\"]),\n",
    "    name=\"Mean\",\n",
    "    marker_color=\"steelblue\"\n",
    "))\n",
    "\n",
    "# Mark weekends\n",
    "for i, day in enumerate(dow_stats[\"day_of_week\"]):\n",
    "    if day in [\"Saturday\", \"Sunday\"]:\n",
    "        fig.add_vrect(\n",
    "            x0=i-0.4, x1=i+0.4,\n",
    "            fillcolor=\"lightgray\", opacity=0.3,\n",
    "            layer=\"below\", line_width=0\n",
    "        )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Day of Week Pattern (gray = weekend)\",\n",
    "    xaxis_title=\"Day of Week\",\n",
    "    yaxis_title=\"Average Value\",\n",
    "    template=\"plotly_white\",\n",
    "    height=400\n",
    ")\n",
    "display_figure(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153f4bec",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Monthly pattern analysis\n",
    "daily_data[\"month\"] = daily_data[TIME_COLUMN].dt.month_name()\n",
    "month_order = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n",
    "               \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "\n",
    "# Only include months present in data\n",
    "present_months = [m for m in month_order if m in daily_data[\"month\"].values]\n",
    "daily_data[\"month\"] = pd.Categorical(daily_data[\"month\"], categories=present_months, ordered=True)\n",
    "\n",
    "monthly_stats = daily_data.groupby(\"month\")[analysis_col].agg([\"mean\", \"std\"]).reset_index()\n",
    "\n",
    "if len(monthly_stats) > 1:\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=monthly_stats[\"month\"],\n",
    "        y=monthly_stats[\"mean\"],\n",
    "        error_y=dict(type=\"data\", array=monthly_stats[\"std\"]),\n",
    "        name=\"Mean\",\n",
    "        marker_color=\"mediumpurple\"\n",
    "    ))\n",
    "    \n",
    "    # Add overall mean line\n",
    "    overall_mean = daily_data[analysis_col].mean()\n",
    "    fig.add_hline(y=overall_mean, line_dash=\"dash\", line_color=\"red\",\n",
    "                  annotation_text=f\"Overall Mean: {overall_mean:.1f}\",\n",
    "                  annotation_position=\"top right\")\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Monthly Pattern\",\n",
    "        xaxis_title=\"Month\",\n",
    "        yaxis_title=\"Average Value\",\n",
    "        template=\"plotly_white\",\n",
    "        height=400\n",
    "    )\n",
    "    display_figure(fig)\n",
    "else:\n",
    "    print(\"Not enough months of data for monthly pattern analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921cda5e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1c.6 Cohort Analysis\n",
    "\n",
    "**\\U0001f4d6 Understanding Cohorts:**\n",
    "- Group entities by when they first appeared (signup cohort)\n",
    "- Compare behavior across cohorts\n",
    "- Identify if acquisition quality changed over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db31c67",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cohort analysis requires entity column\n",
    "if ENTITY_COLUMN:\n",
    "    # Define cohort as the month of first event\n",
    "    first_events = df.groupby(ENTITY_COLUMN)[TIME_COLUMN].min().reset_index()\n",
    "    first_events.columns = [ENTITY_COLUMN, \"first_event\"]\n",
    "    first_events[\"cohort\"] = first_events[\"first_event\"].dt.to_period(\"M\")\n",
    "    \n",
    "    # Merge cohort info back to main data\n",
    "    df_cohort = df.merge(first_events[[ENTITY_COLUMN, \"cohort\"]], on=ENTITY_COLUMN)\n",
    "    \n",
    "    # Cohort-level analysis\n",
    "    cohort_result = analyzer.analyze_cohorts(\n",
    "        df,\n",
    "        entity_column=ENTITY_COLUMN,\n",
    "        cohort_column=TIME_COLUMN,  # Will use min event date as cohort\n",
    "        target_column=TARGET_COLUMN,\n",
    "        period=\"M\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\U0001f465 COHORT ANALYSIS RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"\\n   Cohorts identified: {len(cohort_result)}\")\n",
    "    \n",
    "    if len(cohort_result) > 0:\n",
    "        display_table(cohort_result.head(12))\n",
    "else:\n",
    "    print(\"Entity column not set - skipping cohort analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44fac09",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize cohort sizes and retention\n",
    "if ENTITY_COLUMN and len(cohort_result) > 0:\n",
    "    cohort_result_sorted = cohort_result.sort_values(\"cohort\")\n",
    "    \n",
    "    # Compute retention rate if not present but target exists\n",
    "    if \"retention_rate\" not in cohort_result.columns and TARGET_COLUMN and TARGET_COLUMN in df.columns:\n",
    "        # Calculate retention rate per cohort from raw data\n",
    "        entity_cohort = first_events[[ENTITY_COLUMN, \"cohort\"]]\n",
    "        entity_target = df.groupby(ENTITY_COLUMN)[TARGET_COLUMN].first().reset_index()\n",
    "        cohort_target = entity_cohort.merge(entity_target, on=ENTITY_COLUMN)\n",
    "        \n",
    "        retention_by_cohort = cohort_target.groupby(\"cohort\")[TARGET_COLUMN].mean().reset_index()\n",
    "        retention_by_cohort.columns = [\"cohort\", \"retention_rate\"]\n",
    "        \n",
    "        cohort_result_sorted = cohort_result_sorted.merge(retention_by_cohort, on=\"cohort\", how=\"left\")\n",
    "    \n",
    "    # Decide layout based on available data\n",
    "    has_retention = \"retention_rate\" in cohort_result_sorted.columns and cohort_result_sorted[\"retention_rate\"].notna().any()\n",
    "    \n",
    "    if has_retention:\n",
    "        fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Cohort Sizes\", \"Retention Rate by Cohort\"))\n",
    "        \n",
    "        # Cohort sizes\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=cohort_result_sorted[\"cohort\"].astype(str),\n",
    "                y=cohort_result_sorted[\"entity_count\"],\n",
    "                name=\"Entities\",\n",
    "                marker_color=\"steelblue\"\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Retention rate\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=cohort_result_sorted[\"cohort\"].astype(str),\n",
    "                y=cohort_result_sorted[\"retention_rate\"] * 100,\n",
    "                mode=\"lines+markers\",\n",
    "                name=\"Retention %\",\n",
    "                line=dict(color=\"green\", width=2),\n",
    "                marker=dict(size=8)\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        fig.update_yaxes(title_text=\"Entity Count\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"Retention %\", row=1, col=2)\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=\"Cohort Overview\",\n",
    "            template=\"plotly_white\",\n",
    "            height=400,\n",
    "            showlegend=False\n",
    "        )\n",
    "    else:\n",
    "        # Single chart - cohort sizes only\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=cohort_result_sorted[\"cohort\"].astype(str),\n",
    "                y=cohort_result_sorted[\"entity_count\"],\n",
    "                name=\"Entities\",\n",
    "                marker_color=\"steelblue\",\n",
    "                text=cohort_result_sorted[\"entity_count\"],\n",
    "                textposition=\"outside\"\n",
    "            )\n",
    "        )\n",
    "        fig.update_layout(\n",
    "            title=\"Cohort Sizes (No target column for retention analysis)\",\n",
    "            xaxis_title=\"Cohort\",\n",
    "            yaxis_title=\"Entity Count\",\n",
    "            template=\"plotly_white\",\n",
    "            height=400\n",
    "        )\n",
    "        print(\"ðŸ’¡ Tip: Set TARGET_COLUMN to see retention rates by cohort\")\n",
    "    \n",
    "    fig.update_xaxes(tickangle=45)\n",
    "    display_figure(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0c54c2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1c.7 Recency Analysis\n",
    "\n",
    "**\\U0001f4d6 Understanding Recency:**\n",
    "- Time since last event for each entity\n",
    "- Often strongly correlated with churn/retention\n",
    "- Key feature for predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95048b4c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run recency analysis\n",
    "if ENTITY_COLUMN:\n",
    "    recency_result = analyzer.analyze_recency(\n",
    "        df,\n",
    "        entity_column=ENTITY_COLUMN,\n",
    "        target_column=TARGET_COLUMN,\n",
    "        reference_date=df[TIME_COLUMN].max()  # Use latest date in data as reference\n",
    "    )\n",
    "    \n",
    "    print(\"\\u23f1\\ufe0f  RECENCY ANALYSIS RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"\\n   Reference date: {df[TIME_COLUMN].max()}\")\n",
    "    print(f\"\\n   Recency Statistics (days since last event):\")\n",
    "    print(f\"      Mean: {recency_result.avg_recency_days:.1f}\")\n",
    "    print(f\"      Median: {recency_result.median_recency_days:.1f}\")\n",
    "    print(f\"      Min: {recency_result.min_recency_days:.1f}\")\n",
    "    print(f\"      Max: {recency_result.max_recency_days:.1f}\")\n",
    "    \n",
    "    if recency_result.target_correlation is not None:\n",
    "        corr = recency_result.target_correlation\n",
    "        corr_strength = \"Strong\" if abs(corr) > 0.5 else \"Moderate\" if abs(corr) > 0.3 else \"Weak\"\n",
    "        corr_direction = \"negative\" if corr < 0 else \"positive\"\n",
    "        \n",
    "        print(f\"\\n   \\U0001f3af Target Correlation:\")\n",
    "        print(f\"      Correlation: {corr:.3f}\")\n",
    "        print(f\"      Interpretation: {corr_strength} {corr_direction} correlation\")\n",
    "        \n",
    "        if corr < -0.3:\n",
    "            print(f\"      \\U0001f4a1 Insight: Lower recency (recent activity) associates with higher target\")\n",
    "            print(f\"         This suggests recency is a strong predictor - use in features!\")\n",
    "        elif corr > 0.3:\n",
    "            print(f\"      \\U0001f4a1 Insight: Higher recency (longer since last event) associates with higher target\")\n",
    "else:\n",
    "    print(\"Entity column not set - skipping recency analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2ac006",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize recency distribution - COMPARING RETAINED VS CHURNED\n",
    "if ENTITY_COLUMN:\n",
    "    # Compute recency for each entity\n",
    "    reference_date = df[TIME_COLUMN].max()\n",
    "    entity_last = df.groupby(ENTITY_COLUMN)[TIME_COLUMN].max().reset_index()\n",
    "    entity_last[\"recency_days\"] = (reference_date - entity_last[TIME_COLUMN]).dt.days\n",
    "    \n",
    "    # Add target for comparison\n",
    "    if TARGET_COLUMN and TARGET_COLUMN in df.columns:\n",
    "        entity_target = df.groupby(ENTITY_COLUMN)[TARGET_COLUMN].first().reset_index()\n",
    "        entity_recency = entity_last.merge(entity_target, on=ENTITY_COLUMN)\n",
    "        has_target = True\n",
    "    else:\n",
    "        entity_recency = entity_last.copy()\n",
    "        has_target = False\n",
    "    \n",
    "    # Cap for visualization\n",
    "    cap = entity_recency[\"recency_days\"].quantile(0.99)\n",
    "    entity_recency_capped = entity_recency[entity_recency[\"recency_days\"] <= cap]\n",
    "    \n",
    "    if has_target:\n",
    "        # SIDE-BY-SIDE COMPARISON: Retained vs Churned\n",
    "        print(\"=\"*70)\n",
    "        print(\"RECENCY DISTRIBUTION: Retained vs Churned Comparison\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        retained_recency = entity_recency_capped[entity_recency_capped[TARGET_COLUMN] == 1][\"recency_days\"]\n",
    "        churned_recency = entity_recency_capped[entity_recency_capped[TARGET_COLUMN] == 0][\"recency_days\"]\n",
    "        \n",
    "        fig = make_subplots(\n",
    "            rows=1, cols=2,\n",
    "            subplot_titles=[\n",
    "                f\"ðŸŸ¢ RETAINED (n={len(retained_recency):,})\",\n",
    "                f\"ðŸ”´ CHURNED (n={len(churned_recency):,})\"\n",
    "            ],\n",
    "            horizontal_spacing=0.1\n",
    "        )\n",
    "        \n",
    "        # Retained histogram\n",
    "        fig.add_trace(go.Histogram(\n",
    "            x=retained_recency,\n",
    "            nbinsx=30,\n",
    "            name=\"Retained\",\n",
    "            marker_color=\"rgba(46, 204, 113, 0.7)\",\n",
    "            showlegend=False\n",
    "        ), row=1, col=1)\n",
    "        \n",
    "        # Churned histogram\n",
    "        fig.add_trace(go.Histogram(\n",
    "            x=churned_recency,\n",
    "            nbinsx=30,\n",
    "            name=\"Churned\",\n",
    "            marker_color=\"rgba(231, 76, 60, 0.7)\",\n",
    "            showlegend=False\n",
    "        ), row=1, col=2)\n",
    "        \n",
    "        # Add median lines\n",
    "        fig.add_vline(x=retained_recency.median(), line_dash=\"solid\", line_color=\"green\",\n",
    "                      annotation_text=f\"Med: {retained_recency.median():.0f}d\", row=1, col=1)\n",
    "        fig.add_vline(x=churned_recency.median(), line_dash=\"solid\", line_color=\"red\",\n",
    "                      annotation_text=f\"Med: {churned_recency.median():.0f}d\", row=1, col=2)\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=\"Recency Distribution: Compare Shape and Median Between Groups\",\n",
    "            template=\"plotly_white\",\n",
    "            height=400\n",
    "        )\n",
    "        fig.update_xaxes(title_text=\"Days Since Last Event\", row=1, col=1)\n",
    "        fig.update_xaxes(title_text=\"Days Since Last Event\", row=1, col=2)\n",
    "        fig.update_yaxes(title_text=\"Number of Entities\", row=1, col=1)\n",
    "        \n",
    "        display_figure(fig)\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(\"\\nðŸ“Š Recency Statistics by Retention Status:\")\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"{'Metric':<20} {'Retained':>15} {'Churned':>15} {'Difference':>15}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        metrics = [\n",
    "            (\"Mean\", retained_recency.mean(), churned_recency.mean()),\n",
    "            (\"Median\", retained_recency.median(), churned_recency.median()),\n",
    "            (\"Std Dev\", retained_recency.std(), churned_recency.std()),\n",
    "            (\"25th Percentile\", retained_recency.quantile(0.25), churned_recency.quantile(0.25)),\n",
    "            (\"75th Percentile\", retained_recency.quantile(0.75), churned_recency.quantile(0.75)),\n",
    "        ]\n",
    "        \n",
    "        for name, ret_val, churn_val in metrics:\n",
    "            diff = ret_val - churn_val\n",
    "            print(f\"{name:<20} {ret_val:>15.1f} {churn_val:>15.1f} {diff:>+15.1f}\")\n",
    "        \n",
    "        # Calculate effect size for recency\n",
    "        pooled_std = np.sqrt((retained_recency.var() + churned_recency.var()) / 2)\n",
    "        if pooled_std > 0:\n",
    "            cohens_d = (retained_recency.mean() - churned_recency.mean()) / pooled_std\n",
    "        else:\n",
    "            cohens_d = 0\n",
    "        \n",
    "        abs_d = abs(cohens_d)\n",
    "        if abs_d >= 0.8:\n",
    "            effect_interp = \"Large effect\"\n",
    "        elif abs_d >= 0.5:\n",
    "            effect_interp = \"Medium effect\"\n",
    "        elif abs_d >= 0.2:\n",
    "            effect_interp = \"Small effect\"\n",
    "        else:\n",
    "            effect_interp = \"Negligible\"\n",
    "        \n",
    "        print(f\"\\nðŸ“ˆ Effect Size (Cohen's d): {cohens_d:+.3f} ({effect_interp})\")\n",
    "        \n",
    "        # INTERPRETATION\n",
    "        print(\"\\n\" + \"â”€\"*70)\n",
    "        print(\"ðŸ“– HOW TO INTERPRET RECENCY COMPARISON\")\n",
    "        print(\"â”€\"*70)\n",
    "        if churned_recency.median() > retained_recency.median():\n",
    "            print(\"\"\"\n",
    "Key Finding: Churned customers have HIGHER recency (more days since last event)\n",
    "\n",
    "This is a classic churn pattern - customers who leave typically show:\n",
    "  â€¢ Longer gaps between activities before churning\n",
    "  â€¢ Declining engagement over time\n",
    "  â€¢ Last activity farther from observation date\n",
    "\n",
    "Feature Engineering Recommendations:\n",
    "  â€¢ days_since_last_event (recency as-is)\n",
    "  â€¢ log_recency (if distribution is skewed)\n",
    "  â€¢ recency_bucket (categorical: 0-7d, 8-30d, 31-90d, >90d)\n",
    "  â€¢ is_recent_active (binary: recency < 30 days)\n",
    "\"\"\")\n",
    "        else:\n",
    "            print(\"\"\"\n",
    "Observation: Retained customers have similar or higher recency than churned\n",
    "\n",
    "This is unusual - investigate whether:\n",
    "  â€¢ Churn is happening very quickly (new customers leaving fast)\n",
    "  â€¢ There's a time window issue in the data\n",
    "  â€¢ Target definition may need review\n",
    "\"\"\")\n",
    "        \n",
    "    else:\n",
    "        # Single distribution (no target)\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Histogram(\n",
    "            x=entity_recency_capped[\"recency_days\"],\n",
    "            nbinsx=50,\n",
    "            name=\"Recency\",\n",
    "            marker_color=\"coral\",\n",
    "            opacity=0.7\n",
    "        ))\n",
    "        \n",
    "        fig.add_vline(x=recency_result.median_recency_days, line_dash=\"solid\", line_color=\"green\",\n",
    "                      annotation_text=f\"Median: {recency_result.median_recency_days:.0f} days\",\n",
    "                      annotation_position=\"top right\")\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=f\"Recency Distribution (capped at {cap:.0f} days = 99th percentile)\",\n",
    "            xaxis_title=\"Days Since Last Event\",\n",
    "            yaxis_title=\"Number of Entities\",\n",
    "            template=\"plotly_white\",\n",
    "            height=400\n",
    "        )\n",
    "        display_figure(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb415732",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Recency vs Target visualization (if target exists)\n",
    "if ENTITY_COLUMN and TARGET_COLUMN and TARGET_COLUMN in df.columns:\n",
    "    # Get target per entity\n",
    "    entity_target = df.groupby(ENTITY_COLUMN)[TARGET_COLUMN].first().reset_index()\n",
    "    \n",
    "    # Merge with recency\n",
    "    recency_target = entity_last.merge(entity_target, on=ENTITY_COLUMN)\n",
    "    \n",
    "    # Bin recency for clearer visualization\n",
    "    recency_target[\"recency_bin\"] = pd.cut(\n",
    "        recency_target[\"recency_days\"],\n",
    "        bins=[0, 7, 30, 90, 180, float(\"inf\")],\n",
    "        labels=[\"0-7d\", \"8-30d\", \"31-90d\", \"91-180d\", \">180d\"]\n",
    "    )\n",
    "    \n",
    "    # Target rate by recency bin\n",
    "    target_by_recency = recency_target.groupby(\"recency_bin\")[TARGET_COLUMN].agg([\"mean\", \"count\"]).reset_index()\n",
    "    \n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=target_by_recency[\"recency_bin\"].astype(str),\n",
    "            y=target_by_recency[\"count\"],\n",
    "            name=\"Entity Count\",\n",
    "            marker_color=\"lightsteelblue\",\n",
    "            opacity=0.7\n",
    "        ),\n",
    "        secondary_y=False\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=target_by_recency[\"recency_bin\"].astype(str),\n",
    "            y=target_by_recency[\"mean\"] * 100,\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Target Rate %\",\n",
    "            line=dict(color=\"red\", width=3),\n",
    "            marker=dict(size=10)\n",
    "        ),\n",
    "        secondary_y=True\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Target Rate by Recency Bucket\",\n",
    "        xaxis_title=\"Days Since Last Event\",\n",
    "        template=\"plotly_white\",\n",
    "        height=450\n",
    "    )\n",
    "    fig.update_yaxes(title_text=\"Entity Count\", secondary_y=False)\n",
    "    fig.update_yaxes(title_text=\"Target Rate %\", secondary_y=True)\n",
    "    \n",
    "    display_figure(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1d4f69",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1c.8 Feature Correlations and Relationships\n",
    "\n",
    "**ðŸ“– Understanding Feature Relationships in Event Data:**\n",
    "- **Correlation Matrix**: Identify redundant features (multicollinearity)\n",
    "- **Effect Sizes**: How well features discriminate by target (if available)\n",
    "- **CramÃ©r's V**: Association strength for categorical features\n",
    "\n",
    "These analyses parallel the standard track (notebook 04) but applied to event-level attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b40bfcf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Correlation matrix for numeric event attributes\n",
    "numeric_event_cols = [c for c in df.select_dtypes(include=[np.number]).columns \n",
    "                      if c not in [ENTITY_COLUMN, TARGET_COLUMN]]\n",
    "\n",
    "if len(numeric_event_cols) >= 2:\n",
    "    corr_matrix = df[numeric_event_cols].corr()\n",
    "    fig = charts.heatmap(\n",
    "        corr_matrix.values, x_labels=numeric_event_cols, y_labels=numeric_event_cols,\n",
    "        title=\"Event Attribute Correlation Matrix\"\n",
    "    )\n",
    "    display_figure(fig)\n",
    "    \n",
    "    # High correlation pairs (multicollinearity detection)\n",
    "    high_corr_pairs = []\n",
    "    for i in range(len(numeric_event_cols)):\n",
    "        for j in range(i+1, len(numeric_event_cols)):\n",
    "            corr_val = corr_matrix.iloc[i, j]\n",
    "            if abs(corr_val) >= 0.7:\n",
    "                high_corr_pairs.append({\n",
    "                    \"Column 1\": numeric_event_cols[i], \"Column 2\": numeric_event_cols[j],\n",
    "                    \"Correlation\": f\"{corr_val:.3f}\"\n",
    "                })\n",
    "    \n",
    "    if high_corr_pairs:\n",
    "        print(\"âš ï¸ High Correlation Pairs (|r| >= 0.7):\")\n",
    "        display_table(pd.DataFrame(high_corr_pairs))\n",
    "    else:\n",
    "        print(\"âœ“ No high correlation pairs detected (multicollinearity not a concern)\")\n",
    "else:\n",
    "    print(\"Not enough numeric columns for correlation analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb378207",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Categorical feature analysis using CramÃ©r's V (if target exists at entity level)\n",
    "categorical_cols = [c for c in df.select_dtypes(include=['object', 'category']).columns \n",
    "                    if c not in [ENTITY_COLUMN, TIME_COLUMN]]\n",
    "\n",
    "if categorical_cols and ENTITY_COLUMN:\n",
    "    print(\"=\"*70)\n",
    "    print(\"CATEGORICAL FEATURE ANALYSIS (CramÃ©r's V)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # For event data, aggregate to entity level first (mode category per entity)\n",
    "    entity_cats = df.groupby(ENTITY_COLUMN)[categorical_cols].agg(lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else None)\n",
    "    \n",
    "    if TARGET_COLUMN and TARGET_COLUMN in df.columns:\n",
    "        entity_target = df.groupby(ENTITY_COLUMN)[TARGET_COLUMN].first()\n",
    "        entity_data = entity_cats.join(entity_target)\n",
    "        \n",
    "        overall_retention = entity_data[TARGET_COLUMN].mean()\n",
    "        print(f\"\\nOverall retention rate: {overall_retention:.1%}\")\n",
    "        \n",
    "        cat_analyzer = CategoricalTargetAnalyzer(min_samples_per_category=10)\n",
    "        cat_summary = cat_analyzer.analyze_multiple(entity_data.reset_index(), categorical_cols, TARGET_COLUMN)\n",
    "        \n",
    "        print(\"\\nðŸ“Š Categorical Feature Strength:\")\n",
    "        print(f\"{'Feature':<25} {'CramÃ©r V':>10} {'Strength':<12} {'Significance'}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for _, row in cat_summary.iterrows():\n",
    "            strength = \"Strong\" if row[\"cramers_v\"] >= 0.3 else \"Moderate\" if row[\"cramers_v\"] >= 0.1 else \"Weak\"\n",
    "            sig = \"***\" if row[\"p_value\"] < 0.001 else \"**\" if row[\"p_value\"] < 0.01 else \"*\" if row[\"p_value\"] < 0.05 else \"\"\n",
    "            print(f\"{row['feature'][:24]:<25} {row['cramers_v']:>10.3f} {strength:<12} {sig}\")\n",
    "        \n",
    "        # Detailed analysis for top categorical features\n",
    "        for col_name in categorical_cols[:3]:\n",
    "            result = cat_analyzer.analyze(entity_data.reset_index(), col_name, TARGET_COLUMN)\n",
    "            \n",
    "            if len(result.category_stats) > 0:\n",
    "                print(f\"\\n{'â”€'*60}\")\n",
    "                print(f\"ðŸ“Š {col_name.upper()} - Retention by Category\")\n",
    "                print(\"â”€\"*60)\n",
    "                \n",
    "                cat_stats = result.category_stats\n",
    "                categories = cat_stats['category'].tolist()\n",
    "                retained_counts = cat_stats['retained_count'].tolist()\n",
    "                churned_counts = cat_stats['churned_count'].tolist()\n",
    "                \n",
    "                # Stacked bar chart\n",
    "                fig = go.Figure()\n",
    "                fig.add_trace(go.Bar(\n",
    "                    name='Retained', x=categories, y=retained_counts,\n",
    "                    marker_color='rgba(46, 204, 113, 0.8)',\n",
    "                    text=[f\"{r/(r+c)*100:.0f}%\" for r, c in zip(retained_counts, churned_counts)],\n",
    "                    textposition='inside', textfont=dict(color='white', size=12)\n",
    "                ))\n",
    "                fig.add_trace(go.Bar(\n",
    "                    name='Churned', x=categories, y=churned_counts,\n",
    "                    marker_color='rgba(231, 76, 60, 0.8)',\n",
    "                ))\n",
    "                fig.update_layout(\n",
    "                    barmode='stack', title=f\"Retention by {col_name}\",\n",
    "                    template='plotly_white', height=350,\n",
    "                    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"center\", x=0.5)\n",
    "                )\n",
    "                display_figure(fig)\n",
    "                \n",
    "                # High-risk categories\n",
    "                if result.high_risk_categories:\n",
    "                    print(f\"\\nâš ï¸ High-risk categories (below average retention):\")\n",
    "                    for cat in result.high_risk_categories[:3]:\n",
    "                        cat_row = cat_stats[cat_stats['category'] == cat].iloc[0]\n",
    "                        print(f\"   â€¢ {cat}: {cat_row['retention_rate']:.1%} retention ({cat_row['lift']:.2f}x lift)\")\n",
    "        \n",
    "        # INTERPRETATION\n",
    "        print(\"\\n\" + \"â”€\"*70)\n",
    "        print(\"ðŸ“– INTERPRETING CRAMÃ‰R'S V\")\n",
    "        print(\"â”€\"*70)\n",
    "        print(\"\"\"\n",
    "CramÃ©r's V measures association strength for categorical variables:\n",
    "  V â‰¥ 0.3:  Strong association\n",
    "  V 0.1-0.3: Moderate association\n",
    "  V < 0.1:  Weak association\n",
    "\n",
    "Significance: *** p<0.001, ** p<0.01, * p<0.05\n",
    "\n",
    "High-risk categories (lift < 0.9x overall retention):\n",
    "  â†’ Target for retention campaigns\n",
    "  â†’ Investigate why these segments churn more\n",
    "\"\"\")\n",
    "    else:\n",
    "        print(\"\\nCategorical columns found but no target for association analysis\")\n",
    "        print(f\"  Columns: {categorical_cols}\")\n",
    "elif not categorical_cols:\n",
    "    print(\"No categorical columns found for CramÃ©r's V analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523dc35d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1c.9 Entity-Level Feature Analysis (Effect Sizes)\n",
    "\n",
    "**ðŸ“– Why Aggregate to Entity Level:**\n",
    "- Time series data has multiple events per entity\n",
    "- Target variable (retention) is typically at entity level\n",
    "- Effect sizes (Cohen's d) require entity-level comparison\n",
    "\n",
    "**Effect Size Interpretation (Cohen's d):**\n",
    "\n",
    "| |d| | Interpretation | Predictive Power | Action |\n",
    "|-----|----------------|------------------|--------|\n",
    "| â‰¥ 0.8 | Large | Strong discriminator | Priority feature - include in model |\n",
    "| 0.5-0.8 | Medium | Useful predictor | Include in model |\n",
    "| 0.2-0.5 | Small | Weak signal | May help in combination |\n",
    "| < 0.2 | Negligible | Limited value alone | Consider dropping or engineering |\n",
    "\n",
    "**Direction matters:**\n",
    "- **Positive d**: Retained customers have HIGHER values\n",
    "- **Negative d**: Retained customers have LOWER values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d7f9c9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Aggregate event data to entity level for effect size analysis\n",
    "if ENTITY_COLUMN and TARGET_COLUMN and TARGET_COLUMN in df.columns:\n",
    "    # Build entity-level aggregations\n",
    "    entity_aggs = df.groupby(ENTITY_COLUMN).agg({\n",
    "        TIME_COLUMN: ['count', 'min', 'max'],\n",
    "        **{col: ['mean', 'sum', 'std'] for col in numeric_event_cols if col != TARGET_COLUMN}\n",
    "    })\n",
    "    entity_aggs.columns = ['_'.join(col).strip() for col in entity_aggs.columns]\n",
    "    entity_aggs = entity_aggs.reset_index()\n",
    "    \n",
    "    # Add target\n",
    "    entity_target = df.groupby(ENTITY_COLUMN)[TARGET_COLUMN].first().reset_index()\n",
    "    entity_df = entity_aggs.merge(entity_target, on=ENTITY_COLUMN)\n",
    "    \n",
    "    # Add derived features\n",
    "    entity_df['tenure_days'] = (entity_df[f'{TIME_COLUMN}_max'] - entity_df[f'{TIME_COLUMN}_min']).dt.days\n",
    "    entity_df['event_count'] = entity_df[f'{TIME_COLUMN}_count']\n",
    "    \n",
    "    # Calculate effect sizes (Cohen's d) for entity-level features\n",
    "    effect_feature_cols = [c for c in entity_df.select_dtypes(include=[np.number]).columns\n",
    "                          if c not in [ENTITY_COLUMN, TARGET_COLUMN]]\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ENTITY-LEVEL FEATURE EFFECT SIZES (Cohen's d)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nAnalyzing {len(effect_feature_cols)} aggregated features at entity level\")\n",
    "    print(f\"Entities: {len(entity_df):,} (Retained: {(entity_df[TARGET_COLUMN]==1).sum():,}, Churned: {(entity_df[TARGET_COLUMN]==0).sum():,})\\n\")\n",
    "    \n",
    "    effect_sizes = []\n",
    "    for col in effect_feature_cols:\n",
    "        churned = entity_df[entity_df[TARGET_COLUMN] == 0][col].dropna()\n",
    "        retained = entity_df[entity_df[TARGET_COLUMN] == 1][col].dropna()\n",
    "        \n",
    "        if len(churned) > 0 and len(retained) > 0:\n",
    "            pooled_std = np.sqrt(((len(churned)-1)*churned.std()**2 + (len(retained)-1)*retained.std()**2) / \n",
    "                                 (len(churned) + len(retained) - 2))\n",
    "            d = (retained.mean() - churned.mean()) / pooled_std if pooled_std > 0 else 0\n",
    "            \n",
    "            abs_d = abs(d)\n",
    "            if abs_d >= 0.8:\n",
    "                interp, emoji = \"Large effect\", \"ðŸ”´\"\n",
    "            elif abs_d >= 0.5:\n",
    "                interp, emoji = \"Medium effect\", \"ðŸŸ¡\"\n",
    "            elif abs_d >= 0.2:\n",
    "                interp, emoji = \"Small effect\", \"ðŸŸ¢\"\n",
    "            else:\n",
    "                interp, emoji = \"Negligible\", \"âšª\"\n",
    "            \n",
    "            effect_sizes.append({\n",
    "                \"feature\": col, \"cohens_d\": d, \"abs_d\": abs_d, \n",
    "                \"interpretation\": interp, \"emoji\": emoji,\n",
    "                \"retained_mean\": retained.mean(), \"churned_mean\": churned.mean()\n",
    "            })\n",
    "    \n",
    "    # Sort and display\n",
    "    effect_df = pd.DataFrame(effect_sizes).sort_values(\"abs_d\", ascending=False)\n",
    "    \n",
    "    print(f\"{'Feature':<35} {'d':>8} {'Effect':<15} {'Direction':<20}\")\n",
    "    print(\"-\" * 80)\n",
    "    for _, row in effect_df.head(15).iterrows():\n",
    "        direction = \"â†‘ Higher in retained\" if row[\"cohens_d\"] > 0 else \"â†“ Lower in retained\"\n",
    "        print(f\"{row['emoji']} {row['feature'][:33]:<33} {row['cohens_d']:>+8.3f} {row['interpretation']:<15} {direction:<20}\")\n",
    "    \n",
    "    # Categorize features\n",
    "    large_effect = effect_df[effect_df[\"abs_d\"] >= 0.8][\"feature\"].tolist()\n",
    "    medium_effect = effect_df[(effect_df[\"abs_d\"] >= 0.5) & (effect_df[\"abs_d\"] < 0.8)][\"feature\"].tolist()\n",
    "    small_effect = effect_df[(effect_df[\"abs_d\"] >= 0.2) & (effect_df[\"abs_d\"] < 0.5)][\"feature\"].tolist()\n",
    "    \n",
    "    # INTERPRETATION\n",
    "    print(\"\\n\" + \"â”€\"*80)\n",
    "    print(\"ðŸ“– INTERPRETATION & RECOMMENDATIONS\")\n",
    "    print(\"â”€\"*80)\n",
    "    \n",
    "    if large_effect:\n",
    "        print(f\"\\nðŸ”´ LARGE EFFECT (|d| â‰¥ 0.8) - Priority Features:\")\n",
    "        for f in large_effect[:5]:\n",
    "            row = effect_df[effect_df[\"feature\"] == f].iloc[0]\n",
    "            direction = \"higher\" if row[\"cohens_d\"] > 0 else \"lower\"\n",
    "            print(f\"   â€¢ {f}: Retained customers have {direction} values\")\n",
    "            print(f\"     Mean: Retained={row['retained_mean']:.2f}, Churned={row['churned_mean']:.2f}\")\n",
    "        print(\"   â†’ MUST include in predictive model\")\n",
    "    \n",
    "    if medium_effect:\n",
    "        print(f\"\\nðŸŸ¡ MEDIUM EFFECT (0.5 â‰¤ |d| < 0.8) - Useful Features:\")\n",
    "        for f in medium_effect[:3]:\n",
    "            print(f\"   â€¢ {f}\")\n",
    "        print(\"   â†’ Should include in model\")\n",
    "    \n",
    "    if small_effect:\n",
    "        print(f\"\\nðŸŸ¢ SMALL EFFECT (0.2 â‰¤ |d| < 0.5) - Supporting Features:\")\n",
    "        print(f\"   {', '.join(small_effect[:5])}\")\n",
    "        print(\"   â†’ May help in combination with other features\")\n",
    "    \n",
    "    negligible = effect_df[effect_df[\"abs_d\"] < 0.2][\"feature\"].tolist()\n",
    "    if negligible:\n",
    "        print(f\"\\nâšª NEGLIGIBLE EFFECT (|d| < 0.2): {len(negligible)} features\")\n",
    "        print(\"   â†’ Consider engineering or dropping from model\")\n",
    "else:\n",
    "    print(\"Entity column or target not available for effect size analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0872bf2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Box Plots: Entity-level feature distributions by target\n",
    "if ENTITY_COLUMN and TARGET_COLUMN and 'entity_df' in dir() and len(effect_df) > 0:\n",
    "    # Select top features by effect size for visualization\n",
    "    top_features = effect_df.head(6)[\"feature\"].tolist()\n",
    "    n_features = len(top_features)\n",
    "    \n",
    "    if n_features > 0:\n",
    "        print(\"=\"*70)\n",
    "        print(\"DISTRIBUTION COMPARISON: Retained vs Churned (Box Plots)\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"\\nðŸ“Š Showing top 6 features by effect size\")\n",
    "        print(\"   ðŸŸ¢ Green = Retained | ðŸ”´ Red = Churned\\n\")\n",
    "        \n",
    "        fig = make_subplots(rows=1, cols=n_features, subplot_titles=top_features, horizontal_spacing=0.05)\n",
    "        \n",
    "        for i, col in enumerate(top_features):\n",
    "            col_num = i + 1\n",
    "            \n",
    "            # Retained (1) - Green\n",
    "            retained_data = entity_df[entity_df[TARGET_COLUMN] == 1][col].dropna()\n",
    "            fig.add_trace(go.Box(y=retained_data, name='Retained',\n",
    "                fillcolor='rgba(46, 204, 113, 0.7)', line=dict(color='#1e8449', width=2),\n",
    "                boxpoints='outliers', width=0.35, showlegend=(i == 0), legendgroup='retained',\n",
    "                marker=dict(color='rgba(46, 204, 113, 0.5)', size=4)), row=1, col=col_num)\n",
    "            \n",
    "            # Churned (0) - Red\n",
    "            churned_data = entity_df[entity_df[TARGET_COLUMN] == 0][col].dropna()\n",
    "            fig.add_trace(go.Box(y=churned_data, name='Churned',\n",
    "                fillcolor='rgba(231, 76, 60, 0.7)', line=dict(color='#922b21', width=2),\n",
    "                boxpoints='outliers', width=0.35, showlegend=(i == 0), legendgroup='churned',\n",
    "                marker=dict(color='rgba(231, 76, 60, 0.5)', size=4)), row=1, col=col_num)\n",
    "        \n",
    "        fig.update_layout(height=450, title_text=\"Top Features: Retained (Green) vs Churned (Red)\",\n",
    "            template='plotly_white', showlegend=True, boxmode='group',\n",
    "            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.05, xanchor=\"center\", x=0.5))\n",
    "        fig.update_xaxes(showticklabels=False)\n",
    "        display_figure(fig)\n",
    "        \n",
    "        # INTERPRETATION\n",
    "        print(\"â”€\"*70)\n",
    "        print(\"ðŸ“– HOW TO READ BOX PLOTS\")\n",
    "        print(\"â”€\"*70)\n",
    "        print(\"\"\"\n",
    "Box Plot Elements:\n",
    "  â€¢ Box = Middle 50% of data (IQR: 25th to 75th percentile)\n",
    "  â€¢ Line inside box = Median (50th percentile)\n",
    "  â€¢ Whiskers = 1.5 Ã— IQR from box edges\n",
    "  â€¢ Dots outside = Outliers\n",
    "\n",
    "What makes a good predictor:\n",
    "  âœ“ Clear SEPARATION between green and red boxes\n",
    "  âœ“ Different MEDIANS (center lines at different heights)\n",
    "  âœ“ Minimal OVERLAP between boxes\n",
    "\n",
    "Patterns to look for:\n",
    "  â€¢ Green box entirely above red â†’ Retained have higher values\n",
    "  â€¢ Green box entirely below red â†’ Retained have lower values\n",
    "  â€¢ Overlapping boxes â†’ Feature alone may not discriminate well\n",
    "  â€¢ Many outliers in one group â†’ Subpopulations worth investigating\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3930d3ae",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature-Target Correlation Ranking\n",
    "if ENTITY_COLUMN and TARGET_COLUMN and 'entity_df' in dir():\n",
    "    print(\"=\"*70)\n",
    "    print(\"FEATURE-TARGET CORRELATIONS (Entity-Level)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    correlations = []\n",
    "    for col in effect_feature_cols:\n",
    "        if col != TARGET_COLUMN:\n",
    "            corr = entity_df[[col, TARGET_COLUMN]].corr().iloc[0, 1]\n",
    "            if not np.isnan(corr):\n",
    "                correlations.append({\"Feature\": col, \"Correlation\": corr})\n",
    "    \n",
    "    if correlations:\n",
    "        corr_df = pd.DataFrame(correlations).sort_values(\"Correlation\", key=abs, ascending=False)\n",
    "        \n",
    "        fig = charts.bar_chart(\n",
    "            corr_df[\"Feature\"].head(12).tolist(),\n",
    "            corr_df[\"Correlation\"].head(12).tolist(),\n",
    "            title=f\"Feature Correlations with {TARGET_COLUMN}\"\n",
    "        )\n",
    "        display_figure(fig)\n",
    "        \n",
    "        print(\"\\nðŸ“Š Correlation Rankings:\")\n",
    "        print(f\"{'Feature':<35} {'Correlation':>12} {'Strength':<15} {'Direction'}\")\n",
    "        print(\"-\" * 75)\n",
    "        \n",
    "        for _, row in corr_df.head(10).iterrows():\n",
    "            abs_corr = abs(row[\"Correlation\"])\n",
    "            if abs_corr >= 0.5:\n",
    "                strength = \"Strong\"\n",
    "            elif abs_corr >= 0.3:\n",
    "                strength = \"Moderate\"\n",
    "            elif abs_corr >= 0.1:\n",
    "                strength = \"Weak\"\n",
    "            else:\n",
    "                strength = \"Very weak\"\n",
    "            \n",
    "            direction = \"Positive\" if row[\"Correlation\"] > 0 else \"Negative\"\n",
    "            print(f\"{row['Feature'][:34]:<35} {row['Correlation']:>+12.3f} {strength:<15} {direction}\")\n",
    "        \n",
    "        # INTERPRETATION\n",
    "        print(\"\\n\" + \"â”€\"*70)\n",
    "        print(\"ðŸ“– INTERPRETING CORRELATIONS WITH TARGET\")\n",
    "        print(\"â”€\"*70)\n",
    "        print(\"\"\"\n",
    "Correlation with binary target (retained=1, churned=0):\n",
    "\n",
    "  Positive correlation (+): Higher values â†’ more likely RETAINED\n",
    "  Negative correlation (-): Higher values â†’ more likely CHURNED\n",
    "\n",
    "Strength guide:\n",
    "  |r| > 0.5:  Strong - prioritize this feature\n",
    "  |r| 0.3-0.5: Moderate - useful predictor\n",
    "  |r| 0.1-0.3: Weak - may help in combination\n",
    "  |r| < 0.1:  Very weak - limited predictive value\n",
    "\n",
    "Note: Correlation captures LINEAR relationships only.\n",
    "Non-linear relationships may have low correlation but still be predictive.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e0070e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scatter Plot Matrix for top entity-level features\n",
    "if ENTITY_COLUMN and TARGET_COLUMN and 'entity_df' in dir() and len(effect_df) > 0:\n",
    "    # Select top 4 features for scatter matrix\n",
    "    top_scatter_features = effect_df.head(4)[\"feature\"].tolist()\n",
    "    \n",
    "    if len(top_scatter_features) >= 2:\n",
    "        scatter_data = entity_df[top_scatter_features].sample(min(1000, len(entity_df)))\n",
    "        fig = charts.scatter_matrix(scatter_data, title=\"Scatter Plot Matrix (Top Entity-Level Features)\")\n",
    "        display_figure(fig)\n",
    "        \n",
    "        print(\"\\nðŸ“ˆ Scatter Matrix Insights:\")\n",
    "        print(\"   â€¢ Look for clusters indicating natural segments\")\n",
    "        print(\"   â€¢ Diagonal patterns suggest correlated features\")\n",
    "        print(\"   â€¢ Curved patterns may benefit from polynomial features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f41f14",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1c.10 Sparkline Comparison: Retained vs Churned Trends\n",
    "\n",
    "**ðŸ“– Why Sparklines for Cohort Comparison:**\n",
    "\n",
    "Sparklines provide a compact side-by-side visualization of how metrics evolve differently for retained vs churned customers:\n",
    "\n",
    "| Row | What It Shows | Look For |\n",
    "|-----|--------------|----------|\n",
    "| **Retained (Green)** | Weekly trend for customers who stayed | Stable or upward trends |\n",
    "| **Churned (Red)** | Weekly trend for customers who left | Declining trends before churn |\n",
    "\n",
    "**Reading the Sparklines:**\n",
    "- Each column = one metric\n",
    "- Top row = Retained customers (green)\n",
    "- Bottom row = Churned customers (red)\n",
    "- Compare shapes: divergent patterns = predictive signal\n",
    "\n",
    "**Configuration:**\n",
    "- Variables are auto-selected based on **effect size** (Cohen's d) - metrics that best differentiate retained from churned\n",
    "- Override `SPARKLINE_COLUMNS` below to specify custom columns\n",
    "- Target defaults to detected churn/retention column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46f276d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === SPARKLINE CONFIGURATION ===\n",
    "# Override these to customize the sparkline comparison\n",
    "\n",
    "# Target column for cohort split (default: auto-detected churn/retention column)\n",
    "SPARKLINE_TARGET = TARGET_COLUMN  # Override: e.g., \"churn_flag\"\n",
    "\n",
    "# Columns to visualize (default: auto-select based on effect size)\n",
    "# Set to specific columns: [\"col1\", \"col2\", \"col3\"]\n",
    "# Set to None for auto-selection\n",
    "SPARKLINE_COLUMNS = None  # Override: e.g., [\"revenue\", \"login_count\", \"support_tickets\"]\n",
    "\n",
    "# Number of columns to show if auto-selecting\n",
    "SPARKLINE_MAX_COLS = 6\n",
    "\n",
    "# === AUTO-SELECT BEST COLUMNS (by Effect Size / Cohen's d) ===\n",
    "def select_sparkline_columns(df, numeric_cols, target_col, max_cols=6):\n",
    "    \"\"\"\n",
    "    Select columns most likely to show differences between retained/churned.\n",
    "    \n",
    "    Selection Logic:\n",
    "    - WITH target: Uses effect size (Cohen's d) to find metrics that best \n",
    "      differentiate retained vs churned customers\n",
    "    - WITHOUT target: Uses variance to find most variable (interesting) metrics\n",
    "    \n",
    "    Returns columns sorted by discriminative power.\n",
    "    \"\"\"\n",
    "    if target_col is None or target_col not in df.columns:\n",
    "        # No target - select by variance (most variable = most interesting)\n",
    "        variances = {col: df[col].var() for col in numeric_cols if col in df.columns}\n",
    "        sorted_cols = sorted(variances.keys(), key=lambda x: variances[x], reverse=True)\n",
    "        return sorted_cols[:max_cols]\n",
    "    \n",
    "    # With target - select by discrimination power (effect size proxy)\n",
    "    scores = {}\n",
    "    for col in numeric_cols:\n",
    "        if col not in df.columns or col == target_col:\n",
    "            continue\n",
    "        try:\n",
    "            group0 = df[df[target_col] == 0][col].dropna()\n",
    "            group1 = df[df[target_col] == 1][col].dropna()\n",
    "            if len(group0) > 0 and len(group1) > 0:\n",
    "                # Cohen's d: standardized difference in means\n",
    "                pooled_std = np.sqrt((group0.var() + group1.var()) / 2)\n",
    "                if pooled_std > 0:\n",
    "                    scores[col] = abs(group1.mean() - group0.mean()) / pooled_std\n",
    "                else:\n",
    "                    scores[col] = 0\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if scores:\n",
    "        sorted_cols = sorted(scores.keys(), key=lambda x: scores[x], reverse=True)\n",
    "        return sorted_cols[:max_cols]\n",
    "    \n",
    "    # Fallback to first N columns\n",
    "    return [c for c in numeric_cols if c in df.columns][:max_cols]\n",
    "\n",
    "# Determine columns to use\n",
    "if SPARKLINE_COLUMNS is not None:\n",
    "    sparkline_cols = [c for c in SPARKLINE_COLUMNS if c in df.columns]\n",
    "    selection_method = \"user-specified\"\n",
    "else:\n",
    "    sparkline_cols = select_sparkline_columns(df, numeric_event_cols, SPARKLINE_TARGET, SPARKLINE_MAX_COLS)\n",
    "    selection_method = \"auto-selected by effect size (Cohen's d)\" if SPARKLINE_TARGET else \"auto-selected by variance\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SPARKLINE VARIABLE SELECTION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTarget column: {SPARKLINE_TARGET or 'None (no cohort split)'}\")\n",
    "print(f\"Selection method: {selection_method}\")\n",
    "print(f\"\\nSelected columns ({len(sparkline_cols)}):\")\n",
    "for i, col in enumerate(sparkline_cols, 1):\n",
    "    print(f\"   {i}. {col}\")\n",
    "\n",
    "if SPARKLINE_COLUMNS is None and SPARKLINE_TARGET:\n",
    "    print(\"\"\"\n",
    "ðŸ’¡ Why these columns?\n",
    "   Columns are ranked by EFFECT SIZE (Cohen's d), which measures how well \n",
    "   each metric separates retained from churned customers. Higher effect \n",
    "   size = better discrimination = more interesting to visualize.\n",
    "   \n",
    "   To override: Set SPARKLINE_COLUMNS = [\"your\", \"columns\", \"here\"]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0db01c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sparkline comparison: Retained vs Churned behavior over time\n",
    "if ENTITY_COLUMN and sparkline_cols:\n",
    "    # Prepare data with target labels\n",
    "    if SPARKLINE_TARGET and SPARKLINE_TARGET in df.columns:\n",
    "        entity_target_map = df.groupby(ENTITY_COLUMN)[SPARKLINE_TARGET].first()\n",
    "        df_with_target = df.merge(entity_target_map.reset_index().rename(columns={SPARKLINE_TARGET: '_target'}), on=ENTITY_COLUMN)\n",
    "        has_target_split = True\n",
    "        \n",
    "        # Count for validation\n",
    "        n_retained = (df_with_target['_target'] == 1).sum()\n",
    "        n_churned = (df_with_target['_target'] == 0).sum()\n",
    "        print(f\"Data split: {n_retained:,} retained events, {n_churned:,} churned events\")\n",
    "    else:\n",
    "        df_with_target = df.copy()\n",
    "        df_with_target['_target'] = 1  # Treat all as one group\n",
    "        has_target_split = False\n",
    "    \n",
    "    # Aggregate by week\n",
    "    df_with_target['_week'] = df_with_target[TIME_COLUMN].dt.to_period('W').dt.start_time\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    if has_target_split:\n",
    "        print(\"SPARKLINE COMPARISON: Retained vs Churned Weekly Trends\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "        print(\"â”‚  ðŸŸ¢ TOP ROW = RETAINED (target=1) - customers who stayed â”‚\")\n",
    "        print(\"â”‚  ðŸ”´ BOTTOM ROW = CHURNED (target=0) - customers who left â”‚\")\n",
    "        print(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n\")\n",
    "    else:\n",
    "        print(\"SPARKLINE TRENDS: Weekly Metric Patterns\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"\\nðŸ“Š No target column - showing overall trends\\n\")\n",
    "    \n",
    "    # Build sparkline data for each column\n",
    "    sparkline_data = []\n",
    "    \n",
    "    for col in sparkline_cols:\n",
    "        if has_target_split:\n",
    "            retained_weekly = df_with_target[df_with_target['_target'] == 1].groupby('_week')[col].mean()\n",
    "            churned_weekly = df_with_target[df_with_target['_target'] == 0].groupby('_week')[col].mean()\n",
    "            all_weeks = sorted(set(retained_weekly.index) | set(churned_weekly.index))\n",
    "            retained_values = [retained_weekly.get(w, np.nan) for w in all_weeks]\n",
    "            churned_values = [churned_weekly.get(w, np.nan) for w in all_weeks]\n",
    "        else:\n",
    "            overall_weekly = df_with_target.groupby('_week')[col].mean()\n",
    "            all_weeks = sorted(overall_weekly.index)\n",
    "            retained_values = overall_weekly.tolist()\n",
    "            churned_values = None\n",
    "        \n",
    "        sparkline_data.append({\n",
    "            'name': col,\n",
    "            'retained': retained_values,\n",
    "            'churned': churned_values,\n",
    "            'weeks': all_weeks\n",
    "        })\n",
    "    \n",
    "    # Create sparkline grid with CLEAR ROW LABELS\n",
    "    n_cols = len(sparkline_data)\n",
    "    \n",
    "    if has_target_split:\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=n_cols,\n",
    "            row_titles=['ðŸŸ¢ RETAINED', 'ðŸ”´ CHURNED'],\n",
    "            subplot_titles=[d['name'][:15] for d in sparkline_data],\n",
    "            vertical_spacing=0.2,\n",
    "            horizontal_spacing=0.05\n",
    "        )\n",
    "    else:\n",
    "        fig = make_subplots(\n",
    "            rows=1, cols=n_cols,\n",
    "            subplot_titles=[d['name'][:15] for d in sparkline_data],\n",
    "            horizontal_spacing=0.05\n",
    "        )\n",
    "    \n",
    "    for i, data in enumerate(sparkline_data):\n",
    "        col_num = i + 1\n",
    "        \n",
    "        # Retained sparkline (top row)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            y=data['retained'],\n",
    "            mode='lines',\n",
    "            line=dict(color='#2ca02c', width=2),\n",
    "            fill='tozeroy',\n",
    "            fillcolor='rgba(44, 160, 44, 0.3)',\n",
    "            showlegend=False,\n",
    "            hovertemplate=f\"{data['name']}<br>Retained: %{{y:.2f}}<extra></extra>\"\n",
    "        ), row=1, col=col_num)\n",
    "        \n",
    "        # Churned sparkline (bottom row) - only if target split\n",
    "        if has_target_split and data['churned'] is not None:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                y=data['churned'],\n",
    "                mode='lines',\n",
    "                line=dict(color='#d62728', width=2),\n",
    "                fill='tozeroy',\n",
    "                fillcolor='rgba(214, 39, 40, 0.3)',\n",
    "                showlegend=False,\n",
    "                hovertemplate=f\"{data['name']}<br>Churned: %{{y:.2f}}<extra></extra>\"\n",
    "            ), row=2, col=col_num)\n",
    "    \n",
    "    # Clean up axes for sparkline appearance\n",
    "    fig.update_xaxes(showticklabels=False, showgrid=False)\n",
    "    fig.update_yaxes(showticklabels=False, showgrid=False)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=\"Weekly Metric Trends: Compare TOP ROW (Retained) vs BOTTOM ROW (Churned)\",\n",
    "            font=dict(size=14)\n",
    "        ),\n",
    "        height=350 if has_target_split else 180,\n",
    "        template='plotly_white',\n",
    "        margin=dict(t=100, b=30, l=80, r=20)\n",
    "    )\n",
    "    display_figure(fig)\n",
    "    \n",
    "    # Detailed divergence analysis with interpretation\n",
    "    if has_target_split:\n",
    "        print(\"\\n\" + \"â”€\"*70)\n",
    "        print(\"ðŸ“Š DIVERGENCE ANALYSIS: Which metrics differ between groups?\")\n",
    "        print(\"â”€\"*70)\n",
    "        \n",
    "        divergent_metrics = []\n",
    "        for data in sparkline_data:\n",
    "            if len(data['retained']) >= 4 and data['churned'] is not None and len(data['churned']) >= 4:\n",
    "                # Compare first half to second half\n",
    "                ret_early = np.nanmean(data['retained'][:len(data['retained'])//2])\n",
    "                ret_late = np.nanmean(data['retained'][len(data['retained'])//2:])\n",
    "                churn_early = np.nanmean(data['churned'][:len(data['churned'])//2])\n",
    "                churn_late = np.nanmean(data['churned'][len(data['churned'])//2:])\n",
    "                \n",
    "                retained_trend = ret_late - ret_early\n",
    "                churned_trend = churn_late - churn_early\n",
    "                \n",
    "                r_dir = \"â†‘ rising\" if retained_trend > 0.01 else \"â†“ falling\" if retained_trend < -0.01 else \"â†’ flat\"\n",
    "                c_dir = \"â†‘ rising\" if churned_trend > 0.01 else \"â†“ falling\" if churned_trend < -0.01 else \"â†’ flat\"\n",
    "                \n",
    "                is_divergent = (retained_trend > 0) != (churned_trend > 0) and abs(retained_trend - churned_trend) > 0.01\n",
    "                divergence = \"âš ï¸ DIVERGENT\" if is_divergent else \"\"\n",
    "                \n",
    "                if is_divergent:\n",
    "                    divergent_metrics.append(data['name'])\n",
    "                \n",
    "                print(f\"   {data['name'][:20]}: Retained {r_dir}, Churned {c_dir} {divergence}\")\n",
    "        \n",
    "        # INTERPRETATION\n",
    "        print(\"\\n\" + \"â”€\"*70)\n",
    "        print(\"ðŸ“– HOW TO INTERPRET THE SPARKLINES\")\n",
    "        print(\"â”€\"*70)\n",
    "        print(\"\"\"\n",
    "Compare the SHAPE of green (top) vs red (bottom) rows:\n",
    "\n",
    "Pattern Recognition:\n",
    "  ðŸŸ¢ Top sparkline RISING + ðŸ”´ Bottom sparkline FALLING\n",
    "     â†’ STRONG signal! Metric clearly differentiates groups\n",
    "     â†’ Priority feature candidate\n",
    "     \n",
    "  ðŸŸ¢ Top sparkline STABLE + ðŸ”´ Bottom sparkline FALLING  \n",
    "     â†’ Good signal! Churned customers show declining behavior\n",
    "     â†’ Create velocity/momentum features\n",
    "     \n",
    "  Both rows have SIMILAR shapes\n",
    "     â†’ Weak signal for this metric alone\n",
    "     â†’ May still be useful in combination\n",
    "     \n",
    "  ðŸ”´ Bottom row more VOLATILE than ðŸŸ¢ top row\n",
    "     â†’ Churned customers have erratic behavior\n",
    "     â†’ Consider variance-based features\n",
    "\"\"\")\n",
    "        \n",
    "        if divergent_metrics:\n",
    "            print(f\"â­ DIVERGENT METRICS (high priority): {', '.join(divergent_metrics)}\")\n",
    "            print(\"   These show opposite trends for retained vs churned.\")\n",
    "            print(\"   RECOMMENDED: Create trend/velocity features for these.\")\n",
    "else:\n",
    "    print(\"Entity column required for sparkline comparison\")\n",
    "    if not sparkline_cols:\n",
    "        print(\"No numeric columns available for sparklines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82141349",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use ChartBuilder sparkline_grid for monthly cohort trends (alternative visualization)\n",
    "if ENTITY_COLUMN and sparkline_cols and SPARKLINE_TARGET and SPARKLINE_TARGET in df.columns:\n",
    "    # Monthly aggregation for cleaner sparklines\n",
    "    df_with_target['_month'] = df_with_target[TIME_COLUMN].dt.to_period('M').dt.start_time\n",
    "    \n",
    "    # Build monthly trends for key metrics, split by target\n",
    "    cols_to_plot = sparkline_cols[:4]  # Limit to 4 for grid layout\n",
    "    monthly_retained = df_with_target[df_with_target['_target'] == 1].groupby('_month')[cols_to_plot].mean()\n",
    "    monthly_churned = df_with_target[df_with_target['_target'] == 0].groupby('_month')[cols_to_plot].mean()\n",
    "    \n",
    "    # Create separate sparkline grids for retained and churned\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MONTHLY SPARKLINE GRIDS (ChartBuilder)\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\"\"\n",
    "Alternative view using monthly aggregation (smoother trends).\n",
    "Compare the shapes between Retained (green dots) and Churned (red dots).\n",
    "\"\"\")\n",
    "    \n",
    "    retained_series = {col[:20]: monthly_retained[col].dropna().tolist() for col in cols_to_plot if col in monthly_retained.columns}\n",
    "    if retained_series:\n",
    "        fig_retained = charts.sparkline_grid(retained_series, columns=2, sparkline_height=80)\n",
    "        fig_retained.update_layout(title=\"ðŸŸ¢ RETAINED Customers - Monthly Trends\")\n",
    "        display_figure(fig_retained)\n",
    "    \n",
    "    churned_series = {col[:20]: monthly_churned[col].dropna().tolist() for col in cols_to_plot if col in monthly_churned.columns}\n",
    "    if churned_series:\n",
    "        fig_churned = charts.sparkline_grid(churned_series, columns=2, sparkline_height=80)\n",
    "        fig_churned.update_layout(title=\"ðŸ”´ CHURNED Customers - Monthly Trends\")\n",
    "        display_figure(fig_churned)\n",
    "    \n",
    "    # Side-by-side summary\n",
    "    print(\"\\nðŸ“Š Monthly Trend Summary:\")\n",
    "    print(f\"{'Metric':<20} {'Retained Trend':>15} {'Churned Trend':>15} {'Signal':<12}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    for col in cols_to_plot:\n",
    "        if col in monthly_retained.columns and col in monthly_churned.columns:\n",
    "            ret_vals = monthly_retained[col].dropna().tolist()\n",
    "            churn_vals = monthly_churned[col].dropna().tolist()\n",
    "            \n",
    "            if len(ret_vals) >= 2 and len(churn_vals) >= 2:\n",
    "                ret_trend = ret_vals[-1] - ret_vals[0]\n",
    "                churn_trend = churn_vals[-1] - churn_vals[0]\n",
    "                \n",
    "                ret_dir = \"â†‘\" if ret_trend > 0 else \"â†“\" if ret_trend < 0 else \"â†’\"\n",
    "                churn_dir = \"â†‘\" if churn_trend > 0 else \"â†“\" if churn_trend < 0 else \"â†’\"\n",
    "                \n",
    "                signal = \"âš ï¸ DIVERGENT\" if (ret_trend > 0) != (churn_trend > 0) else \"\"\n",
    "                print(f\"{col[:19]:<20} {ret_dir:>15} {churn_dir:>15} {signal:<12}\")\n",
    "elif not SPARKLINE_TARGET:\n",
    "    print(\"ðŸ’¡ Set SPARKLINE_TARGET to enable retained vs churned comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aab0ff",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1c.11 Velocity & Acceleration Analysis\n",
    "\n",
    "**ðŸ“– Why Velocity and Acceleration Matter:**\n",
    "\n",
    "| Metric | Formula | Interpretation |\n",
    "|--------|---------|----------------|\n",
    "| **Velocity** | Î”(event_count) / Î”t | Rate of change - is activity speeding up or slowing down? |\n",
    "| **Acceleration** | Î”(velocity) / Î”t | Change in rate - is the slowdown accelerating? |\n",
    "\n",
    "- Positive velocity: Activity increasing\n",
    "- Negative velocity: Activity decreasing (churn signal)\n",
    "- Positive acceleration: Speeding up (engagement growing)\n",
    "- Negative acceleration: Slowing down (disengagement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f6e53b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Velocity & Acceleration Analysis using TemporalFeatureAnalyzer\n",
    "if ENTITY_COLUMN and sparkline_cols and SPARKLINE_TARGET and SPARKLINE_TARGET in df.columns:\n",
    "    # Initialize the analyzer\n",
    "    feature_analyzer = TemporalFeatureAnalyzer(\n",
    "        time_column=TIME_COLUMN,\n",
    "        entity_column=ENTITY_COLUMN\n",
    "    )\n",
    "    \n",
    "    velocity_cols = sparkline_cols[:4]\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"VELOCITY & ACCELERATION ANALYSIS (using TemporalFeatureAnalyzer)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Calculate velocity using framework\n",
    "    velocity_results = feature_analyzer.calculate_velocity(df, velocity_cols, window_days=7)\n",
    "    acceleration_results = feature_analyzer.calculate_acceleration(df, velocity_cols, window_days=7)\n",
    "    \n",
    "    # Compare cohorts\n",
    "    cohort_comparison = feature_analyzer.compare_cohorts(df, velocity_cols, SPARKLINE_TARGET)\n",
    "    \n",
    "    # Build data for visualization\n",
    "    chart_data = {}\n",
    "    for col in velocity_cols:\n",
    "        # Get weekly data for retained and churned\n",
    "        entity_target = df.groupby(ENTITY_COLUMN)[SPARKLINE_TARGET].first()\n",
    "        df_temp = df.merge(entity_target.reset_index().rename(columns={SPARKLINE_TARGET: '_target'}), on=ENTITY_COLUMN)\n",
    "        df_temp['_week'] = df_temp[TIME_COLUMN].dt.to_period('W').dt.start_time\n",
    "        \n",
    "        retained_weekly = df_temp[df_temp['_target'] == 1].groupby('_week')[col].mean()\n",
    "        churned_weekly = df_temp[df_temp['_target'] == 0].groupby('_week')[col].mean()\n",
    "        \n",
    "        # Calculate derivatives\n",
    "        ret_vel = retained_weekly.diff().dropna()\n",
    "        churn_vel = churned_weekly.diff().dropna()\n",
    "        ret_acc = ret_vel.diff().dropna()\n",
    "        churn_acc = churn_vel.diff().dropna()\n",
    "        \n",
    "        chart_data[col] = {\n",
    "            \"retained\": retained_weekly.tolist(),\n",
    "            \"churned\": churned_weekly.tolist(),\n",
    "            \"velocity_retained\": ret_vel.tolist(),\n",
    "            \"velocity_churned\": churn_vel.tolist(),\n",
    "            \"accel_retained\": ret_acc.tolist(),\n",
    "            \"accel_churned\": churn_acc.tolist(),\n",
    "        }\n",
    "    \n",
    "    # Use ChartBuilder for visualization\n",
    "    fig = charts.velocity_acceleration_chart(\n",
    "        chart_data,\n",
    "        title=\"Value â†’ Velocity â†’ Acceleration (ðŸŸ¢ Retained vs ðŸ”´ Churned)\"\n",
    "    )\n",
    "    display_figure(fig)\n",
    "    \n",
    "    # Display framework results\n",
    "    print(\"\\nðŸ“Š Velocity Analysis Results:\")\n",
    "    for col, result in velocity_results.items():\n",
    "        print(f\"   {col}: {result.trend_direction} (mean velocity: {result.mean_velocity:.4f})\")\n",
    "    \n",
    "    print(\"\\nðŸ“Š Cohort Comparison (Retained vs Churned):\")\n",
    "    divergent_cols = []\n",
    "    for col, comparison in cohort_comparison.items():\n",
    "        ret_vel = comparison[\"retained\"].velocity\n",
    "        churn_vel = comparison[\"churned\"].velocity\n",
    "        is_divergent = (ret_vel > 0) != (churn_vel > 0)\n",
    "        if is_divergent:\n",
    "            divergent_cols.append(col)\n",
    "        diff = \"âš ï¸ DIVERGENT\" if is_divergent else \"\"\n",
    "        print(f\"   {col}: Retained vel={ret_vel:+.4f}, Churned vel={churn_vel:+.4f} {diff}\")\n",
    "    \n",
    "    # INTERPRETATION SECTION\n",
    "    print(\"\\n\" + \"â”€\"*70)\n",
    "    print(\"ðŸ“– HOW TO INTERPRET THESE RESULTS\")\n",
    "    print(\"â”€\"*70)\n",
    "    print(\"\"\"\n",
    "Velocity shows the RATE OF CHANGE of each metric over time:\n",
    "  â€¢ Positive velocity = metric is INCREASING\n",
    "  â€¢ Negative velocity = metric is DECREASING\n",
    "  â€¢ Zero velocity = metric is STABLE\n",
    "\n",
    "Key patterns to look for:\n",
    "  1. DIVERGENT velocities (retained â†‘ while churned â†“) = STRONG signal\n",
    "     â†’ These variables directly differentiate behavior\n",
    "     â†’ High priority for feature engineering\n",
    "     \n",
    "  2. Same direction but different magnitude = Moderate signal\n",
    "     â†’ Both groups trending same way, but at different rates\n",
    "     â†’ May indicate timing differences\n",
    "     \n",
    "  3. Both near zero = Weak signal for this metric\n",
    "     â†’ Stable behavior in both groups\n",
    "     â†’ Less useful for churn prediction\n",
    "\"\"\")\n",
    "    \n",
    "    if divergent_cols:\n",
    "        print(f\"â­ TOP CANDIDATES from velocity: {', '.join(divergent_cols)}\")\n",
    "        print(\"   These show opposite trends for retained vs churned customers.\")\n",
    "        print(\"   RECOMMENDED: Create velocity features for these variables.\")\n",
    "    \n",
    "    print(\"\\nðŸ’¡ Feature Engineering from Velocity Analysis:\")\n",
    "    print(\"   â€¢ {col}_velocity_7d = (current - 7d_ago) / 7d_ago\")\n",
    "    print(\"   â€¢ {col}_momentum = mean_7d / mean_30d\")\n",
    "    print(\"   â€¢ {col}_acceleration = velocity_now - velocity_7d_ago\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3f77cf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1c.12 Lag Correlation Analysis\n",
    "\n",
    "**ðŸ“– Why Lag Correlations Matter:**\n",
    "\n",
    "Lag correlations show how a metric relates to itself over time:\n",
    "- High lag-1 correlation: Today's value predicts tomorrow's\n",
    "- Decaying correlations: Effect diminishes over time\n",
    "- Periodic spikes: Seasonality (e.g., spike at lag 7 = weekly pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb55851",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lag Correlation Analysis using TemporalFeatureAnalyzer\n",
    "if ENTITY_COLUMN and sparkline_cols:\n",
    "    lag_cols = sparkline_cols[:6]\n",
    "    max_lag = 14\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"LAG CORRELATION ANALYSIS (using TemporalFeatureAnalyzer)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Use framework analyzer (initialized above or create new one)\n",
    "    if 'feature_analyzer' not in dir():\n",
    "        feature_analyzer = TemporalFeatureAnalyzer(\n",
    "            time_column=TIME_COLUMN,\n",
    "            entity_column=ENTITY_COLUMN\n",
    "        )\n",
    "    \n",
    "    # Calculate lag correlations using framework\n",
    "    lag_results = feature_analyzer.calculate_lag_correlations(df, lag_cols, max_lag=max_lag)\n",
    "    \n",
    "    # Build data for heatmap\n",
    "    lag_corr_data = {col: result.correlations for col, result in lag_results.items()}\n",
    "    \n",
    "    # Use ChartBuilder for visualization\n",
    "    fig = charts.lag_correlation_heatmap(\n",
    "        lag_corr_data,\n",
    "        max_lag=max_lag,\n",
    "        title=\"Autocorrelation by Lag (days) - Informs Lag Feature Selection\"\n",
    "    )\n",
    "    display_figure(fig)\n",
    "    \n",
    "    # Display framework results\n",
    "    print(\"\\nðŸ“Š Best Lag per Variable:\")\n",
    "    strong_lag_vars = []\n",
    "    weekly_pattern_vars = []\n",
    "    for col, result in lag_results.items():\n",
    "        best_lag_info = f\"best lag={result.best_lag}d (r={result.best_correlation:.2f})\"\n",
    "        weekly_info = \" [Weekly pattern]\" if result.has_weekly_pattern else \"\"\n",
    "        \n",
    "        if result.best_correlation > 0.3:\n",
    "            strong_lag_vars.append((col, result.best_lag, result.best_correlation))\n",
    "        if result.has_weekly_pattern:\n",
    "            weekly_pattern_vars.append(col)\n",
    "            \n",
    "        print(f\"   {col[:25]}: {best_lag_info}{weekly_info}\")\n",
    "    \n",
    "    # INTERPRETATION SECTION\n",
    "    print(\"\\n\" + \"â”€\"*70)\n",
    "    print(\"ðŸ“– HOW TO INTERPRET LAG CORRELATIONS\")\n",
    "    print(\"â”€\"*70)\n",
    "    print(\"\"\"\n",
    "Lag correlation shows how a variable relates to its PAST values:\n",
    "\n",
    "Reading the heatmap:\n",
    "  â€¢ Darker colors = STRONGER correlation at that lag\n",
    "  â€¢ Row = variable being analyzed\n",
    "  â€¢ Column = lag in days (1-14)\n",
    "\n",
    "What the patterns mean:\n",
    "  1. HIGH correlation at lag-1 (r > 0.5)\n",
    "     â†’ Strong \"memory\" - today's value predicts tomorrow's\n",
    "     â†’ Use: {col}_lag_1d, {col}_diff_1d features\n",
    "     \n",
    "  2. HIGH correlation at lag-7 (weekly peak)\n",
    "     â†’ Clear weekly seasonality\n",
    "     â†’ Use: {col}_lag_7d, day_of_week encoding\n",
    "     \n",
    "  3. SLOWLY decaying correlations\n",
    "     â†’ Mean-reverting behavior\n",
    "     â†’ Use: Rolling averages work well\n",
    "     \n",
    "  4. LOW correlations everywhere (< 0.2)\n",
    "     â†’ Random/noisy variable\n",
    "     â†’ Lag features less useful here\n",
    "\"\"\")\n",
    "    \n",
    "    if strong_lag_vars:\n",
    "        print(\"â­ STRONG LAG CANDIDATES:\")\n",
    "        for col, lag, corr in strong_lag_vars:\n",
    "            print(f\"   â€¢ {col}: lag {lag}d (r={corr:.2f}) â†’ Create {col}_lag_{lag}d feature\")\n",
    "    \n",
    "    if weekly_pattern_vars:\n",
    "        print(f\"\\nðŸ“… WEEKLY PATTERN DETECTED in: {', '.join(weekly_pattern_vars)}\")\n",
    "        print(\"   RECOMMENDED: Add day_of_week features + lag_7d features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f016361a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1c.13 Predictive Power Analysis (IV & KS Statistics)\n",
    "\n",
    "**ðŸ“– Information Value (IV) and KS Statistics:**\n",
    "\n",
    "These metrics measure how well time-window features predict the target:\n",
    "\n",
    "| Metric | Range | Interpretation |\n",
    "|--------|-------|----------------|\n",
    "| **IV** | 0-1+ | <0.02=weak, 0.02-0.1=medium, 0.1-0.3=strong, >0.3=very strong |\n",
    "| **KS** | 0-1 | Maximum separation between target classes |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0499714",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predictive Power Analysis using TemporalFeatureAnalyzer\n",
    "if ENTITY_COLUMN and SPARKLINE_TARGET and SPARKLINE_TARGET in df.columns:\n",
    "    print(\"=\"*70)\n",
    "    print(\"PREDICTIVE POWER ANALYSIS (using TemporalFeatureAnalyzer)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Use framework analyzer\n",
    "    if 'feature_analyzer' not in dir():\n",
    "        feature_analyzer = TemporalFeatureAnalyzer(\n",
    "            time_column=TIME_COLUMN,\n",
    "            entity_column=ENTITY_COLUMN\n",
    "        )\n",
    "    \n",
    "    # Calculate predictive power using framework\n",
    "    power_results = feature_analyzer.calculate_predictive_power(\n",
    "        df, sparkline_cols, SPARKLINE_TARGET\n",
    "    )\n",
    "    \n",
    "    # Build data for visualization\n",
    "    iv_values = {col: result.information_value for col, result in power_results.items()}\n",
    "    ks_values = {col: result.ks_statistic for col, result in power_results.items()}\n",
    "    \n",
    "    # Use ChartBuilder for visualization\n",
    "    fig = charts.predictive_power_chart(\n",
    "        iv_values,\n",
    "        ks_values,\n",
    "        title=\"Variable Predictive Power Rankings\"\n",
    "    )\n",
    "    display_figure(fig)\n",
    "    \n",
    "    # Display framework results\n",
    "    print(\"\\nðŸ“Š Predictive Power Rankings (from framework):\")\n",
    "    print(f\"{'Variable':<25} {'IV':>8} {'Strength':<12} {'KS':>8} {'p-value':>10}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    sorted_results = sorted(power_results.items(), key=lambda x: x[1].information_value, reverse=True)\n",
    "    strong_iv_vars = []\n",
    "    strong_ks_vars = []\n",
    "    suspicious_vars = []\n",
    "    \n",
    "    for col, result in sorted_results:\n",
    "        sig = \"***\" if result.ks_pvalue < 0.001 else \"**\" if result.ks_pvalue < 0.01 else \"*\" if result.ks_pvalue < 0.05 else \"\"\n",
    "        print(f\"{col[:24]:<25} {result.information_value:>8.3f} {result.iv_interpretation:<12} {result.ks_statistic:>8.3f} {result.ks_pvalue:>9.4f} {sig}\")\n",
    "        \n",
    "        if result.information_value > 0.3:\n",
    "            strong_iv_vars.append(col)\n",
    "        if result.ks_statistic > 0.4:\n",
    "            strong_ks_vars.append(col)\n",
    "        if result.iv_interpretation == \"suspicious\":\n",
    "            suspicious_vars.append(col)\n",
    "    \n",
    "    # INTERPRETATION SECTION\n",
    "    print(\"\\n\" + \"â”€\"*70)\n",
    "    print(\"ðŸ“– HOW TO INTERPRET IV AND KS STATISTICS\")\n",
    "    print(\"â”€\"*70)\n",
    "    print(\"\"\"\n",
    "Information Value (IV) - measures how well a variable separates classes:\n",
    "  â€¢ IV < 0.02:   Very weak - not useful alone\n",
    "  â€¢ IV 0.02-0.1: Weak - some signal\n",
    "  â€¢ IV 0.1-0.3:  Medium - good predictor\n",
    "  â€¢ IV 0.3-0.5:  Strong - excellent predictor\n",
    "  â€¢ IV > 0.5:    SUSPICIOUS - check for data leakage!\n",
    "\n",
    "KS Statistic - measures distribution separation between retained/churned:\n",
    "  â€¢ KS < 0.2:    Heavy overlap - weak discriminator\n",
    "  â€¢ KS 0.2-0.4:  Moderate separation\n",
    "  â€¢ KS > 0.4:    Clear separation - strong discriminator\n",
    "\n",
    "Significance stars: *** p<0.001, ** p<0.01, * p<0.05\n",
    "\n",
    "Combined interpretation:\n",
    "  â€¢ HIGH IV + HIGH KS + Significant â†’ TOP FEATURE CANDIDATE\n",
    "  â€¢ HIGH IV but LOW KS â†’ May need binning/transformation\n",
    "  â€¢ LOW IV but HIGH KS â†’ May have outliers driving KS\n",
    "\"\"\")\n",
    "    \n",
    "    # Warnings and recommendations\n",
    "    if suspicious_vars:\n",
    "        print(f\"âš ï¸ WARNING: Suspicious IV for: {', '.join(suspicious_vars)}\")\n",
    "        print(\"   IV > 0.5 may indicate DATA LEAKAGE - investigate these carefully!\")\n",
    "        print(\"   Check if these variables are derived from the target or future data.\")\n",
    "    \n",
    "    top_vars = [col for col, r in sorted_results if r.information_value > 0.1 or r.ks_statistic > 0.3]\n",
    "    if top_vars:\n",
    "        print(f\"\\nâ­ TOP FEATURE ENGINEERING CANDIDATES: {', '.join(top_vars[:5])}\")\n",
    "        print(\"   These variables show strong predictive power for the target.\")\n",
    "        print(\"   RECOMMENDED: Prioritize creating derived features from these.\")\n",
    "else:\n",
    "    print(\"Target column required for predictive power analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fc1ef1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1c.14 Momentum Analysis (Window Ratios)\n",
    "\n",
    "**ðŸ“– Momentum Features:**\n",
    "\n",
    "Momentum captures behavioral changes by comparing time windows:\n",
    "- recent_7d / recent_30d > 1: Activity increasing\n",
    "- recent_7d / recent_30d < 1: Activity decreasing\n",
    "- Large swings indicate volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c88070",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Momentum Analysis using TemporalFeatureAnalyzer\n",
    "if ENTITY_COLUMN and SPARKLINE_TARGET and SPARKLINE_TARGET in df.columns:\n",
    "    print(\"=\"*70)\n",
    "    print(\"MOMENTUM ANALYSIS (using TemporalFeatureAnalyzer)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Use framework analyzer\n",
    "    if 'feature_analyzer' not in dir():\n",
    "        feature_analyzer = TemporalFeatureAnalyzer(\n",
    "            time_column=TIME_COLUMN,\n",
    "            entity_column=ENTITY_COLUMN\n",
    "        )\n",
    "    \n",
    "    momentum_cols = sparkline_cols[:4]\n",
    "    \n",
    "    # Calculate momentum using framework\n",
    "    momentum_7_30 = feature_analyzer.calculate_momentum(df, momentum_cols, short_window=7, long_window=30)\n",
    "    momentum_30_90 = feature_analyzer.calculate_momentum(df, momentum_cols, short_window=30, long_window=90)\n",
    "    \n",
    "    # For cohort comparison, split by target and calculate separately\n",
    "    entity_target = df.groupby(ENTITY_COLUMN)[SPARKLINE_TARGET].first()\n",
    "    df_temp = df.merge(entity_target.reset_index().rename(columns={SPARKLINE_TARGET: '_target'}), on=ENTITY_COLUMN)\n",
    "    \n",
    "    retained_df = df_temp[df_temp['_target'] == 1]\n",
    "    churned_df = df_temp[df_temp['_target'] == 0]\n",
    "    \n",
    "    retained_mom_7_30 = feature_analyzer.calculate_momentum(retained_df, momentum_cols, 7, 30)\n",
    "    churned_mom_7_30 = feature_analyzer.calculate_momentum(churned_df, momentum_cols, 7, 30)\n",
    "    retained_mom_30_90 = feature_analyzer.calculate_momentum(retained_df, momentum_cols, 30, 90)\n",
    "    churned_mom_30_90 = feature_analyzer.calculate_momentum(churned_df, momentum_cols, 30, 90)\n",
    "    \n",
    "    # Build data for visualization\n",
    "    momentum_data = {}\n",
    "    divergent_momentum_cols = []\n",
    "    for col in momentum_cols:\n",
    "        ret_7_30 = retained_mom_7_30[col].mean_momentum if col in retained_mom_7_30 else 1\n",
    "        churn_7_30 = churned_mom_7_30[col].mean_momentum if col in churned_mom_7_30 else 1\n",
    "        momentum_data[col] = {\n",
    "            \"retained_7_30\": ret_7_30,\n",
    "            \"churned_7_30\": churn_7_30,\n",
    "            \"retained_30_90\": retained_mom_30_90[col].mean_momentum if col in retained_mom_30_90 else 1,\n",
    "            \"churned_30_90\": churned_mom_30_90[col].mean_momentum if col in churned_mom_30_90 else 1,\n",
    "        }\n",
    "        if abs(ret_7_30 - churn_7_30) > 0.1:\n",
    "            divergent_momentum_cols.append(col)\n",
    "    \n",
    "    # Use ChartBuilder for visualization\n",
    "    fig = charts.momentum_comparison_chart(\n",
    "        momentum_data,\n",
    "        title=\"Momentum by Retention Status (ratio > 1 = increasing, < 1 = declining)\"\n",
    "    )\n",
    "    display_figure(fig)\n",
    "    \n",
    "    # Display framework results\n",
    "    print(\"\\nðŸ“Š Momentum Results (from framework):\")\n",
    "    print(f\"{'Variable':<20} {'7d/30d Ret':>12} {'7d/30d Churn':>12} {'Diff':>10}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for col in momentum_cols:\n",
    "        ret = momentum_data[col][\"retained_7_30\"]\n",
    "        churn = momentum_data[col][\"churned_7_30\"]\n",
    "        diff = ret - churn\n",
    "        signal = \"âš ï¸\" if abs(diff) > 0.1 else \"\"\n",
    "        print(f\"{col[:19]:<20} {ret:>12.3f} {churn:>12.3f} {diff:>+10.3f} {signal}\")\n",
    "    \n",
    "    # INTERPRETATION SECTION\n",
    "    print(\"\\n\" + \"â”€\"*70)\n",
    "    print(\"ðŸ“– HOW TO INTERPRET MOMENTUM ANALYSIS\")\n",
    "    print(\"â”€\"*70)\n",
    "    print(\"\"\"\n",
    "Momentum = mean(recent_window) / mean(longer_window)\n",
    "\n",
    "Interpreting momentum values:\n",
    "  â€¢ Momentum > 1.2:  Recent activity HIGHER than historical â†’ Increasing\n",
    "  â€¢ Momentum 0.8-1.2: Activity is STABLE\n",
    "  â€¢ Momentum 0.5-0.8: Recent activity LOWER than historical â†’ Declining\n",
    "  â€¢ Momentum < 0.5:   Sharp decline â†’ High churn risk\n",
    "\n",
    "What to look for in the chart:\n",
    "  1. RETAINED momentum > CHURNED momentum\n",
    "     â†’ Retained customers have improving engagement\n",
    "     â†’ This pattern is expected and validates the metric\n",
    "     \n",
    "  2. Large GAP between retained and churned\n",
    "     â†’ Strong differentiator - good feature candidate\n",
    "     â†’ Create: {col}_momentum_7_30 = mean_7d / mean_30d\n",
    "     \n",
    "  3. Both groups have similar momentum\n",
    "     â†’ Metric doesn't differentiate well on its own\n",
    "     â†’ May still be useful in combination with other features\n",
    "\n",
    "Window pair choices:\n",
    "  â€¢ 7d/30d:  Captures short-term changes (reacts quickly)\n",
    "  â€¢ 30d/90d: Captures medium-term trends (more stable)\n",
    "  â€¢ Both together can capture different dynamics\n",
    "\"\"\")\n",
    "    \n",
    "    if divergent_momentum_cols:\n",
    "        print(f\"â­ HIGH-SIGNAL MOMENTUM FEATURES: {', '.join(divergent_momentum_cols)}\")\n",
    "        print(\"   These show meaningful differences between retained and churned.\")\n",
    "        print(\"   RECOMMENDED: Create momentum features for these variables:\")\n",
    "        for col in divergent_momentum_cols:\n",
    "            print(f\"   â€¢ {col}_momentum_7_30 = mean({col}, 7d) / mean({col}, 30d)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fe79af",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1c.15 Feature Engineering Summary\n",
    "\n",
    "**ðŸ“‹ Consolidated recommendations from all analyses above:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc69a116",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature Engineering Recommendations using TemporalFeatureAnalyzer\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURE ENGINEERING RECOMMENDATIONS (from TemporalFeatureAnalyzer)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'feature_analyzer' in dir() and SPARKLINE_TARGET:\n",
    "    # Get automated recommendations from framework\n",
    "    recommendations = feature_analyzer.get_feature_recommendations(\n",
    "        df,\n",
    "        value_columns=sparkline_cols,\n",
    "        target_column=SPARKLINE_TARGET\n",
    "    )\n",
    "    \n",
    "    if recommendations:\n",
    "        print(f\"\\nðŸŽ¯ Framework Generated {len(recommendations)} Feature Recommendations:\\n\")\n",
    "        \n",
    "        # Group by type\n",
    "        by_type = {}\n",
    "        for rec in recommendations:\n",
    "            if rec.feature_type.value not in by_type:\n",
    "                by_type[rec.feature_type.value] = []\n",
    "            by_type[rec.feature_type.value].append(rec)\n",
    "        \n",
    "        for feat_type, recs in by_type.items():\n",
    "            print(f\"\\n{'â”€'*60}\")\n",
    "            print(f\"ðŸ“Œ {feat_type.upper()} FEATURES\")\n",
    "            print(f\"{'â”€'*60}\")\n",
    "            for rec in recs[:5]:  # Top 5 per type\n",
    "                print(f\"   Feature: {rec.feature_name}\")\n",
    "                print(f\"   Formula: {rec.formula}\")\n",
    "                print(f\"   Reason:  {rec.rationale}\")\n",
    "                print()\n",
    "    else:\n",
    "        print(\"\\n   No significant feature recommendations found.\")\n",
    "\n",
    "# Also show manual summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"QUICK REFERENCE: Feature Engineering Patterns\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Feature Type    â”‚ Formula Example                                     â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ Velocity        â”‚ (value_now - value_7d_ago) / value_7d_ago          â”‚\n",
    "â”‚ Acceleration    â”‚ velocity_now - velocity_7d_ago                      â”‚\n",
    "â”‚ Momentum        â”‚ mean_7d / mean_30d                                  â”‚\n",
    "â”‚ Lag             â”‚ df[col].shift(N)                                    â”‚\n",
    "â”‚ Rolling Mean    â”‚ df[col].rolling(7).mean()                          â”‚\n",
    "â”‚ Rolling Std     â”‚ df[col].rolling(30).std()                          â”‚\n",
    "â”‚ Ratio           â”‚ sum_30d / sum_all_time                              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6951024",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEMPORAL PATTERN SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Trend summary\n",
    "print(f\"\\n\\U0001f4c8 TREND:\")\n",
    "print(f\"   Direction: {trend_result.direction.value}\")\n",
    "print(f\"   Confidence: {trend_result.confidence}\")\n",
    "if trend_result.direction == TrendDirection.INCREASING:\n",
    "    print(\"   \\U0001f4a1 Consider: Time-based features may improve with recency weighting\")\n",
    "elif trend_result.direction == TrendDirection.DECREASING:\n",
    "    print(\"   \\U0001f4a1 Consider: Investigate cause of decline; recent data may be more valuable\")\n",
    "\n",
    "# Seasonality summary\n",
    "print(f\"\\n\\U0001f501 SEASONALITY:\")\n",
    "if seasonality_results:\n",
    "    for sr in seasonality_results[:2]:\n",
    "        period_name = sr.period_name or f\"{sr.period}-day\"\n",
    "        print(f\"   {period_name.title()} pattern (strength: {sr.strength:.2f})\")\n",
    "    print(\"   \\U0001f4a1 Consider: Add day-of-week or month features; use seasonal adjustments\")\n",
    "else:\n",
    "    print(\"   No significant seasonality detected\")\n",
    "\n",
    "# Recency summary\n",
    "if ENTITY_COLUMN:\n",
    "    print(f\"\\n\\u23f1\\ufe0f  RECENCY:\")\n",
    "    print(f\"   Median recency: {recency_result.median_recency_days:.0f} days\")\n",
    "    if recency_result.target_correlation is not None:\n",
    "        print(f\"   Target correlation: {recency_result.target_correlation:.3f}\")\n",
    "        if abs(recency_result.target_correlation) > 0.3:\n",
    "            print(\"   \\U0001f4a1 Consider: Recency is a strong predictor - prioritize in feature engineering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b951fe",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature engineering recommendations based on patterns\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RECOMMENDED TEMPORAL FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n\\U0001f6e0\\ufe0f Based on detected patterns, consider these features:\\n\")\n",
    "\n",
    "print(\"1. RECENCY FEATURES:\")\n",
    "print(\"   - days_since_last_event\")\n",
    "print(\"   - log_days_since_last_event (if right-skewed)\")\n",
    "print(\"   - recency_bucket (categorical: 0-7d, 8-30d, etc.)\")\n",
    "\n",
    "if seasonality_results:\n",
    "    weekly = any(6 <= sr.period <= 8 for sr in seasonality_results)\n",
    "    monthly = any(28 <= sr.period <= 32 for sr in seasonality_results)\n",
    "    \n",
    "    print(\"\\n2. SEASONALITY FEATURES:\")\n",
    "    if weekly:\n",
    "        print(\"   - is_weekend (binary)\")\n",
    "        print(\"   - day_of_week_sin, day_of_week_cos (cyclical encoding)\")\n",
    "    if monthly:\n",
    "        print(\"   - day_of_month\")\n",
    "        print(\"   - is_month_start, is_month_end\")\n",
    "\n",
    "print(\"\\n3. TREND-ADJUSTED FEATURES:\")\n",
    "if trend_result.direction in [TrendDirection.INCREASING, TrendDirection.DECREASING]:\n",
    "    print(\"   - event_count_recent_vs_overall (ratio)\")\n",
    "    print(\"   - activity_trend_direction (for each entity)\")\n",
    "else:\n",
    "    print(\"   - Standard time-window aggregations should work well\")\n",
    "\n",
    "print(\"\\n4. COHORT FEATURES:\")\n",
    "print(\"   - cohort_month (categorical or ordinal)\")\n",
    "print(\"   - tenure_days (days since first event)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b44ce1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1c.16 Save Pattern Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda00ef5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Store pattern analysis results in findings\n",
    "pattern_summary = {\n",
    "    \"trend\": {\n",
    "        \"direction\": trend_result.direction.value,\n",
    "        \"strength\": trend_result.strength,\n",
    "        \"confidence\": trend_result.confidence,\n",
    "    },\n",
    "    \"seasonality\": [\n",
    "        {\"period\": sr.period, \"name\": sr.period_name, \"strength\": sr.strength}\n",
    "        for sr in seasonality_results\n",
    "    ],\n",
    "}\n",
    "\n",
    "if ENTITY_COLUMN:\n",
    "    pattern_summary[\"recency\"] = {\n",
    "        \"median_days\": recency_result.median_recency_days,\n",
    "        \"target_correlation\": recency_result.target_correlation,\n",
    "    }\n",
    "\n",
    "# Add to findings notes\n",
    "if not findings.metadata:\n",
    "    findings.metadata = {}\n",
    "findings.metadata[\"temporal_patterns\"] = pattern_summary\n",
    "\n",
    "findings.save(FINDINGS_PATH)\n",
    "print(f\"Pattern analysis saved to: {FINDINGS_PATH}\")\n",
    "print(f\"\\nSummary: {pattern_summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188d981f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Summary: What We Learned\n",
    "\n",
    "In this notebook, we analyzed temporal patterns:\n",
    "\n",
    "1. **Trend Detection** - Identified long-term direction in data\n",
    "2. **Seasonality** - Found periodic patterns (weekly, monthly)\n",
    "3. **Cohort Analysis** - Compared behavior by entity join date\n",
    "4. **Recency Analysis** - Measured how recent activity relates to outcomes\n",
    "5. **Feature Recommendations** - Generated feature engineering suggestions\n",
    "\n",
    "## Pattern Summary\n",
    "\n",
    "| Pattern | Status | Recommendation |\n",
    "|---------|--------|----------------|\n",
    "| Trend | Check findings | Detrend if strong |\n",
    "| Seasonality | Check findings | Add cyclical features |\n",
    "| Cohort Effects | Check findings | Add cohort indicators |\n",
    "| Recency Effects | Check findings | Prioritize recent windows |\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "**Complete the Event Bronze Track:**\n",
    "- **01d_event_aggregation.ipynb** - Aggregate events to entity-level (produces new dataset)\n",
    "\n",
    "After 01d produces the aggregated dataset, continue with:\n",
    "- **02_column_deep_dive.ipynb** - Profile aggregated feature distributions\n",
    "- **03_quality_assessment.ipynb** - Quality checks on aggregated data\n",
    "- **04_relationship_analysis.ipynb** - Feature correlations and relationships\n",
    "\n",
    "The aggregated data from 01d becomes the input for the Entity Bronze Track."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5.042374,
   "end_time": "2026-01-22T14:17:53.022660",
   "environment_variables": {},
   "exception": true,
   "input_path": "exploration_notebooks/01c_temporal_patterns.ipynb",
   "output_path": "docs/tutorial/executed/01c_temporal_patterns.ipynb",
   "parameters": {},
   "start_time": "2026-01-22T14:17:47.980286",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}