{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd82829c",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [2]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb57429f",
   "metadata": {
    "papermill": {
     "duration": 0.002797,
     "end_time": "2026-01-22T14:17:43.619435",
     "exception": false,
     "start_time": "2026-01-22T14:17:43.616638",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Chapter 1a: Temporal Deep Dive (Event Bronze Track)\n",
    "\n",
    "**Purpose:** Analyze event-level (time series) datasets with focus on temporal patterns, entity lifecycles, and event frequency distributions.\n",
    "\n",
    "**When to use this notebook:**\n",
    "- Your dataset was detected as `EVENT_LEVEL` granularity in notebook 01\n",
    "- You have multiple rows per entity (customer, user, etc.)\n",
    "- Each row represents an event with a timestamp\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to profile entity lifecycles (first event, last event, duration)\n",
    "- Understanding event frequency distributions per entity\n",
    "- Inter-event timing patterns and their implications\n",
    "- Time series-specific feature engineering opportunities\n",
    "\n",
    "**Outputs:**\n",
    "- Entity lifecycle visualizations\n",
    "- Event frequency distribution analysis\n",
    "- Inter-event timing statistics\n",
    "- Updated exploration findings with time series metadata\n",
    "\n",
    "---\n",
    "\n",
    "## Understanding Time Series Profiling\n",
    "\n",
    "| Metric | Description | Why It Matters |\n",
    "|--------|-------------|----------------|\n",
    "| **Events per Entity** | Distribution of event counts | Identifies power users vs. one-time users |\n",
    "| **Entity Lifecycle** | Duration from first to last event | Reveals customer tenure patterns |\n",
    "| **Inter-event Time** | Time between consecutive events | Indicates engagement patterns |\n",
    "| **Time Span** | Overall data period coverage | Helps plan time window aggregations |\n",
    "\n",
    "**Aggregation Windows (used in notebook 01d):**\n",
    "- 24h: Very recent activity\n",
    "- 7d: Weekly patterns\n",
    "- 30d: Monthly patterns\n",
    "- 90d: Quarterly trends\n",
    "- 180d: Semi-annual patterns\n",
    "- 365d: Annual patterns\n",
    "- all-time: Historical totals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703be044",
   "metadata": {
    "papermill": {
     "duration": 0.002271,
     "end_time": "2026-01-22T14:17:43.624037",
     "exception": false,
     "start_time": "2026-01-22T14:17:43.621766",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1a.1 Load Previous Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ce5a0f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T14:17:43.629338Z",
     "iopub.status.busy": "2026-01-22T14:17:43.629215Z",
     "iopub.status.idle": "2026-01-22T14:17:45.044302Z",
     "shell.execute_reply": "2026-01-22T14:17:45.043919Z"
    },
    "papermill": {
     "duration": 1.418933,
     "end_time": "2026-01-22T14:17:45.045138",
     "exception": false,
     "start_time": "2026-01-22T14:17:43.626205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from customer_retention.analysis.auto_explorer import ExplorationFindings\n",
    "from customer_retention.analysis.visualization import ChartBuilder, display_figure, display_table\n",
    "from customer_retention.core.config.column_config import ColumnType, DatasetGranularity\n",
    "from customer_retention.stages.profiling import (\n",
    "    TimeSeriesProfiler, TimeSeriesProfile,\n",
    "    TypeDetector,\n",
    "    DistributionAnalyzer, TransformationType,\n",
    "    TemporalAnalyzer, TemporalGranularity,\n",
    "    SegmentAnalyzer\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1937559c",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51ec7b72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T14:17:45.050642Z",
     "iopub.status.busy": "2026-01-22T14:17:45.050492Z",
     "iopub.status.idle": "2026-01-22T14:17:45.185938Z",
     "shell.execute_reply": "2026-01-22T14:17:45.185457Z"
    },
    "papermill": {
     "duration": 0.139225,
     "end_time": "2026-01-22T14:17:45.187079",
     "exception": true,
     "start_time": "2026-01-22T14:17:45.047854",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No findings files found in ../experiments/findings. Run notebook 01 first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m findings_files = [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m FINDINGS_DIR.glob(\u001b[33m\"\u001b[39m\u001b[33m*_findings.yaml\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmulti_dataset\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m f.name]\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m findings_files:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo findings files found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFINDINGS_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Run notebook 01 first.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Sort by modification time (most recent first)\u001b[39;00m\n\u001b[32m     16\u001b[39m findings_files.sort(key=\u001b[38;5;28;01mlambda\u001b[39;00m f: f.stat().st_mtime, reverse=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: No findings files found in ../experiments/findings. Run notebook 01 first."
     ]
    }
   ],
   "source": [
    "# === CONFIGURATION ===\n",
    "# Option 1: Set the exact path from notebook 01 output\n",
    "# FINDINGS_PATH = \"../experiments/findings/transactions_abc123_findings.yaml\"\n",
    "\n",
    "# Option 2: Auto-discover findings files\n",
    "from pathlib import Path\n",
    "\n",
    "FINDINGS_DIR = Path(\"../experiments/findings\")\n",
    "\n",
    "# Find all findings files\n",
    "findings_files = [f for f in FINDINGS_DIR.glob(\"*_findings.yaml\") if \"multi_dataset\" not in f.name]\n",
    "if not findings_files:\n",
    "    raise FileNotFoundError(f\"No findings files found in {FINDINGS_DIR}. Run notebook 01 first.\")\n",
    "\n",
    "# Sort by modification time (most recent first)\n",
    "findings_files.sort(key=lambda f: f.stat().st_mtime, reverse=True)\n",
    "FINDINGS_PATH = str(findings_files[0])\n",
    "\n",
    "print(f\"Found {len(findings_files)} findings file(s)\")\n",
    "print(f\"Using: {FINDINGS_PATH}\")\n",
    "if len(findings_files) > 1:\n",
    "    print(f\"Other available: {[str(f.name) for f in findings_files[1:3]]}\")\n",
    "\n",
    "findings = ExplorationFindings.load(FINDINGS_PATH)\n",
    "print(f\"\\nLoaded findings for {findings.column_count} columns from {findings.source_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f57026",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verify this is a time series dataset\n",
    "if findings.is_time_series:\n",
    "    print(\"\\u2705 Dataset confirmed as TIME SERIES (event-level)\")\n",
    "    ts_meta = findings.time_series_metadata\n",
    "    print(f\"   Entity column: {ts_meta.entity_column}\")\n",
    "    print(f\"   Time column: {ts_meta.time_column}\")\n",
    "    print(f\"   Avg events per entity: {ts_meta.avg_events_per_entity:.1f}\" if ts_meta.avg_events_per_entity else \"\")\n",
    "else:\n",
    "    print(\"\\u26a0\\ufe0f This dataset was NOT detected as time series.\")\n",
    "    print(\"   Consider using 02_column_deep_dive.ipynb instead.\")\n",
    "    print(\"   Or manually specify entity and time columns below.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9326f17",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1a.2 Load Source Data & Configure Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9924b14",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from customer_retention.stages.temporal import load_data_with_snapshot_preference, TEMPORAL_METADATA_COLS\n",
    "\n",
    "df, data_source = load_data_with_snapshot_preference(findings, output_dir=\"../experiments/findings\")\n",
    "charts = ChartBuilder()\n",
    "\n",
    "print(f\"Loaded {len(df):,} rows x {len(df.columns)} columns\")\n",
    "print(f\"Data source: {data_source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429c299c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === COLUMN CONFIGURATION ===\n",
    "# These will be auto-populated from findings if available\n",
    "# Override manually if needed\n",
    "\n",
    "if findings.is_time_series and findings.time_series_metadata:\n",
    "    ENTITY_COLUMN = findings.time_series_metadata.entity_column\n",
    "    TIME_COLUMN = findings.time_series_metadata.time_column\n",
    "else:\n",
    "    # Manual configuration - uncomment and set if auto-detection failed\n",
    "    # ENTITY_COLUMN = \"customer_id\"\n",
    "    # TIME_COLUMN = \"event_date\"\n",
    "    \n",
    "    # Try auto-detection\n",
    "    detector = TypeDetector()\n",
    "    granularity = detector.detect_granularity(df)\n",
    "    ENTITY_COLUMN = granularity.entity_column\n",
    "    TIME_COLUMN = granularity.time_column\n",
    "\n",
    "print(f\"Entity column: {ENTITY_COLUMN}\")\n",
    "print(f\"Time column: {TIME_COLUMN}\")\n",
    "\n",
    "if not ENTITY_COLUMN or not TIME_COLUMN:\n",
    "    raise ValueError(\"Please set ENTITY_COLUMN and TIME_COLUMN manually above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c988ad",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1a.3 Time Series Profile Overview\n",
    "\n",
    "**What we analyze:**\n",
    "- Total events and unique entities\n",
    "- Time span coverage\n",
    "- Events per entity distribution\n",
    "- Entity lifecycle metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb90164",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the time series profiler and run analysis\n",
    "profiler = TimeSeriesProfiler(entity_column=ENTITY_COLUMN, time_column=TIME_COLUMN)\n",
    "ts_profile = profiler.profile(df)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TIME SERIES PROFILE SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n\\U0001f4ca Dataset Overview:\")\n",
    "print(f\"   Total Events: {ts_profile.total_events:,}\")\n",
    "print(f\"   Unique Entities: {ts_profile.unique_entities:,}\")\n",
    "print(f\"   Avg Events/Entity: {ts_profile.events_per_entity.mean:.1f}\")\n",
    "print(f\"   Time Span: {ts_profile.time_span_days:,} days ({ts_profile.time_span_days/365:.1f} years)\")\n",
    "\n",
    "print(f\"\\n\\U0001f4c5 Date Range:\")\n",
    "print(f\"   First Event: {ts_profile.first_event_date}\")\n",
    "print(f\"   Last Event: {ts_profile.last_event_date}\")\n",
    "\n",
    "print(f\"\\n\\u23f1\\ufe0f  Inter-Event Timing:\")\n",
    "if ts_profile.avg_inter_event_days is not None:\n",
    "    print(f\"   Avg Days Between Events: {ts_profile.avg_inter_event_days:.1f}\")\n",
    "else:\n",
    "    print(\"   Not enough data to compute inter-event timing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9434903a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1a.4 Events per Entity Distribution\n",
    "\n",
    "**üìñ How to Interpret:**\n",
    "- **Right-skewed** distribution (common): Most entities have few events, some have many\n",
    "- **Bimodal**: May indicate two distinct user segments\n",
    "- **Power law**: Very common in transaction data (few heavy users, many light users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c88ec84",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Events per entity distribution statistics\n",
    "events_dist = ts_profile.events_per_entity\n",
    "\n",
    "print(\"\\U0001f4ca Events per Entity Distribution:\")\n",
    "print(f\"   Min: {events_dist.min:.0f}\")\n",
    "print(f\"   25th percentile: {events_dist.q25:.0f}\")\n",
    "print(f\"   Median: {events_dist.median:.0f}\")\n",
    "print(f\"   Mean: {events_dist.mean:.1f}\")\n",
    "print(f\"   75th percentile: {events_dist.q75:.0f}\")\n",
    "print(f\"   Max: {events_dist.max:.0f}\")\n",
    "print(f\"   Std Dev: {events_dist.std:.1f}\")\n",
    "\n",
    "# Interpretation\n",
    "if events_dist.mean > events_dist.median * 1.5:\n",
    "    print(\"\\n\\U0001f4a1 Insight: Distribution is RIGHT-SKEWED (mean >> median)\")\n",
    "    print(\"   This is typical - a few entities have many events, most have few.\")\n",
    "    print(\"   Consider: Log transform for event count features, or segment by activity level.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08dbb67",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Histogram of events per entity\n",
    "event_counts = ts_profile.entity_lifecycles[\"event_count\"]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# For discrete integer data, use bar chart with value_counts for cleaner display\n",
    "value_counts = event_counts.value_counts().sort_index()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=value_counts.index,\n",
    "    y=value_counts.values,\n",
    "    name=\"Event Count\",\n",
    "    marker_color=\"steelblue\",\n",
    "    opacity=0.7\n",
    "))\n",
    "\n",
    "# Add mean and median lines - offset annotations to avoid overlap\n",
    "mean_val = events_dist.mean\n",
    "median_val = events_dist.median\n",
    "\n",
    "fig.add_vline(x=mean_val, line_dash=\"dash\", line_color=\"red\")\n",
    "fig.add_vline(x=median_val, line_dash=\"solid\", line_color=\"green\")\n",
    "\n",
    "# Use paper-referenced annotations to avoid overlap\n",
    "fig.add_annotation(\n",
    "    text=f\"Mean: {mean_val:.1f}\",\n",
    "    xref=\"paper\", yref=\"paper\",\n",
    "    x=0.98, y=0.95, showarrow=False,\n",
    "    font=dict(size=11, color=\"red\"),\n",
    "    xanchor=\"right\"\n",
    ")\n",
    "fig.add_annotation(\n",
    "    text=f\"Median: {median_val:.0f}\",\n",
    "    xref=\"paper\", yref=\"paper\",\n",
    "    x=0.98, y=0.88, showarrow=False,\n",
    "    font=dict(size=11, color=\"green\"),\n",
    "    xanchor=\"right\"\n",
    ")\n",
    "\n",
    "# Use log scale on Y-axis (count of entities) if highly skewed, not X-axis\n",
    "use_log_y = value_counts.max() > value_counts.median() * 50\n",
    "\n",
    "title_text = \"Events per Entity Distribution\"\n",
    "if use_log_y:\n",
    "    title_text += \"<br><sub>‚ö†Ô∏è Log scale on Y-axis due to high skewness</sub>\"\n",
    "\n",
    "fig.update_layout(\n",
    "    title=title_text,\n",
    "    xaxis_title=\"Number of Events\",\n",
    "    yaxis_title=\"Number of Entities\",\n",
    "    template=\"plotly_white\",\n",
    "    height=400,\n",
    "    yaxis_type=\"log\" if use_log_y else \"linear\"\n",
    ")\n",
    "\n",
    "display_figure(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11aa243",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Entity segmentation by activity level\n",
    "def categorize_activity(count, q25, q75):\n",
    "    if count <= 1:\n",
    "        return \"One-time\"\n",
    "    elif count <= q25:\n",
    "        return \"Low Activity\"\n",
    "    elif count <= q75:\n",
    "        return \"Medium Activity\"\n",
    "    else:\n",
    "        return \"High Activity\"\n",
    "\n",
    "lifecycles = ts_profile.entity_lifecycles.copy()\n",
    "lifecycles[\"activity_segment\"] = lifecycles[\"event_count\"].apply(\n",
    "    lambda x: categorize_activity(x, events_dist.q25, events_dist.q75)\n",
    ")\n",
    "\n",
    "segment_counts = lifecycles[\"activity_segment\"].value_counts()\n",
    "segment_order = [\"One-time\", \"Low Activity\", \"Medium Activity\", \"High Activity\"]\n",
    "segment_counts = segment_counts.reindex([s for s in segment_order if s in segment_counts.index])\n",
    "\n",
    "print(\"\\n\\U0001f465 Entity Activity Segments:\")\n",
    "for segment, count in segment_counts.items():\n",
    "    pct = count / len(lifecycles) * 100\n",
    "    print(f\"   {segment}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "# Calculate segment statistics for the second chart\n",
    "segment_stats = lifecycles.groupby(\"activity_segment\").agg({\n",
    "    \"event_count\": [\"mean\", \"median\", \"max\"]\n",
    "}).round(1)\n",
    "segment_stats.columns = [\"Avg Events\", \"Median Events\", \"Max Events\"]\n",
    "segment_stats = segment_stats.reindex([s for s in segment_order if s in segment_stats.index])\n",
    "\n",
    "# Side-by-side charts: Pie chart + Bar chart with segment stats\n",
    "colors = {\"One-time\": \"#d62728\", \"Low Activity\": \"#ff7f0e\", \n",
    "          \"Medium Activity\": \"#2ca02c\", \"High Activity\": \"#1f77b4\"}\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    specs=[[{\"type\": \"pie\"}, {\"type\": \"bar\"}]],\n",
    "    subplot_titles=(\"Entity Distribution\", \"Avg Events per Segment\"),\n",
    "    horizontal_spacing=0.12\n",
    ")\n",
    "\n",
    "# Left: Pie chart\n",
    "fig.add_trace(go.Pie(\n",
    "    labels=segment_counts.index,\n",
    "    values=segment_counts.values,\n",
    "    marker_colors=[colors.get(s, \"gray\") for s in segment_counts.index],\n",
    "    textinfo=\"label+percent\",\n",
    "    hole=0.3,\n",
    "    showlegend=False\n",
    "), row=1, col=1)\n",
    "\n",
    "# Right: Bar chart showing average events per segment\n",
    "fig.add_trace(go.Bar(\n",
    "    x=segment_stats.index,\n",
    "    y=segment_stats[\"Avg Events\"],\n",
    "    marker_color=[colors.get(s, \"gray\") for s in segment_stats.index],\n",
    "    text=[f\"{v:.1f}\" for v in segment_stats[\"Avg Events\"]],\n",
    "    textposition=\"outside\",\n",
    "    showlegend=False\n",
    "), row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Entity Activity Segments\",\n",
    "    height=400,\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "fig.update_yaxes(title_text=\"Avg Event Count\", row=1, col=2)\n",
    "\n",
    "display_figure(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0492821",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1a.5 Entity Lifecycle Analysis\n",
    "\n",
    "**üìñ Understanding Lifecycles:**\n",
    "- **Tenure**: Days between first and last event\n",
    "- **Active period**: Does not account for gaps - just first to last\n",
    "- **Short tenure with many events**: Intense but brief engagement\n",
    "- **Long tenure with few events**: Occasional but loyal user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e25497e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lifecycle duration distribution\n",
    "duration_stats = lifecycles[\"duration_days\"].describe()\n",
    "\n",
    "print(\"\\U0001f4c6 Entity Lifecycle Duration (days):\")\n",
    "print(f\"   Min: {duration_stats['min']:.0f}\")\n",
    "print(f\"   25th percentile: {duration_stats['25%']:.0f}\")\n",
    "print(f\"   Median: {duration_stats['50%']:.0f}\")\n",
    "print(f\"   Mean: {duration_stats['mean']:.1f}\")\n",
    "print(f\"   75th percentile: {duration_stats['75%']:.0f}\")\n",
    "print(f\"   Max: {duration_stats['max']:.0f}\")\n",
    "\n",
    "# Single-event entities (duration = 0)\n",
    "single_event = (lifecycles[\"duration_days\"] == 0).sum()\n",
    "print(f\"\\n\\U0001f6a8 Single-event entities: {single_event:,} ({single_event/len(lifecycles)*100:.1f}%)\")\n",
    "if single_event / len(lifecycles) > 0.3:\n",
    "    print(\"   High proportion of one-time users - consider retention analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310c66d3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lifecycle duration histogram (excluding zeros for clarity)\n",
    "non_zero_duration = lifecycles[lifecycles[\"duration_days\"] > 0][\"duration_days\"]\n",
    "\n",
    "if len(non_zero_duration) > 0:\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Histogram(\n",
    "        x=non_zero_duration,\n",
    "        nbinsx=50,\n",
    "        name=\"Duration\",\n",
    "        marker_color=\"mediumpurple\",\n",
    "        opacity=0.7\n",
    "    ))\n",
    "    \n",
    "    fig.add_vline(x=non_zero_duration.median(), line_dash=\"solid\", line_color=\"green\",\n",
    "                  annotation_text=f\"Median: {non_zero_duration.median():.0f} days\",\n",
    "                  annotation_position=\"top right\")\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"Entity Lifecycle Duration (excluding {single_event:,} single-event entities)\",\n",
    "        xaxis_title=\"Duration (days)\",\n",
    "        yaxis_title=\"Number of Entities\",\n",
    "        template=\"plotly_white\",\n",
    "        height=400\n",
    "    )\n",
    "    display_figure(fig)\n",
    "else:\n",
    "    print(\"All entities have only single events - no duration distribution to show\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ab4f1e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scatter: Event count vs Lifecycle duration\n",
    "fig = px.scatter(\n",
    "    lifecycles,\n",
    "    x=\"duration_days\",\n",
    "    y=\"event_count\",\n",
    "    color=\"activity_segment\",\n",
    "    color_discrete_map=colors,\n",
    "    opacity=0.5,\n",
    "    title=\"Event Count vs Lifecycle Duration\",\n",
    "    labels={\"duration_days\": \"Lifecycle Duration (days)\", \"event_count\": \"Event Count\"}\n",
    ")\n",
    "\n",
    "fig.update_layout(template=\"plotly_white\", height=500)\n",
    "display_figure(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b943f6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1a.6 Temporal Coverage Analysis\n",
    "\n",
    "**üìñ Why This Matters:**\n",
    "- Shows when data collection started/ended\n",
    "- Identifies gaps or seasonality in data volume\n",
    "- Helps plan time window aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c9cc75",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parse time column\n",
    "df_temp = df.copy()\n",
    "df_temp[TIME_COLUMN] = pd.to_datetime(df_temp[TIME_COLUMN])\n",
    "\n",
    "# Events over time (daily/weekly/monthly depending on span)\n",
    "time_span_days = ts_profile.time_span_days\n",
    "\n",
    "if time_span_days <= 90:\n",
    "    freq = \"D\"\n",
    "    freq_name = \"Daily\"\n",
    "elif time_span_days <= 365:\n",
    "    freq = \"W\"\n",
    "    freq_name = \"Weekly\"\n",
    "else:\n",
    "    freq = \"ME\"  # Month-end frequency (pandas 2.2+)\n",
    "    freq_name = \"Monthly\"\n",
    "\n",
    "events_over_time = df_temp.groupby(pd.Grouper(key=TIME_COLUMN, freq=freq)).size()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=events_over_time.index,\n",
    "    y=events_over_time.values,\n",
    "    mode=\"lines\",\n",
    "    fill=\"tozeroy\",\n",
    "    name=\"Events\",\n",
    "    line_color=\"steelblue\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"{freq_name} Event Volume Over Time\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Number of Events\",\n",
    "    template=\"plotly_white\",\n",
    "    height=400\n",
    ")\n",
    "display_figure(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25363a2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# New entities over time (cohort arrival)\n",
    "first_events = lifecycles.copy()\n",
    "first_events[\"first_event\"] = pd.to_datetime(first_events[\"first_event\"])\n",
    "\n",
    "new_entities = first_events.groupby(\n",
    "    pd.Grouper(key=\"first_event\", freq=freq)  # Uses freq from previous cell\n",
    ").size()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=new_entities.index,\n",
    "    y=new_entities.values,\n",
    "    name=\"New Entities\",\n",
    "    marker_color=\"mediumseagreen\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"New Entities Over Time ({freq_name})\",\n",
    "    xaxis_title=\"First Event Date\",\n",
    "    yaxis_title=\"Number of New Entities\",\n",
    "    template=\"plotly_white\",\n",
    "    height=400\n",
    ")\n",
    "display_figure(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9109a34",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1a.7 Inter-Event Timing Analysis\n",
    "\n",
    "**üìñ Understanding Inter-Event Time:**\n",
    "- Time between consecutive events for each entity\n",
    "- Short inter-event time: Frequent engagement\n",
    "- Long inter-event time: Sporadic usage or churn risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52bd193",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute inter-event times for all entities with >1 event\n",
    "inter_event_times = []\n",
    "\n",
    "for entity, group in df_temp.groupby(ENTITY_COLUMN):\n",
    "    if len(group) < 2:\n",
    "        continue\n",
    "    sorted_times = group[TIME_COLUMN].sort_values()\n",
    "    diffs = sorted_times.diff().dropna()\n",
    "    inter_event_times.extend(diffs.dt.total_seconds() / 86400)  # Convert to days\n",
    "\n",
    "if inter_event_times:\n",
    "    inter_event_series = pd.Series(inter_event_times)\n",
    "    \n",
    "    print(\"\\u23f1\\ufe0f  Inter-Event Time Distribution (days):\")\n",
    "    print(f\"   Min: {inter_event_series.min():.2f}\")\n",
    "    print(f\"   25th percentile: {inter_event_series.quantile(0.25):.2f}\")\n",
    "    print(f\"   Median: {inter_event_series.median():.2f}\")\n",
    "    print(f\"   Mean: {inter_event_series.mean():.2f}\")\n",
    "    print(f\"   75th percentile: {inter_event_series.quantile(0.75):.2f}\")\n",
    "    print(f\"   Max: {inter_event_series.max():.2f}\")\n",
    "    \n",
    "    # Histogram\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Cap at 99th percentile for visualization\n",
    "    cap = inter_event_series.quantile(0.99)\n",
    "    display_data = inter_event_series[inter_event_series <= cap]\n",
    "    \n",
    "    fig.add_trace(go.Histogram(\n",
    "        x=display_data,\n",
    "        nbinsx=50,\n",
    "        name=\"Inter-Event Time\",\n",
    "        marker_color=\"coral\",\n",
    "        opacity=0.7\n",
    "    ))\n",
    "    \n",
    "    fig.add_vline(x=inter_event_series.median(), line_dash=\"solid\", line_color=\"green\",\n",
    "                  annotation_text=f\"Median: {inter_event_series.median():.1f} days\",\n",
    "                  annotation_position=\"top right\")\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"Inter-Event Time Distribution (capped at {cap:.0f} days = 99th percentile)\",\n",
    "        xaxis_title=\"Days Between Events\",\n",
    "        yaxis_title=\"Frequency\",\n",
    "        template=\"plotly_white\",\n",
    "        height=400\n",
    "    )\n",
    "    display_figure(fig)\n",
    "else:\n",
    "    print(\"Not enough multi-event entities to analyze inter-event timing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a714453",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1a.8 Column Distributions\n",
    "\n",
    "Standard column profiling applied to event-level data - distributions, outliers, transformation needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fad82ad",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use framework's DistributionAnalyzer for comprehensive analysis\n",
    "analyzer = DistributionAnalyzer()\n",
    "\n",
    "numeric_cols = [n for n, c in findings.columns.items() \n",
    "                if c.inferred_type.value in ('numeric_continuous', 'numeric_discrete')\n",
    "                and n not in [ENTITY_COLUMN, TIME_COLUMN]]\n",
    "\n",
    "# Analyze all numeric columns using the framework\n",
    "analyses = analyzer.analyze_dataframe(df, numeric_cols)\n",
    "recommendations = {col: analyzer.recommend_transformation(analysis) \n",
    "                   for col, analysis in analyses.items()}\n",
    "\n",
    "# Human-readable transformation names\n",
    "TRANSFORM_DISPLAY_NAMES = {\n",
    "    'none': 'None needed',\n",
    "    'log': 'Log transform',\n",
    "    'log1p': 'Log(1+x) transform',\n",
    "    'sqrt': 'Square root',\n",
    "    'box_cox': 'Box-Cox power transform',\n",
    "    'yeo_johnson': 'Yeo-Johnson power transform',\n",
    "    'quantile': 'Quantile normalization',\n",
    "    'robust_scale': 'Robust scaling (median/IQR)',\n",
    "    'standard_scale': 'Standard scaling (z-score)',\n",
    "    'minmax_scale': 'Min-Max scaling',\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"NUMERIC COLUMN PROFILES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for col_name in numeric_cols:\n",
    "    col_info = findings.columns[col_name]\n",
    "    analysis = analyses.get(col_name)\n",
    "    rec = recommendations.get(col_name)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Column: {col_name}\")\n",
    "    print(f\"Type: {col_info.inferred_type.value} (Confidence: {col_info.confidence:.0%})\")\n",
    "    print(f\"-\" * 70)\n",
    "    \n",
    "    if analysis:\n",
    "        print(f\"üìä Distribution Statistics:\")\n",
    "        print(f\"   Mean: {analysis.mean:.3f}  |  Median: {analysis.median:.3f}  |  Std: {analysis.std:.3f}\")\n",
    "        print(f\"   Range: [{analysis.min_value:.3f}, {analysis.max_value:.3f}]\")\n",
    "        print(f\"   Percentiles: 1%={analysis.percentiles['p1']:.3f}, 25%={analysis.q1:.3f}, 75%={analysis.q3:.3f}, 99%={analysis.percentiles['p99']:.3f}\")\n",
    "        print(f\"\\nüìà Shape Analysis:\")\n",
    "        skew_label = '(Right-skewed)' if analysis.skewness > 0.5 else '(Left-skewed)' if analysis.skewness < -0.5 else '(Symmetric)'\n",
    "        print(f\"   Skewness: {analysis.skewness:.2f} {skew_label}\")\n",
    "        kurt_label = '(Heavy tails/outliers)' if analysis.kurtosis > 3 else '(Light tails)'\n",
    "        print(f\"   Kurtosis: {analysis.kurtosis:.2f} {kurt_label}\")\n",
    "        print(f\"   Zeros: {analysis.zero_count:,} ({analysis.zero_percentage:.1f}%)\")\n",
    "        print(f\"   Outliers (IQR): {analysis.outlier_count_iqr:,} ({analysis.outlier_percentage:.1f}%)\")\n",
    "        \n",
    "        if rec:\n",
    "            transform_display = TRANSFORM_DISPLAY_NAMES.get(rec.recommended_transform.value, rec.recommended_transform.value)\n",
    "            print(f\"\\nüîß Recommended Transformation: {transform_display}\")\n",
    "            print(f\"   Reason: {rec.reason}\")\n",
    "            print(f\"   Priority: {rec.priority}\")\n",
    "            if rec.warnings:\n",
    "                for warn in rec.warnings:\n",
    "                    print(f\"   ‚ö†Ô∏è {warn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6179c66",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Per-column distribution visualizations with transformation recommendations\n",
    "for col_name in numeric_cols:\n",
    "    analysis = analyses.get(col_name)\n",
    "    rec = recommendations.get(col_name)\n",
    "    if not analysis:\n",
    "        continue\n",
    "    \n",
    "    data = df[col_name].dropna()\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Histogram(x=data, nbinsx=50, name='Distribution',\n",
    "                                marker_color='steelblue', opacity=0.7))\n",
    "    \n",
    "    mean_val = data.mean()\n",
    "    median_val = data.median()\n",
    "    \n",
    "    # Position labels on opposite sides to avoid overlap\n",
    "    mean_position = \"top right\" if mean_val >= median_val else \"top left\"\n",
    "    median_position = \"top left\" if mean_val >= median_val else \"top right\"\n",
    "    \n",
    "    fig.add_vline(\n",
    "        x=mean_val, line_dash=\"dash\", line_color=\"red\",\n",
    "        annotation_text=f\"Mean: {mean_val:.2f}\",\n",
    "        annotation_position=mean_position,\n",
    "        annotation_font_color=\"red\",\n",
    "        annotation_bgcolor=\"rgba(255,255,255,0.8)\"\n",
    "    )\n",
    "    \n",
    "    fig.add_vline(\n",
    "        x=median_val, line_dash=\"solid\", line_color=\"green\",\n",
    "        annotation_text=f\"Median: {median_val:.2f}\",\n",
    "        annotation_position=median_position,\n",
    "        annotation_font_color=\"green\",\n",
    "        annotation_bgcolor=\"rgba(255,255,255,0.8)\"\n",
    "    )\n",
    "    \n",
    "    # Add 99th percentile marker if there are outliers\n",
    "    if analysis.outlier_percentage > 5:\n",
    "        fig.add_vline(x=analysis.percentiles['p99'], line_dash=\"dot\", line_color=\"orange\",\n",
    "                      annotation_text=f\"99th: {analysis.percentiles['p99']:.2f}\",\n",
    "                      annotation_position=\"top right\",\n",
    "                      annotation_font_color=\"orange\",\n",
    "                      annotation_bgcolor=\"rgba(255,255,255,0.8)\")\n",
    "    \n",
    "    transform_key = rec.recommended_transform.value if rec else \"none\"\n",
    "    transform_label = TRANSFORM_DISPLAY_NAMES.get(transform_key, transform_key)\n",
    "    fig.update_layout(\n",
    "        title=f\"Distribution: {col_name}<br><sub>Skew: {analysis.skewness:.2f} | Kurt: {analysis.kurtosis:.2f} | Strategy: {transform_label}</sub>\",\n",
    "        xaxis_title=col_name,\n",
    "        yaxis_title=\"Count\",\n",
    "        template='plotly_white',\n",
    "        height=400\n",
    "    )\n",
    "    display_figure(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d8f2d4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CATEGORICAL COLUMN PROFILES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "categorical_cols = [n for n, c in findings.columns.items()\n",
    "                    if c.inferred_type.value in ('categorical_nominal', 'categorical_ordinal', 'binary', 'categorical_cyclical')\n",
    "                    and c.inferred_type != ColumnType.TEXT  # TEXT columns processed separately in 01a_a\n",
    "                    and n not in [ENTITY_COLUMN, TIME_COLUMN]]\n",
    "\n",
    "for col_name in categorical_cols:\n",
    "    col_info = findings.columns[col_name]\n",
    "    cardinality = col_info.universal_metrics.get('distinct_count', df[col_name].nunique())\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Column: {col_name}\")\n",
    "    print(f\"Type: {col_info.inferred_type.value} (Confidence: {col_info.confidence:.0%})\")\n",
    "    print(f\"Distinct Values: {cardinality}\")\n",
    "    \n",
    "    # Encoding recommendation based on type and cardinality\n",
    "    if col_info.inferred_type.value == 'categorical_cyclical':\n",
    "        encoding_rec = \"Sin/Cos encoding (cyclical)\"\n",
    "    elif cardinality <= 5:\n",
    "        encoding_rec = \"One-hot encoding (low cardinality)\"\n",
    "    elif cardinality <= 20:\n",
    "        encoding_rec = \"One-hot or Target encoding\"\n",
    "    else:\n",
    "        encoding_rec = \"Target encoding or Frequency encoding (high cardinality)\"\n",
    "    print(f\"Recommended Encoding: {encoding_rec}\")\n",
    "    \n",
    "    # Value counts visualization\n",
    "    value_counts = df[col_name].value_counts().head(10)\n",
    "    fig = charts.bar_chart(value_counts.index.tolist(), value_counts.values.tolist(),\n",
    "                           title=f\"Top Categories: {col_name}\")\n",
    "    display_figure(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a3ddfe",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRANSFORMATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Human-readable transformation names\n",
    "TRANSFORM_DISPLAY_NAMES = {\n",
    "    'none': 'None needed',\n",
    "    'log': 'Log transform',\n",
    "    'log1p': 'Log(1+x) transform',\n",
    "    'sqrt': 'Square root',\n",
    "    'box_cox': 'Box-Cox power transform',\n",
    "    'yeo_johnson': 'Yeo-Johnson power transform',\n",
    "    'quantile': 'Quantile normalization',\n",
    "    'robust_scale': 'Robust scaling (median/IQR)',\n",
    "    'standard_scale': 'Standard scaling (z-score)',\n",
    "    'minmax_scale': 'Min-Max scaling',\n",
    "}\n",
    "\n",
    "transformations = []\n",
    "for col_name, rec in recommendations.items():\n",
    "    if rec and rec.recommended_transform != TransformationType.NONE:\n",
    "        transform_key = rec.recommended_transform.value\n",
    "        display_name = TRANSFORM_DISPLAY_NAMES.get(transform_key, transform_key)\n",
    "        transformations.append({\n",
    "            'column': col_name,\n",
    "            'transform': display_name,\n",
    "            'reason': rec.reason,\n",
    "            'priority': rec.priority\n",
    "        })\n",
    "\n",
    "if transformations:\n",
    "    print(\"\\nRecommended transformations:\")\n",
    "    # Sort by priority\n",
    "    priority_order = {'high': 0, 'medium': 1, 'low': 2}\n",
    "    transformations.sort(key=lambda x: priority_order.get(x['priority'], 3))\n",
    "    \n",
    "    for t in transformations:\n",
    "        priority_marker = \"üî¥\" if t['priority'] == 'high' else \"üü°\" if t['priority'] == 'medium' else \"üü¢\"\n",
    "        print(f\"\\n   {priority_marker} {t['column']}: {t['transform']}\")\n",
    "        print(f\"      Reason: {t['reason']}\")\n",
    "else:\n",
    "    print(\"\\nNo transformations needed - columns are well-behaved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e52346",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1a.9 Data Segmentation Analysis\n",
    "\n",
    "**Purpose:** Determine if the dataset contains natural subgroups that might benefit from separate models.\n",
    "\n",
    "**üìñ Why This Matters:**\n",
    "- Some datasets have distinct customer segments with very different behaviors\n",
    "- A single model might struggle to capture patterns that vary significantly across segments\n",
    "- Segmented models can improve accuracy but add maintenance complexity\n",
    "\n",
    "**Recommendations:**\n",
    "- **single_model** - Data is homogeneous; one model for all records\n",
    "- **consider_segmentation** - Some variation exists; evaluate if complexity is worth it\n",
    "- **strong_segmentation** - Distinct segments with different target rates; separate models likely beneficial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef1316",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize segment analyzer\n",
    "segment_analyzer = SegmentAnalyzer()\n",
    "\n",
    "# Find target column if detected\n",
    "target_col = None\n",
    "for col_name, col_info in findings.columns.items():\n",
    "    if col_info.inferred_type == ColumnType.TARGET:\n",
    "        target_col = col_name\n",
    "        break\n",
    "\n",
    "# Get numeric feature columns (excluding entity/time columns)\n",
    "feature_cols = [n for n, c in findings.columns.items() \n",
    "                if c.inferred_type.value in ('numeric_continuous', 'numeric_discrete')\n",
    "                and n not in [ENTITY_COLUMN, TIME_COLUMN]]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DATA SEGMENTATION ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if feature_cols:\n",
    "    segmentation = segment_analyzer.analyze(\n",
    "        df,\n",
    "        target_col=target_col,\n",
    "        feature_cols=feature_cols,\n",
    "        max_segments=5\n",
    "    )\n",
    "\n",
    "    print(f\"\\nüéØ Analysis Results:\")\n",
    "    print(f\"   Method: {segmentation.method.value}\")\n",
    "    print(f\"   Detected Segments: {segmentation.n_segments}\")\n",
    "    print(f\"   Cluster Quality Score: {segmentation.quality_score:.2f}\")\n",
    "    if segmentation.target_variance_ratio is not None:\n",
    "        print(f\"   Target Variance Ratio: {segmentation.target_variance_ratio:.2f}\")\n",
    "\n",
    "    print(f\"\\nüìä Segment Profiles:\")\n",
    "    for profile in segmentation.profiles:\n",
    "        target_info = f\" | Target Rate: {profile.target_rate*100:.1f}%\" if profile.target_rate is not None else \"\"\n",
    "        print(f\"   Segment {profile.segment_id}: {profile.size:,} records ({profile.size_pct:.1f}%){target_info}\")\n",
    "\n",
    "    # Display recommendation card\n",
    "    fig = charts.segment_recommendation_card(segmentation)\n",
    "    display_figure(fig)\n",
    "\n",
    "    # Display segment overview\n",
    "    fig = charts.segment_overview(segmentation, title=\"Segment Overview\")\n",
    "    display_figure(fig)\n",
    "\n",
    "    # Display feature comparison if we have features\n",
    "    if segmentation.n_segments > 1 and any(p.defining_features for p in segmentation.profiles):\n",
    "        fig = charts.segment_feature_comparison(segmentation, title=\"Feature Comparison Across Segments\")\n",
    "        display_figure(fig)\n",
    "\n",
    "    print(f\"\\nüìù Rationale:\")\n",
    "    for reason in segmentation.rationale:\n",
    "        print(f\"   ‚Ä¢ {reason}\")\n",
    "else:\n",
    "    print(\"\\nNo numeric feature columns available for segmentation analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d09477",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1a.10 Feature Engineering Opportunities\n",
    "\n",
    "Based on the time series profile, here are recommended aggregation features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd8dd5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Analyze available columns for aggregation\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols = [c for c in numeric_cols if c not in [ENTITY_COLUMN, TIME_COLUMN]]\n",
    "\n",
    "print(\"\\U0001f6e0\\ufe0f Feature Engineering Recommendations:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1\\ufe0f\\u20e3  TIME WINDOW AGGREGATIONS (for each entity):\")\n",
    "windows = [\"24h\", \"7d\", \"30d\", \"90d\", \"180d\", \"365d\", \"all_time\"]\n",
    "print(f\"   Windows: {', '.join(windows)}\")\n",
    "print(f\"   \\n   For event counts:\")\n",
    "for w in windows:\n",
    "    print(f\"      - event_count_{w}\")\n",
    "\n",
    "if numeric_cols:\n",
    "    print(f\"\\n   For numeric columns ({', '.join(numeric_cols[:3])}...):\")\n",
    "    aggs = [\"sum\", \"mean\", \"max\", \"min\"]\n",
    "    print(f\"      Aggregations: {', '.join(aggs)}\")\n",
    "    print(f\"      Example: {numeric_cols[0]}_sum_7d, {numeric_cols[0]}_mean_30d\")\n",
    "\n",
    "print(\"\\n2\\ufe0f\\u20e3  RECENCY FEATURES:\")\n",
    "print(\"   - days_since_last_event\")\n",
    "print(\"   - days_since_first_event (tenure)\")\n",
    "\n",
    "print(\"\\n3\\ufe0f\\u20e3  FREQUENCY FEATURES:\")\n",
    "print(\"   - avg_events_per_day\")\n",
    "print(\"   - avg_inter_event_days\")\n",
    "print(\"   - event_frequency_trend (increasing/decreasing)\")\n",
    "\n",
    "print(\"\\n4\\ufe0f\\u20e3  LIFECYCLE FEATURES:\")\n",
    "print(\"   - lifecycle_duration_days\")\n",
    "print(\"   - is_new_entity (first event in last 30 days)\")\n",
    "print(\"   - activity_segment (one-time, low, medium, high)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b924e5eb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1a.11 Update Findings with Time Series Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ea55d6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from customer_retention.analysis.auto_explorer.findings import TimeSeriesMetadata\n",
    "\n",
    "# Update or create time series metadata\n",
    "ts_metadata = TimeSeriesMetadata(\n",
    "    granularity=DatasetGranularity.EVENT_LEVEL,\n",
    "    entity_column=ENTITY_COLUMN,\n",
    "    time_column=TIME_COLUMN,\n",
    "    avg_events_per_entity=ts_profile.events_per_entity.mean,\n",
    "    time_span_days=ts_profile.time_span_days,\n",
    "    unique_entities=ts_profile.unique_entities,\n",
    "    suggested_aggregations=[\"24h\", \"7d\", \"30d\", \"90d\", \"180d\", \"365d\", \"all_time\"]\n",
    ")\n",
    "\n",
    "findings.time_series_metadata = ts_metadata\n",
    "\n",
    "print(\"\\u2705 Time series metadata updated:\")\n",
    "print(f\"   Entity column: {ts_metadata.entity_column}\")\n",
    "print(f\"   Time column: {ts_metadata.time_column}\")\n",
    "print(f\"   Avg events/entity: {ts_metadata.avg_events_per_entity:.1f}\")\n",
    "print(f\"   Time span: {ts_metadata.time_span_days} days\")\n",
    "print(f\"   Suggested aggregations: {ts_metadata.suggested_aggregations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6b30d0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save updated findings\n",
    "findings.save(FINDINGS_PATH)\n",
    "print(f\"Updated findings saved to: {FINDINGS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647323f0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Summary: What We Learned\n",
    "\n",
    "In this notebook, we performed a deep dive on time series data:\n",
    "\n",
    "1. **Event Distribution** - Analyzed how events are distributed across entities\n",
    "2. **Activity Segments** - Categorized entities by activity level (one-time, low, medium, high)\n",
    "3. **Lifecycle Analysis** - Examined entity tenure and duration patterns\n",
    "4. **Temporal Coverage** - Visualized data volume over time\n",
    "5. **Inter-Event Timing** - Understood engagement frequency patterns\n",
    "6. **Feature Opportunities** - Identified time-window aggregations and recency features\n",
    "\n",
    "## Key Metrics for This Dataset\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Unique Entities | Fill from ts_profile |\n",
    "| Avg Events/Entity | Fill from ts_profile |\n",
    "| Median Lifecycle | Fill from analysis |\n",
    "| Median Inter-Event Days | Fill from analysis |\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Continue with the **Event Bronze Track**:\n",
    "\n",
    "1. **01b_temporal_quality.ipynb** - Check for duplicate events, temporal gaps, future dates\n",
    "2. **01c_temporal_patterns.ipynb** - Detect trends, seasonality, cohort analysis\n",
    "3. **01d_event_aggregation.ipynb** - Aggregate events to entity-level (produces new dataset)\n",
    "\n",
    "After completing 01d, continue with the **Entity Bronze Track** (02 ‚Üí 03 ‚Üí 04) on the aggregated data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2.479884,
   "end_time": "2026-01-22T14:17:45.507144",
   "environment_variables": {},
   "exception": true,
   "input_path": "exploration_notebooks/01a_temporal_deep_dive.ipynb",
   "output_path": "docs/tutorial/executed/01a_temporal_deep_dive.ipynb",
   "parameters": {},
   "start_time": "2026-01-22T14:17:43.027260",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}