{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d606872b",
   "metadata": {
    "papermill": {
     "duration": 0.002974,
     "end_time": "2026-01-29T23:49:45.683306",
     "exception": false,
     "start_time": "2026-01-29T23:49:45.680332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Chapter 10: Pipeline Generation\n",
    "\n",
    "Generate production-ready pipeline code from exploration findings.\n",
    "\n",
    "**Generation Targets:**\n",
    "1. **Local (Feast + MLFlow)** - Local feature store and experiment tracking\n",
    "2. **Databricks (FS + MLFlow)** - Unity Catalog, DLT, Feature Store, MLFlow\n",
    "3. **LLM Documentation** - Markdown files for AI-assisted development\n",
    "\n",
    "**Output Formats:**\n",
    "- Python files (`.py`)\n",
    "- Jupyter notebooks (`.ipynb`)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0466e710",
   "metadata": {
    "papermill": {
     "duration": 0.001998,
     "end_time": "2026-01-29T23:49:45.688121",
     "exception": false,
     "start_time": "2026-01-29T23:49:45.686123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10.1 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a70a02b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-29T23:49:45.693646Z",
     "iopub.status.busy": "2026-01-29T23:49:45.693507Z",
     "iopub.status.idle": "2026-01-29T23:49:46.626425Z",
     "shell.execute_reply": "2026-01-29T23:49:46.626001Z"
    },
    "papermill": {
     "duration": 0.936743,
     "end_time": "2026-01-29T23:49:46.627240",
     "exception": false,
     "start_time": "2026-01-29T23:49:45.690497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: customer_churn\n",
      "Target: local\n",
      "Format: py\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "\n",
    "class GenerationTarget(Enum):\n",
    "    LOCAL_FEAST_MLFLOW = \"local\"\n",
    "    DATABRICKS = \"databricks\"\n",
    "    LLM_DOCS = \"llm_docs\"\n",
    "\n",
    "class OutputFormat(Enum):\n",
    "    PYTHON = \"py\"\n",
    "    NOTEBOOK = \"ipynb\"\n",
    "\n",
    "# === USER CONFIGURATION ===\n",
    "PIPELINE_NAME = \"customer_churn\"\n",
    "GENERATION_TARGET = GenerationTarget.LOCAL_FEAST_MLFLOW\n",
    "OUTPUT_FORMAT = OutputFormat.PYTHON\n",
    "\n",
    "# Paths\n",
    "# FINDINGS_DIR imported from customer_retention.core.config.experiments\n",
    "OUTPUT_BASE_DIR = Path(\"../generated_pipelines\")\n",
    "\n",
    "# Databricks settings (only used when GENERATION_TARGET == DATABRICKS)\n",
    "DATABRICKS_CATALOG = \"main\"\n",
    "DATABRICKS_SCHEMA = \"ml_features\"\n",
    "\n",
    "print(f\"Pipeline: {PIPELINE_NAME}\")\n",
    "print(f\"Target: {GENERATION_TARGET.value}\")\n",
    "print(f\"Format: {OUTPUT_FORMAT.value}\")\n",
    "from customer_retention.stages.temporal import TEMPORAL_METADATA_COLS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73f46fa",
   "metadata": {
    "papermill": {
     "duration": 0.001985,
     "end_time": "2026-01-29T23:49:46.631270",
     "exception": false,
     "start_time": "2026-01-29T23:49:46.629285",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10.2 Load Findings and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da968603",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-29T23:49:46.635612Z",
     "iopub.status.busy": "2026-01-29T23:49:46.635424Z",
     "iopub.status.idle": "2026-01-29T23:49:47.425619Z",
     "shell.execute_reply": "2026-01-29T23:49:47.425113Z"
    },
    "papermill": {
     "duration": 0.793407,
     "end_time": "2026-01-29T23:49:47.426342",
     "exception": false,
     "start_time": "2026-01-29T23:49:46.632935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded recommendations from: customer_emails_408768_aggregated_846212_recommendations.yaml\n",
      "Loaded: /Users/Vital/python/CustomerRetention/experiments/findings/customer_emails_408768_aggregated.parquet\n",
      "Rows: 4,998 | Columns: 72\n",
      "Target: target\n",
      "Recommendations: Loaded\n",
      "Multi-dataset: Loaded\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from customer_retention.analysis.auto_explorer import ExplorationFindings\n",
    "from customer_retention.analysis.auto_explorer.layered_recommendations import RecommendationRegistry\n",
    "from customer_retention.core.config.experiments import FINDINGS_DIR, EXPERIMENTS_DIR, OUTPUT_DIR, setup_experiments_structure\n",
    "\n",
    "def load_findings_and_recommendations(findings_dir: Path):\n",
    "    findings_files = sorted(\n",
    "        [f for f in findings_dir.glob(\"*_findings.yaml\") if \"multi_dataset\" not in f.name],\n",
    "        key=lambda f: f.stat().st_mtime, reverse=True\n",
    "    )\n",
    "    if not findings_files:\n",
    "        raise FileNotFoundError(f\"No findings in {findings_dir}. Run exploration notebooks first.\")\n",
    "    \n",
    "    findings = ExplorationFindings.load(str(findings_files[0]))\n",
    "    \n",
    "    # Look for recommendations file matching the findings file pattern\n",
    "    # Step 06 saves as: {name}_recommendations.yaml (matching {name}_findings.yaml)\n",
    "    findings_name = findings_files[0].stem.replace(\"_findings\", \"\")\n",
    "    recommendations_path = findings_dir / f\"{findings_name}_recommendations.yaml\"\n",
    "    \n",
    "    # Fallback to generic recommendations.yaml if not found\n",
    "    if not recommendations_path.exists():\n",
    "        recommendations_path = findings_dir / \"recommendations.yaml\"\n",
    "    \n",
    "    # Final fallback: find any *_recommendations.yaml\n",
    "    if not recommendations_path.exists():\n",
    "        rec_files = sorted(findings_dir.glob(\"*_recommendations.yaml\"), \n",
    "                          key=lambda f: f.stat().st_mtime, reverse=True)\n",
    "        if rec_files:\n",
    "            recommendations_path = rec_files[0]\n",
    "    \n",
    "    registry = None\n",
    "    if recommendations_path.exists():\n",
    "        with open(recommendations_path) as f:\n",
    "            registry = RecommendationRegistry.from_dict(yaml.safe_load(f))\n",
    "        print(f\"Loaded recommendations from: {recommendations_path.name}\")\n",
    "    \n",
    "    multi_dataset_path = findings_dir / \"multi_dataset_findings.yaml\"\n",
    "    multi_dataset = None\n",
    "    if multi_dataset_path.exists():\n",
    "        with open(multi_dataset_path) as f:\n",
    "            multi_dataset = yaml.safe_load(f)\n",
    "    \n",
    "    return findings, registry, multi_dataset\n",
    "\n",
    "findings, registry, multi_dataset = load_findings_and_recommendations(FINDINGS_DIR)\n",
    "\n",
    "print(f\"Loaded: {findings.source_path}\")\n",
    "print(f\"Rows: {findings.row_count:,} | Columns: {findings.column_count}\")\n",
    "print(f\"Target: {findings.target_column}\")\n",
    "print(f\"Recommendations: {'Loaded' if registry else 'Not found'}\")\n",
    "print(f\"Multi-dataset: {'Loaded' if multi_dataset else 'Not found'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f777c05c",
   "metadata": {
    "papermill": {
     "duration": 0.001704,
     "end_time": "2026-01-29T23:49:47.430241",
     "exception": false,
     "start_time": "2026-01-29T23:49:47.428537",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10.3 Review Layered Recommendations\n",
    "\n",
    "Recommendations are organized by medallion layer:\n",
    "- **Bronze**: null_handling, outlier_handling, type_conversions, deduplication, filtering, text_processing\n",
    "- **Silver**: joins, aggregations, derived_columns\n",
    "- **Gold**: encoding, scaling, feature_selection, transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a1dca4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-29T23:49:47.434914Z",
     "iopub.status.busy": "2026-01-29T23:49:47.434740Z",
     "iopub.status.idle": "2026-01-29T23:49:47.437622Z",
     "shell.execute_reply": "2026-01-29T23:49:47.437139Z"
    },
    "papermill": {
     "duration": 0.006239,
     "end_time": "2026-01-29T23:49:47.438361",
     "exception": false,
     "start_time": "2026-01-29T23:49:47.432122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BRONZE (52 recommendations):\n",
      "--------------------------------------------------\n",
      "  [null] opened_mean_180d: impute\n",
      "  [null] opened_max_180d: impute\n",
      "  [null] clicked_mean_180d: impute\n",
      "  [null] clicked_max_180d: impute\n",
      "  [null] send_hour_mean_180d: impute\n",
      "  ... and 47 more\n",
      "\n",
      "SILVER (8 recommendations):\n",
      "--------------------------------------------------\n",
      "  [derived] event_count_180d_to_event_count_180d_ratio: ratio\n",
      "  [derived] event_count_180d_x_event_count_365d: interaction\n",
      "  [derived] event_count_180d_x_event_count_all_time: interaction\n",
      "  [derived] event_count_180d_x_opened_sum_180d: interaction\n",
      "  [derived] event_count_365d_x_event_count_all_time: interaction\n",
      "  ... and 3 more\n",
      "\n",
      "GOLD (303 recommendations):\n",
      "--------------------------------------------------\n",
      "  [encoding] lifecycle_quadrant: one_hot\n",
      "  [encoding] recency_bucket: one_hot\n",
      "  [encoding] lifecycle_quadrant: onehot\n",
      "  [encoding] recency_bucket: onehot\n",
      "  [scaling] send_hour_mean_180d: standard\n",
      "  ... and 298 more\n"
     ]
    }
   ],
   "source": [
    "def display_recommendations(registry: RecommendationRegistry):\n",
    "    if not registry:\n",
    "        print(\"No recommendations loaded. Run notebooks 02-07 first.\")\n",
    "        return\n",
    "    \n",
    "    for layer in [\"bronze\", \"silver\", \"gold\"]:\n",
    "        recs = registry.get_by_layer(layer)\n",
    "        print(f\"\\n{layer.upper()} ({len(recs)} recommendations):\")\n",
    "        print(\"-\" * 50)\n",
    "        for rec in recs[:5]:\n",
    "            print(f\"  [{rec.category}] {rec.target_column}: {rec.action}\")\n",
    "        if len(recs) > 5:\n",
    "            print(f\"  ... and {len(recs) - 5} more\")\n",
    "\n",
    "display_recommendations(registry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f72471b",
   "metadata": {
    "papermill": {
     "duration": 0.001903,
     "end_time": "2026-01-29T23:49:47.442194",
     "exception": false,
     "start_time": "2026-01-29T23:49:47.440291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 10.4 Generate Pipeline\n",
    "\n",
    "Select generation based on configured target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13071a94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-29T23:49:47.446871Z",
     "iopub.status.busy": "2026-01-29T23:49:47.446754Z",
     "iopub.status.idle": "2026-01-29T23:49:47.449085Z",
     "shell.execute_reply": "2026-01-29T23:49:47.448525Z"
    },
    "papermill": {
     "duration": 0.005477,
     "end_time": "2026-01-29T23:49:47.449701",
     "exception": false,
     "start_time": "2026-01-29T23:49:47.444224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: ../generated_pipelines/local/customer_churn\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "output_dir = OUTPUT_BASE_DIR / GENERATION_TARGET.value / PIPELINE_NAME\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212ece85",
   "metadata": {
    "papermill": {
     "duration": 0.001743,
     "end_time": "2026-01-29T23:49:47.453364",
     "exception": false,
     "start_time": "2026-01-29T23:49:47.451621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Option A: Local (Feast + MLFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb514612",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-29T23:49:47.457242Z",
     "iopub.status.busy": "2026-01-29T23:49:47.457140Z",
     "iopub.status.idle": "2026-01-29T23:49:47.877508Z",
     "shell.execute_reply": "2026-01-29T23:49:47.877009Z"
    },
    "papermill": {
     "duration": 0.423032,
     "end_time": "2026-01-29T23:49:47.877991",
     "exception": false,
     "start_time": "2026-01-29T23:49:47.454959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated MLflow pipeline files:\n",
      "  pipeline.py\n",
      "  requirements.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated pipeline files (Bronze/Silver/Gold/Training):\n",
      "  ../generated_pipelines/local/customer_churn/run_all.py\n",
      "  ../generated_pipelines/local/customer_churn/config.py\n",
      "  ../generated_pipelines/local/customer_churn/bronze/bronze_customer_emails_aggregated.py\n",
      "  ../generated_pipelines/local/customer_churn/silver/silver_merge.py\n",
      "  ../generated_pipelines/local/customer_churn/gold/gold_features.py\n",
      "  ../generated_pipelines/local/customer_churn/training/ml_experiment.py\n",
      "  ../generated_pipelines/local/customer_churn/pipeline_runner.py\n",
      "  ../generated_pipelines/local/customer_churn/workflow.json\n",
      "  ../generated_pipelines/local/customer_churn/feature_repo/feature_store.yaml\n",
      "  ../generated_pipelines/local/customer_churn/feature_repo/features.py\n",
      "  ../generated_pipelines/local/customer_churn/scoring/run_scoring.py\n",
      "  ../generated_pipelines/local/customer_churn/scoring/scoring_dashboard.ipynb\n"
     ]
    }
   ],
   "source": [
    "if GENERATION_TARGET == GenerationTarget.LOCAL_FEAST_MLFLOW:\n",
    "    from customer_retention.generators.spec_generator import MLflowPipelineGenerator, MLflowConfig\n",
    "    from customer_retention.generators.pipeline_generator import PipelineGenerator\n",
    "    \n",
    "    mlflow_config = MLflowConfig(\n",
    "        tracking_uri=\"./mlruns\",\n",
    "        experiment_name=PIPELINE_NAME,\n",
    "        log_data_quality=True,\n",
    "        nested_runs=True\n",
    "    )\n",
    "    \n",
    "    mlflow_gen = MLflowPipelineGenerator(mlflow_config=mlflow_config, output_dir=str(output_dir))\n",
    "    \n",
    "    if OUTPUT_FORMAT == OutputFormat.PYTHON:\n",
    "        saved = mlflow_gen.save_all(findings)\n",
    "        print(\"Generated MLflow pipeline files:\")\n",
    "        for f in saved:\n",
    "            print(f\"  {f}\")\n",
    "    \n",
    "    if multi_dataset:\n",
    "        pipeline_gen = PipelineGenerator(\n",
    "            findings_dir=str(FINDINGS_DIR),\n",
    "            output_dir=str(output_dir),\n",
    "            pipeline_name=PIPELINE_NAME\n",
    "        )\n",
    "        orch_files = pipeline_gen.generate()\n",
    "        print(\"\\nGenerated pipeline files (Bronze/Silver/Gold/Training):\")\n",
    "        for f in orch_files:\n",
    "            print(f\"  {f}\")\n",
    "else:\n",
    "    print(f\"Skipping Local generation (target is {GENERATION_TARGET.value})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bd2b40",
   "metadata": {
    "papermill": {
     "duration": 0.001734,
     "end_time": "2026-01-29T23:49:47.882204",
     "exception": false,
     "start_time": "2026-01-29T23:49:47.880470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Option B: Databricks (FS + MLFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1a47899",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-29T23:49:47.886558Z",
     "iopub.status.busy": "2026-01-29T23:49:47.886396Z",
     "iopub.status.idle": "2026-01-29T23:49:47.889162Z",
     "shell.execute_reply": "2026-01-29T23:49:47.888774Z"
    },
    "papermill": {
     "duration": 0.005693,
     "end_time": "2026-01-29T23:49:47.889683",
     "exception": false,
     "start_time": "2026-01-29T23:49:47.883990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Databricks generation (target is local)\n"
     ]
    }
   ],
   "source": [
    "if GENERATION_TARGET == GenerationTarget.DATABRICKS:\n",
    "    from customer_retention.generators.spec_generator import DatabricksSpecGenerator, PipelineSpec, SourceSpec\n",
    "    \n",
    "    spec = PipelineSpec(\n",
    "        name=PIPELINE_NAME,\n",
    "        version=\"1.0.0\",\n",
    "        sources=[SourceSpec(\n",
    "            name=findings.source_path.split(\"/\")[-1].replace(\".csv\", \"\"),\n",
    "            path=findings.source_path,\n",
    "            format=findings.source_format\n",
    "        )]\n",
    "    )\n",
    "    \n",
    "    if findings.target_column:\n",
    "        from customer_retention.generators.spec_generator import ModelSpec\n",
    "        spec.model_config = ModelSpec(\n",
    "            name=f\"{PIPELINE_NAME}_model\",\n",
    "            model_type=\"gradient_boosting\",\n",
    "            target_column=findings.target_column\n",
    "        )\n",
    "    \n",
    "    db_gen = DatabricksSpecGenerator(\n",
    "        catalog=DATABRICKS_CATALOG,\n",
    "        schema=DATABRICKS_SCHEMA,\n",
    "        output_dir=str(output_dir)\n",
    "    )\n",
    "    \n",
    "    saved = db_gen.save_all(spec)\n",
    "    print(\"Generated Databricks artifacts:\")\n",
    "    for f in saved:\n",
    "        print(f\"  {f}\")\n",
    "else:\n",
    "    print(f\"Skipping Databricks generation (target is {GENERATION_TARGET.value})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306c4c63",
   "metadata": {
    "papermill": {
     "duration": 0.001973,
     "end_time": "2026-01-29T23:49:47.893660",
     "exception": false,
     "start_time": "2026-01-29T23:49:47.891687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Option C: LLM Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2ecf763",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-29T23:49:47.898587Z",
     "iopub.status.busy": "2026-01-29T23:49:47.898456Z",
     "iopub.status.idle": "2026-01-29T23:49:47.905383Z",
     "shell.execute_reply": "2026-01-29T23:49:47.904911Z"
    },
    "papermill": {
     "duration": 0.010039,
     "end_time": "2026-01-29T23:49:47.905838",
     "exception": false,
     "start_time": "2026-01-29T23:49:47.895799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping LLM docs generation (target is local)\n"
     ]
    }
   ],
   "source": [
    "if GENERATION_TARGET == GenerationTarget.LLM_DOCS:\n",
    "    from customer_retention.analysis.auto_explorer import RecommendationEngine\n",
    "    \n",
    "    recommender = RecommendationEngine()\n",
    "    target_rec = recommender.recommend_target(findings)\n",
    "    feature_recs = recommender.recommend_features(findings)\n",
    "    cleaning_recs = recommender.recommend_cleaning(findings)\n",
    "    \n",
    "    docs_dir = output_dir / \"docs\"\n",
    "    docs_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 1. Overview\n",
    "    overview = f\"\"\"# {PIPELINE_NAME} Pipeline Overview\n",
    "\n",
    "## Data Source\n",
    "- **Path**: {findings.source_path}\n",
    "- **Format**: {findings.source_format}\n",
    "- **Rows**: {findings.row_count:,}\n",
    "- **Columns**: {findings.column_count}\n",
    "- **Quality Score**: {findings.overall_quality_score:.1f}/100\n",
    "\n",
    "## Target Variable\n",
    "- **Column**: {target_rec.column_name}\n",
    "- **Type**: {target_rec.target_type}\n",
    "- **Rationale**: {target_rec.rationale}\n",
    "\n",
    "## Column Types\n",
    "| Column | Type | Nulls | Unique |\n",
    "|--------|------|-------|--------|\n",
    "\"\"\"\n",
    "    for name, col in list(findings.columns.items())[:20]:\n",
    "        overview += f\"| {name} | {col.inferred_type.value} | {col.null_percentage:.1f}% | {col.unique_count} |\\n\"\n",
    "    (docs_dir / \"01_overview.md\").write_text(overview)\n",
    "    \n",
    "    # 2. Bronze layer - separate file per source\n",
    "    if registry and registry.sources:\n",
    "        for source_name, bronze_recs in registry.sources.items():\n",
    "            bronze_doc = f\"\"\"# Bronze Layer - {source_name}\n",
    "\n",
    "## Source File\n",
    "`{bronze_recs.source_file}`\n",
    "\n",
    "## Null Handling\n",
    "\"\"\"\n",
    "            for rec in bronze_recs.null_handling:\n",
    "                bronze_doc += f\"- `{rec.target_column}`: {rec.action} ({rec.parameters.get('strategy', '')}) - {rec.rationale}\\n\"\n",
    "            \n",
    "            bronze_doc += \"\\n## Outlier Handling\\n\"\n",
    "            for rec in bronze_recs.outlier_handling:\n",
    "                bronze_doc += f\"- `{rec.target_column}`: {rec.action} - {rec.rationale}\\n\"\n",
    "            \n",
    "            bronze_doc += \"\\n## Type Conversions\\n\"\n",
    "            for rec in bronze_recs.type_conversions:\n",
    "                bronze_doc += f\"- `{rec.target_column}`: {rec.action} - {rec.rationale}\\n\"\n",
    "            \n",
    "            bronze_doc += \"\\n## Deduplication\\n\"\n",
    "            for rec in bronze_recs.deduplication:\n",
    "                bronze_doc += f\"- `{rec.target_column}`: {rec.action} - {rec.rationale}\\n\"\n",
    "            \n",
    "            bronze_doc += \"\\n## Filtering\\n\"\n",
    "            for rec in bronze_recs.filtering:\n",
    "                bronze_doc += f\"- `{rec.target_column}`: {rec.action} - {rec.rationale}\\n\"\n",
    "            \n",
    "            bronze_doc += \"\\n## Text Processing\\n\"\n",
    "            for rec in bronze_recs.text_processing:\n",
    "                bronze_doc += f\"- `{rec.target_column}`: {rec.action} - {rec.rationale}\\n\"\n",
    "            \n",
    "            safe_name = source_name.replace(\" \", \"_\").lower()\n",
    "            (docs_dir / f\"02_bronze_cleaning_{safe_name}.md\").write_text(bronze_doc)\n",
    "    else:\n",
    "        bronze_doc = f\"\"\"# Bronze Layer - Data Cleaning\n",
    "\n",
    "## Cleaning Recommendations\n",
    "\"\"\"\n",
    "        for rec in cleaning_recs:\n",
    "            bronze_doc += f\"\\n### {rec.column_name}\\n- **Strategy**: {rec.strategy}\\n- **Severity**: {rec.severity}\\n- **Rationale**: {rec.rationale}\\n\"\n",
    "        (docs_dir / \"02_bronze_cleaning.md\").write_text(bronze_doc)\n",
    "    \n",
    "    # 3. Silver layer\n",
    "    silver_doc = \"\"\"# Silver Layer - Feature Engineering\n",
    "\n",
    "## Aggregations and Joins\n",
    "\"\"\"\n",
    "    if registry and registry.silver:\n",
    "        silver_doc += \"\\n### Joins\\n\"\n",
    "        for rec in registry.silver.joins:\n",
    "            silver_doc += f\"- {rec.parameters.get('left_source', '')} âŸ· {rec.parameters.get('right_source', '')} on `{rec.parameters.get('join_keys', [])}`\\n\"\n",
    "        \n",
    "        silver_doc += \"\\n### Aggregations\\n\"\n",
    "        for rec in registry.silver.aggregations:\n",
    "            silver_doc += f\"- `{rec.target_column}`: {rec.action} - windows: {rec.parameters.get('windows', [])}\\n\"\n",
    "        \n",
    "        silver_doc += \"\\n### Derived Columns\\n\"\n",
    "        for rec in registry.silver.derived_columns:\n",
    "            silver_doc += f\"- `{rec.target_column}`: {rec.parameters.get('expression', rec.action)}\\n\"\n",
    "    else:\n",
    "        silver_doc += \"\\nNo silver-layer recommendations found.\\n\"\n",
    "    (docs_dir / \"03_silver_features.md\").write_text(silver_doc)\n",
    "    \n",
    "    # 4. Gold layer\n",
    "    gold_doc = \"\"\"# Gold Layer - ML Features\n",
    "\n",
    "## Feature Recommendations\n",
    "\"\"\"\n",
    "    for rec in feature_recs[:15]:\n",
    "        gold_doc += f\"\\n### {rec.feature_name}\\n- **Source**: {rec.source_column}\\n- **Type**: {rec.feature_type}\\n- **Description**: {rec.description}\\n\"\n",
    "    \n",
    "    if registry and registry.gold:\n",
    "        gold_doc += \"\\n## Encoding\\n\"\n",
    "        for rec in registry.gold.encoding:\n",
    "            gold_doc += f\"- `{rec.target_column}`: {rec.parameters.get('method', rec.action)}\\n\"\n",
    "        \n",
    "        gold_doc += \"\\n## Scaling\\n\"\n",
    "        for rec in registry.gold.scaling:\n",
    "            gold_doc += f\"- `{rec.target_column}`: {rec.parameters.get('method', rec.action)}\\n\"\n",
    "        \n",
    "        gold_doc += \"\\n## Feature Selection\\n\"\n",
    "        for rec in registry.gold.feature_selection:\n",
    "            gold_doc += f\"- `{rec.target_column}`: {rec.action} - {rec.rationale}\\n\"\n",
    "        \n",
    "        gold_doc += \"\\n## Transformations\\n\"\n",
    "        for rec in registry.gold.transformations:\n",
    "            gold_doc += f\"- `{rec.target_column}`: {rec.action} - {rec.parameters}\\n\"\n",
    "    (docs_dir / \"04_gold_ml_features.md\").write_text(gold_doc)\n",
    "    \n",
    "    # 5. Training\n",
    "    training_doc = f\"\"\"# Model Training\n",
    "\n",
    "## Target\n",
    "- **Column**: {target_rec.column_name}\n",
    "- **Type**: {target_rec.target_type}\n",
    "\n",
    "## Recommended Models\n",
    "1. **Gradient Boosting** - Good for tabular data with mixed types\n",
    "2. **Random Forest** - Robust baseline, handles missing values\n",
    "3. **Logistic Regression** - Interpretable, good for imbalanced data\n",
    "\n",
    "## Evaluation Metrics\n",
    "- ROC-AUC (primary)\n",
    "- Precision/Recall at threshold\n",
    "- F1 Score\n",
    "\"\"\"\n",
    "    (docs_dir / \"05_training.md\").write_text(training_doc)\n",
    "    \n",
    "    print(\"Generated LLM documentation:\")\n",
    "    for f in sorted(docs_dir.glob(\"*.md\")):\n",
    "        print(f\"  {f.name}\")\n",
    "else:\n",
    "    print(f\"Skipping LLM docs generation (target is {GENERATION_TARGET.value})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2ac87f",
   "metadata": {
    "papermill": {
     "duration": 0.001943,
     "end_time": "2026-01-29T23:49:47.909882",
     "exception": false,
     "start_time": "2026-01-29T23:49:47.907939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 10.5 Convert to Notebooks (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dda5fc77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-29T23:49:47.914894Z",
     "iopub.status.busy": "2026-01-29T23:49:47.914776Z",
     "iopub.status.idle": "2026-01-29T23:49:47.919404Z",
     "shell.execute_reply": "2026-01-29T23:49:47.918746Z"
    },
    "papermill": {
     "duration": 0.007977,
     "end_time": "2026-01-29T23:49:47.920017",
     "exception": false,
     "start_time": "2026-01-29T23:49:47.912040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output format is Python. Set OUTPUT_FORMAT = OutputFormat.NOTEBOOK to convert.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def py_to_notebook(py_path: Path):\n",
    "    content = py_path.read_text()\n",
    "    cells = []\n",
    "    current_lines = []\n",
    "    \n",
    "    for line in content.split(\"\\n\"):\n",
    "        if line.startswith(\"# %% \") or line.startswith(\"# %%\\n\"):\n",
    "            if current_lines:\n",
    "                cells.append({\"cell_type\": \"code\", \"metadata\": {}, \"source\": current_lines, \"outputs\": [], \"execution_count\": None})\n",
    "                current_lines = []\n",
    "            title = line.replace(\"# %% \", \"\").strip()\n",
    "            if title:\n",
    "                cells.append({\"cell_type\": \"markdown\", \"metadata\": {}, \"source\": [f\"## {title}\"]})\n",
    "        else:\n",
    "            current_lines.append(line + \"\\n\")\n",
    "    \n",
    "    if current_lines:\n",
    "        cells.append({\"cell_type\": \"code\", \"metadata\": {}, \"source\": current_lines, \"outputs\": [], \"execution_count\": None})\n",
    "    \n",
    "    notebook = {\n",
    "        \"cells\": cells,\n",
    "        \"metadata\": {\"kernelspec\": {\"display_name\": \"Python 3\", \"language\": \"python\", \"name\": \"python3\"}},\n",
    "        \"nbformat\": 4, \"nbformat_minor\": 4\n",
    "    }\n",
    "    \n",
    "    out_path = py_path.with_suffix(\".ipynb\")\n",
    "    out_path.write_text(json.dumps(notebook, indent=1))\n",
    "    return out_path\n",
    "\n",
    "if OUTPUT_FORMAT == OutputFormat.NOTEBOOK:\n",
    "    print(\"Converting Python files to notebooks...\")\n",
    "    for py_file in output_dir.rglob(\"*.py\"):\n",
    "        if py_file.name != \"__init__.py\":\n",
    "            nb_path = py_to_notebook(py_file)\n",
    "            print(f\"  {py_file.name} -> {nb_path.name}\")\n",
    "else:\n",
    "    print(\"Output format is Python. Set OUTPUT_FORMAT = OutputFormat.NOTEBOOK to convert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f077300d",
   "metadata": {
    "papermill": {
     "duration": 0.001999,
     "end_time": "2026-01-29T23:49:47.924372",
     "exception": false,
     "start_time": "2026-01-29T23:49:47.922373",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 10.6 Run Pipeline\n",
    "\n",
    "Single command runs everything: Bronze (parallel) â†’ Silver â†’ Gold â†’ Training â†’ MLflow UI (auto-opens browser)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afa15261",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-29T23:49:47.929524Z",
     "iopub.status.busy": "2026-01-29T23:49:47.929402Z",
     "iopub.status.idle": "2026-01-29T23:49:51.301806Z",
     "shell.execute_reply": "2026-01-29T23:49:51.301178Z"
    },
    "papermill": {
     "duration": 3.375862,
     "end_time": "2026-01-29T23:49:51.302506",
     "exception": false,
     "start_time": "2026-01-29T23:49:47.926644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: python ../generated_pipelines/local/customer_churn/run_all.py\n",
      "Pipeline will run and MLflow UI will open automatically...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running customer_churn\n",
      "==================================================\n",
      "Experiments directory: /Users/Vital/python/CustomerRetention/experiments\n",
      "MLflow tracking: sqlite:////Users/Vital/python/CustomerRetention/experiments/mlruns.db\n",
      "Findings directory: /Users/Vital/python/CustomerRetention/experiments/findings\n",
      "\n",
      "[1/4] Bronze (parallel)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/Vital/python/CustomerRetention/generated_pipelines/local/customer_churn/run_all.py\", line 110, in <module>\n",
      "    run_pipeline()\n",
      "  File \"/Users/Vital/python/CustomerRetention/generated_pipelines/local/customer_churn/run_all.py\", line 82, in run_pipeline\n",
      "    run_bronze_parallel()\n",
      "  File \"/Users/Vital/python/CustomerRetention/generated_pipelines/local/customer_churn/run_all.py\", line 44, in run_bronze_parallel\n",
      "    list(ex.map(lambda f: f(), bronze_funcs))\n",
      "  File \"/opt/anaconda3/lib/python3.12/concurrent/futures/_base.py\", line 619, in result_iterator\n",
      "    yield _result_or_cancel(fs.pop())\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/concurrent/futures/_base.py\", line 317, in _result_or_cancel\n",
      "    return fut.result(timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/concurrent/futures/_base.py\", line 456, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/opt/anaconda3/lib/python3.12/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Vital/python/CustomerRetention/generated_pipelines/local/customer_churn/run_all.py\", line 44, in <lambda>\n",
      "    list(ex.map(lambda f: f(), bronze_funcs))\n",
      "                          ^^^\n",
      "  File \"/Users/Vital/python/CustomerRetention/generated_pipelines/local/customer_churn/bronze/bronze_customer_emails_aggregated.py\", line 24, in run_bronze_customer_emails_aggregated\n",
      "    df = load_customer_emails_aggregated()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Vital/python/CustomerRetention/generated_pipelines/local/customer_churn/bronze/bronze_customer_emails_aggregated.py\", line 12, in load_customer_emails_aggregated\n",
      "    raise FileNotFoundError(f\"Source file not found: {path}\")\n",
      "FileNotFoundError: Source file not found: /Users/Vital/python/CustomerRetention/customer_emails_408768_aggregated.parquet\n"
     ]
    }
   ],
   "source": [
    "# Uncomment below to run the pipeline after generation\n",
    "# RUN_PIPELINE = True\n",
    "\n",
    "RUN_PIPELINE = True\n",
    "\n",
    "run_all_path = output_dir / \"run_all.py\"\n",
    "\n",
    "if RUN_PIPELINE and GENERATION_TARGET == GenerationTarget.LOCAL_FEAST_MLFLOW:\n",
    "    import subprocess\n",
    "    if run_all_path.exists():\n",
    "        print(f\"Running: python {run_all_path}\")\n",
    "        print(\"Pipeline will run and MLflow UI will open automatically...\")\n",
    "        subprocess.run([\"python\", \"run_all.py\"], cwd=str(run_all_path.parent.resolve()))\n",
    "    else:\n",
    "        print(f\"run_all.py not found. Generate first by running cells above.\")\n",
    "else:\n",
    "    print(\"To run the complete pipeline:\")\n",
    "    print(f\"\\n  cd {output_dir}\")\n",
    "    print(f\"  python run_all.py\")\n",
    "    print(f\"\\nThis will:\")\n",
    "    print(\"  1. Run Bronze layers (parallel)\")\n",
    "    print(\"  2. Run Silver merge\")\n",
    "    print(\"  3. Run Gold features\")\n",
    "    print(\"  4. Train models with MLflow\")\n",
    "    print(\"  5. Auto-start MLflow UI and open browser\")\n",
    "    print(\"  6. Press Ctrl+C to stop MLflow UI when done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff846b6",
   "metadata": {
    "papermill": {
     "duration": 0.002002,
     "end_time": "2026-01-29T23:49:51.306887",
     "exception": false,
     "start_time": "2026-01-29T23:49:51.304885",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 10.7 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20fc9754",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-29T23:49:51.311802Z",
     "iopub.status.busy": "2026-01-29T23:49:51.311646Z",
     "iopub.status.idle": "2026-01-29T23:49:51.316850Z",
     "shell.execute_reply": "2026-01-29T23:49:51.316187Z"
    },
    "papermill": {
     "duration": 0.008569,
     "end_time": "2026-01-29T23:49:51.317414",
     "exception": false,
     "start_time": "2026-01-29T23:49:51.308845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Artifacts Summary\n",
      "============================================================\n",
      "Pipeline: customer_churn\n",
      "Target: local\n",
      "Format: py\n",
      "Output: ../generated_pipelines/local/customer_churn\n",
      "\n",
      "â”œâ”€â”€ __pycache__/\n",
      "â”‚   â””â”€â”€ config.cpython-312.pyc (3,040 bytes)\n",
      "â”œâ”€â”€ bronze/\n",
      "â”‚   â”œâ”€â”€ __pycache__/\n",
      "â”‚   â”‚   â””â”€â”€ bronze_customer_emails_aggregated.cpython-312.pyc (1,709 bytes)\n",
      "â”‚   â””â”€â”€ bronze_customer_emails_aggregated.py (891 bytes)\n",
      "â”œâ”€â”€ feature_repo/\n",
      "â”‚   â”œâ”€â”€ data/\n",
      "â”‚   â”‚   â””â”€â”€ registry.db (55 bytes)\n",
      "â”‚   â”œâ”€â”€ feature_store.yaml (188 bytes)\n",
      "â”‚   â””â”€â”€ features.py (1,112 bytes)\n",
      "â”œâ”€â”€ gold/\n",
      "â”‚   â”œâ”€â”€ __pycache__/\n",
      "â”‚   â”‚   â””â”€â”€ gold_features.cpython-312.pyc (4,998 bytes)\n",
      "â”‚   â””â”€â”€ gold_features.py (3,269 bytes)\n",
      "â”œâ”€â”€ scoring/\n",
      "â”‚   â”œâ”€â”€ mlruns/\n",
      "â”‚   â”œâ”€â”€ run_scoring.py (8,077 bytes)\n",
      "â”‚   â””â”€â”€ scoring_dashboard.ipynb (26,598 bytes)\n",
      "â”œâ”€â”€ silver/\n",
      "â”‚   â”œâ”€â”€ __pycache__/\n",
      "â”‚   â”‚   â””â”€â”€ silver_merge.cpython-312.pyc (4,034 bytes)\n",
      "â”‚   â””â”€â”€ silver_merge.py (2,940 bytes)\n",
      "â”œâ”€â”€ training/\n",
      "â”‚   â”œâ”€â”€ __pycache__/\n",
      "â”‚   â”‚   â””â”€â”€ ml_experiment.cpython-312.pyc (13,281 bytes)\n",
      "â”‚   â””â”€â”€ ml_experiment.py (10,130 bytes)\n",
      "â”œâ”€â”€ config.py (2,403 bytes)\n",
      "â”œâ”€â”€ pipeline.py (8,589 bytes)\n",
      "â”œâ”€â”€ pipeline_runner.py (1,343 bytes)\n",
      "â”œâ”€â”€ requirements.txt (111 bytes)\n",
      "â”œâ”€â”€ run_all.py (3,312 bytes)\n",
      "â””â”€â”€ workflow.json (968 bytes)\n"
     ]
    }
   ],
   "source": [
    "print(\"Generated Artifacts Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Pipeline: {PIPELINE_NAME}\")\n",
    "print(f\"Target: {GENERATION_TARGET.value}\")\n",
    "print(f\"Format: {OUTPUT_FORMAT.value}\")\n",
    "print(f\"Output: {output_dir}\")\n",
    "print()\n",
    "\n",
    "def show_tree(path: Path, prefix: str = \"\"):\n",
    "    items = sorted(path.iterdir(), key=lambda p: (p.is_file(), p.name))\n",
    "    for i, item in enumerate(items):\n",
    "        is_last = i == len(items) - 1\n",
    "        connector = \"â””â”€â”€ \" if is_last else \"â”œâ”€â”€ \"\n",
    "        if item.is_file():\n",
    "            size = item.stat().st_size\n",
    "            print(f\"{prefix}{connector}{item.name} ({size:,} bytes)\")\n",
    "        else:\n",
    "            print(f\"{prefix}{connector}{item.name}/\")\n",
    "            show_tree(item, prefix + (\"    \" if is_last else \"â”‚   \"))\n",
    "\n",
    "if output_dir.exists():\n",
    "    show_tree(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98b2e5e",
   "metadata": {
    "papermill": {
     "duration": 0.001989,
     "end_time": "2026-01-29T23:49:51.321757",
     "exception": false,
     "start_time": "2026-01-29T23:49:51.319768",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 10.8 Recommendations Hash\n",
    "\n",
    "The recommendations hash is a unique identifier for the gold layer feature engineering configuration. It enables experiment tracking and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "219e8376",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-29T23:49:51.327263Z",
     "iopub.status.busy": "2026-01-29T23:49:51.327148Z",
     "iopub.status.idle": "2026-01-29T23:49:51.332072Z",
     "shell.execute_reply": "2026-01-29T23:49:51.331468Z"
    },
    "papermill": {
     "duration": 0.00852,
     "end_time": "2026-01-29T23:49:51.332627",
     "exception": false,
     "start_time": "2026-01-29T23:49:51.324107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations Hash\n",
      "============================================================\n",
      "Hash: 4131c25b\n",
      "Full version tag: v1.0.0_4131c25b\n",
      "\n",
      "This hash uniquely identifies the gold layer configuration:\n",
      "  - Encodings: 4\n",
      "  - Scalings: 6\n",
      "  - Transformations: 105\n",
      "  - Feature selections: 188\n",
      "\n",
      "Recommendations by layer:\n",
      "  BRONZE: 52 recommendations\n",
      "  SILVER: 8 recommendations\n",
      "  GOLD: 303 recommendations\n",
      "    - [encoding] lifecycle_quadrant: one_hot\n",
      "    - [encoding] recency_bucket: one_hot\n",
      "    - [encoding] lifecycle_quadrant: onehot\n",
      "    ... and 300 more\n",
      "\n",
      "âœ“ Gold layer initialized (target: target)\n",
      "\n",
      "Use this hash to:\n",
      "  - Track MLflow experiments (tag: recommendations_hash)\n",
      "  - Version Feast feature views (tag in feature_store)\n",
      "  - Return to a specific feature engineering configuration\n"
     ]
    }
   ],
   "source": [
    "if registry:\n",
    "    recommendations_hash = registry.compute_recommendations_hash()\n",
    "    print(\"Recommendations Hash\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Hash: {recommendations_hash}\")\n",
    "    print(f\"Full version tag: v1.0.0_{recommendations_hash}\")\n",
    "    print()\n",
    "    print(\"This hash uniquely identifies the gold layer configuration:\")\n",
    "    print(f\"  - Encodings: {len(registry.gold.encoding) if registry.gold else 0}\")\n",
    "    print(f\"  - Scalings: {len(registry.gold.scaling) if registry.gold else 0}\")\n",
    "    print(f\"  - Transformations: {len(registry.gold.transformations) if registry.gold else 0}\")\n",
    "    print(f\"  - Feature selections: {len(registry.gold.feature_selection) if registry.gold else 0}\")\n",
    "    \n",
    "    # Show what's in each layer for debugging\n",
    "    print()\n",
    "    print(\"Recommendations by layer:\")\n",
    "    for layer in [\"bronze\", \"silver\", \"gold\"]:\n",
    "        recs = registry.get_by_layer(layer)\n",
    "        print(f\"  {layer.upper()}: {len(recs)} recommendations\")\n",
    "        if recs and layer == \"gold\":\n",
    "            for rec in recs[:3]:\n",
    "                print(f\"    - [{rec.category}] {rec.target_column}: {rec.action}\")\n",
    "            if len(recs) > 3:\n",
    "                print(f\"    ... and {len(recs) - 3} more\")\n",
    "    \n",
    "    # Check if gold layer exists but is empty\n",
    "    if registry.gold:\n",
    "        print(f\"\\nâœ“ Gold layer initialized (target: {registry.gold.target_column})\")\n",
    "    else:\n",
    "        print(\"\\nâš  Gold layer not initialized - run step 06 first\")\n",
    "    \n",
    "    print()\n",
    "    print(\"Use this hash to:\")\n",
    "    print(\"  - Track MLflow experiments (tag: recommendations_hash)\")\n",
    "    print(\"  - Version Feast feature views (tag in feature_store)\")\n",
    "    print(\"  - Return to a specific feature engineering configuration\")\n",
    "else:\n",
    "    print(\"No recommendations loaded - hash not available\")\n",
    "    print(\"Run notebooks 02-07 first, then re-run this notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967af89a",
   "metadata": {
    "papermill": {
     "duration": 0.002018,
     "end_time": "2026-01-29T23:49:51.337026",
     "exception": false,
     "start_time": "2026-01-29T23:49:51.335008",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 10.9 Feast Feature Store Validation\n",
    "\n",
    "Check what's registered in Feast after running the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba7a26e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-29T23:49:51.341961Z",
     "iopub.status.busy": "2026-01-29T23:49:51.341847Z",
     "iopub.status.idle": "2026-01-29T23:49:52.865758Z",
     "shell.execute_reply": "2026-01-29T23:49:52.865124Z"
    },
    "papermill": {
     "duration": 1.527674,
     "end_time": "2026-01-29T23:49:52.866625",
     "exception": false,
     "start_time": "2026-01-29T23:49:51.338951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feast Feature Store Contents\n",
      "============================================================\n",
      "\n",
      "âš ï¸  Feature store registry is empty.\n",
      "   The feature definitions exist but haven't been applied yet.\n",
      "\n",
      "   To register features, run:\n",
      "     cd ../generated_pipelines/local/customer_churn/feature_repo\n",
      "     feast apply\n",
      "\n",
      "   Or run the full pipeline:\n",
      "     cd ../generated_pipelines/local/customer_churn\n",
      "     python run_all.py\n",
      "\n",
      "ðŸ“„ Sample Feature Data:\n",
      "   No parquet files found yet in data/ directory.\n",
      "   Features will be materialized when you run the pipeline.\n"
     ]
    }
   ],
   "source": [
    "# Inspect Feast Feature Store contents\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"feast\")\n",
    "\n",
    "feast_repo_path = output_dir / \"feature_repo\"\n",
    "\n",
    "if feast_repo_path.exists() and (feast_repo_path / \"feature_store.yaml\").exists():\n",
    "    try:\n",
    "        from feast import FeatureStore\n",
    "        store = FeatureStore(repo_path=str(feast_repo_path))\n",
    "        \n",
    "        print(\"Feast Feature Store Contents\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # List entities\n",
    "        entities = store.list_entities()\n",
    "        feature_views = store.list_feature_views()\n",
    "        data_sources = store.list_data_sources()\n",
    "        \n",
    "        # Check if registry is empty (feast apply not run yet)\n",
    "        if not entities and not feature_views:\n",
    "            print(\"\\nâš ï¸  Feature store registry is empty.\")\n",
    "            print(\"   The feature definitions exist but haven't been applied yet.\")\n",
    "            print(\"\\n   To register features, run:\")\n",
    "            print(f\"     cd {feast_repo_path}\")\n",
    "            print(\"     feast apply\")\n",
    "            print(\"\\n   Or run the full pipeline:\")\n",
    "            print(f\"     cd {output_dir}\")\n",
    "            print(\"     python run_all.py\")\n",
    "        else:\n",
    "            print(f\"\\nðŸ“¦ Entities ({len(entities)}):\")\n",
    "            for entity in entities:\n",
    "                print(f\"   - {entity.name} (join_key: {entity.join_keys})\")\n",
    "            \n",
    "            print(f\"\\nðŸ“Š Feature Views ({len(feature_views)}):\")\n",
    "            for fv in feature_views:\n",
    "                print(f\"   - {fv.name}: {len(fv.features)} features\")\n",
    "                for feat in fv.features[:5]:\n",
    "                    print(f\"      â€¢ {feat.name} ({feat.dtype})\")\n",
    "                if len(fv.features) > 5:\n",
    "                    print(f\"      ... and {len(fv.features) - 5} more\")\n",
    "            \n",
    "            print(f\"\\nðŸ’¾ Data Sources ({len(data_sources)}):\")\n",
    "            for ds in data_sources:\n",
    "                print(f\"   - {ds.name}\")\n",
    "        \n",
    "        # Try to show sample data from parquet files\n",
    "        print(f\"\\nðŸ“„ Sample Feature Data:\")\n",
    "        data_dir = feast_repo_path / \"data\"\n",
    "        if data_dir.exists():\n",
    "            parquet_files = list(data_dir.glob(\"*.parquet\"))\n",
    "            if parquet_files:\n",
    "                sample_df = pd.read_parquet(parquet_files[0])\n",
    "                print(f\"   Source: {parquet_files[0].name}\")\n",
    "                print(f\"   Shape: {sample_df.shape[0]:,} rows x {sample_df.shape[1]} columns\")\n",
    "                print(f\"\\n   Head (first 5 rows):\")\n",
    "                display(sample_df.head())\n",
    "            else:\n",
    "                print(\"   No parquet files found yet in data/ directory.\")\n",
    "                print(\"   Features will be materialized when you run the pipeline.\")\n",
    "        else:\n",
    "            print(\"   Data directory not created yet.\")\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"Feast not installed. Install with: pip install feast\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not connect to Feast: {e}\")\n",
    "        print(\"\\nTo manually inspect, run:\")\n",
    "        print(f\"  cd {feast_repo_path}\")\n",
    "        print(\"  feast apply\")\n",
    "        print(\"  feast feature-views list\")\n",
    "else:\n",
    "    print(f\"Feature repo not found at: {feast_repo_path}\")\n",
    "    print(\"Generate the pipeline first by running cells above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d153f651",
   "metadata": {
    "papermill": {
     "duration": 0.002303,
     "end_time": "2026-01-29T23:49:52.871609",
     "exception": false,
     "start_time": "2026-01-29T23:49:52.869306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 10.10 Next Steps\n",
    "\n",
    "### Run Pipeline (Single Command)\n",
    "```bash\n",
    "cd ../generated_pipelines/local/customer_churn\n",
    "python run_all.py\n",
    "```\n",
    "\n",
    "This single command:\n",
    "1. Runs Bronze layers in **parallel**\n",
    "2. Runs Silver merge\n",
    "3. Runs Gold features  \n",
    "4. Trains models with MLflow tracking\n",
    "5. **Auto-starts MLflow UI** and opens browser\n",
    "6. Press `Ctrl+C` to stop when done\n",
    "\n",
    "### Generated Structure\n",
    "```\n",
    "generated_pipelines/local/{pipeline}/\n",
    "â”œâ”€â”€ run_all.py          # Single entry point\n",
    "â”œâ”€â”€ config.py           # Configuration (includes RECOMMENDATIONS_HASH)\n",
    "â”œâ”€â”€ bronze/\n",
    "â”‚   â””â”€â”€ bronze_*.py     # Parallel execution\n",
    "â”œâ”€â”€ silver/\n",
    "â”‚   â””â”€â”€ silver_merge.py\n",
    "â”œâ”€â”€ gold/\n",
    "â”‚   â””â”€â”€ gold_features.py  # Includes feature version tag\n",
    "â”œâ”€â”€ training/\n",
    "â”‚   â””â”€â”€ ml_experiment.py  # MLflow tags with recommendations_hash\n",
    "â”œâ”€â”€ pipeline.py         # Standalone pipeline script\n",
    "â””â”€â”€ requirements.txt\n",
    "```\n",
    "\n",
    "### Tracking Your Experiment\n",
    "After running, you can find your experiment by:\n",
    "- **MLflow UI**: Filter by tag `recommendations_hash = <your_hash>`\n",
    "- **Feast**: Check feature view tags for `recommendations_hash`\n",
    "- **Return to config**: The hash uniquely identifies the gold layer settings\n",
    "\n",
    "---\n",
    "\n",
    "## Complete!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.522313,
   "end_time": "2026-01-29T23:49:53.292207",
   "environment_variables": {},
   "exception": null,
   "input_path": "exploration_notebooks/10_spec_generation.ipynb",
   "output_path": "docs/tutorial/executed/10_spec_generation.ipynb",
   "parameters": {},
   "start_time": "2026-01-29T23:49:44.769894",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
