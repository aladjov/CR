{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10: Pipeline Generation\n",
    "\n",
    "Generate production-ready pipeline code from exploration findings.\n",
    "\n",
    "**Generation Targets:**\n",
    "1. **Local (Feast + MLFlow)** - Local feature store and experiment tracking\n",
    "2. **Databricks (FS + MLFlow)** - Unity Catalog, DLT, Feature Store, MLFlow\n",
    "3. **LLM Documentation** - Markdown files for AI-assisted development\n",
    "\n",
    "**Output Formats:**\n",
    "- Python files (`.py`)\n",
    "- Jupyter notebooks (`.ipynb`)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: customer_churn\n",
      "Target: local\n",
      "Format: py\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "\n",
    "class GenerationTarget(Enum):\n",
    "    LOCAL_FEAST_MLFLOW = \"local\"\n",
    "    DATABRICKS = \"databricks\"\n",
    "    LLM_DOCS = \"llm_docs\"\n",
    "\n",
    "class OutputFormat(Enum):\n",
    "    PYTHON = \"py\"\n",
    "    NOTEBOOK = \"ipynb\"\n",
    "\n",
    "# === USER CONFIGURATION ===\n",
    "PIPELINE_NAME = \"customer_churn\"\n",
    "GENERATION_TARGET = GenerationTarget.LOCAL_FEAST_MLFLOW\n",
    "OUTPUT_FORMAT = OutputFormat.PYTHON\n",
    "\n",
    "# Paths\n",
    "# FINDINGS_DIR imported from customer_retention.core.config.experiments\n",
    "OUTPUT_BASE_DIR = Path(\"../generated_pipelines\")\n",
    "\n",
    "# Databricks settings (only used when GENERATION_TARGET == DATABRICKS)\n",
    "DATABRICKS_CATALOG = \"main\"\n",
    "DATABRICKS_SCHEMA = \"ml_features\"\n",
    "\n",
    "print(f\"Pipeline: {PIPELINE_NAME}\")\n",
    "print(f\"Target: {GENERATION_TARGET.value}\")\n",
    "print(f\"Format: {OUTPUT_FORMAT.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 Load Findings and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded recommendations from: customer_emails_408768_aggregated_d24886_recommendations.yaml\n",
      "Loaded: ../experiments/findings/customer_emails_408768_aggregated.parquet\n",
      "Rows: 4,998 | Columns: 68\n",
      "Target: target\n",
      "Recommendations: Loaded\n",
      "Multi-dataset: Loaded\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from customer_retention.analysis.auto_explorer import ExplorationFindings\n",
    "from customer_retention.analysis.auto_explorer.layered_recommendations import RecommendationRegistry\n",
    "from customer_retention.core.config.experiments import FINDINGS_DIR, EXPERIMENTS_DIR, OUTPUT_DIR, setup_experiments_structure\n",
    "\n",
    "def load_findings_and_recommendations(findings_dir: Path):\n",
    "    findings_files = sorted(\n",
    "        [f for f in findings_dir.glob(\"*_findings.yaml\") if \"multi_dataset\" not in f.name],\n",
    "        key=lambda f: f.stat().st_mtime, reverse=True\n",
    "    )\n",
    "    if not findings_files:\n",
    "        raise FileNotFoundError(f\"No findings in {findings_dir}. Run exploration notebooks first.\")\n",
    "    \n",
    "    findings = ExplorationFindings.load(str(findings_files[0]))\n",
    "    \n",
    "    # Look for recommendations file matching the findings file pattern\n",
    "    # Step 06 saves as: {name}_recommendations.yaml (matching {name}_findings.yaml)\n",
    "    findings_name = findings_files[0].stem.replace(\"_findings\", \"\")\n",
    "    recommendations_path = findings_dir / f\"{findings_name}_recommendations.yaml\"\n",
    "    \n",
    "    # Fallback to generic recommendations.yaml if not found\n",
    "    if not recommendations_path.exists():\n",
    "        recommendations_path = findings_dir / \"recommendations.yaml\"\n",
    "    \n",
    "    # Final fallback: find any *_recommendations.yaml\n",
    "    if not recommendations_path.exists():\n",
    "        rec_files = sorted(findings_dir.glob(\"*_recommendations.yaml\"), \n",
    "                          key=lambda f: f.stat().st_mtime, reverse=True)\n",
    "        if rec_files:\n",
    "            recommendations_path = rec_files[0]\n",
    "    \n",
    "    registry = None\n",
    "    if recommendations_path.exists():\n",
    "        with open(recommendations_path) as f:\n",
    "            registry = RecommendationRegistry.from_dict(yaml.safe_load(f))\n",
    "        print(f\"Loaded recommendations from: {recommendations_path.name}\")\n",
    "    \n",
    "    multi_dataset_path = findings_dir / \"multi_dataset_findings.yaml\"\n",
    "    multi_dataset = None\n",
    "    if multi_dataset_path.exists():\n",
    "        with open(multi_dataset_path) as f:\n",
    "            multi_dataset = yaml.safe_load(f)\n",
    "    \n",
    "    return findings, registry, multi_dataset\n",
    "\n",
    "findings, registry, multi_dataset = load_findings_and_recommendations(FINDINGS_DIR)\n",
    "\n",
    "print(f\"Loaded: {findings.source_path}\")\n",
    "print(f\"Rows: {findings.row_count:,} | Columns: {findings.column_count}\")\n",
    "print(f\"Target: {findings.target_column}\")\n",
    "print(f\"Recommendations: {'Loaded' if registry else 'Not found'}\")\n",
    "print(f\"Multi-dataset: {'Loaded' if multi_dataset else 'Not found'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 Review Layered Recommendations\n",
    "\n",
    "Recommendations are organized by medallion layer:\n",
    "- **Bronze**: null_handling, outlier_handling, type_conversions, deduplication, filtering, text_processing\n",
    "- **Silver**: joins, aggregations, derived_columns\n",
    "- **Gold**: encoding, scaling, feature_selection, transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BRONZE (50 recommendations):\n",
      "--------------------------------------------------\n",
      "  [null] time_to_open_hours_mean_180d: impute\n",
      "  [null] time_to_open_hours_max_180d: impute\n",
      "  [null] send_hour_mean_180d: impute\n",
      "  [null] send_hour_max_180d: impute\n",
      "  [null] opened_mean_180d: impute\n",
      "  ... and 45 more\n",
      "\n",
      "SILVER (8 recommendations):\n",
      "--------------------------------------------------\n",
      "  [derived] event_count_180d_to_event_count_180d_ratio: ratio\n",
      "  [derived] event_count_180d_x_event_count_365d: interaction\n",
      "  [derived] event_count_180d_x_event_count_all_time: interaction\n",
      "  [derived] event_count_180d_x_time_to_open_hours_sum_180d: interaction\n",
      "  [derived] event_count_365d_x_event_count_all_time: interaction\n",
      "  ... and 3 more\n",
      "\n",
      "GOLD (295 recommendations):\n",
      "--------------------------------------------------\n",
      "  [encoding] lifecycle_quadrant: one_hot\n",
      "  [encoding] lifecycle_quadrant: onehot\n",
      "  [scaling] send_hour_mean_180d: standard\n",
      "  [scaling] send_hour_max_180d: standard\n",
      "  [scaling] send_hour_mean_365d: standard\n",
      "  ... and 290 more\n"
     ]
    }
   ],
   "source": [
    "def display_recommendations(registry: RecommendationRegistry):\n",
    "    if not registry:\n",
    "        print(\"No recommendations loaded. Run notebooks 02-07 first.\")\n",
    "        return\n",
    "    \n",
    "    for layer in [\"bronze\", \"silver\", \"gold\"]:\n",
    "        recs = registry.get_by_layer(layer)\n",
    "        print(f\"\\n{layer.upper()} ({len(recs)} recommendations):\")\n",
    "        print(\"-\" * 50)\n",
    "        for rec in recs[:5]:\n",
    "            print(f\"  [{rec.category}] {rec.target_column}: {rec.action}\")\n",
    "        if len(recs) > 5:\n",
    "            print(f\"  ... and {len(recs) - 5} more\")\n",
    "\n",
    "display_recommendations(registry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10.4 Generate Pipeline\n",
    "\n",
    "Select generation based on configured target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: ../generated_pipelines/local/customer_churn\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "output_dir = OUTPUT_BASE_DIR / GENERATION_TARGET.value / PIPELINE_NAME\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option A: Local (Feast + MLFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated MLflow pipeline files:\n",
      "  pipeline.py\n",
      "  requirements.txt\n",
      "\n",
      "Generated pipeline files (Bronze/Silver/Gold/Training):\n",
      "  ../generated_pipelines/local/customer_churn/run_all.py\n",
      "  ../generated_pipelines/local/customer_churn/config.py\n",
      "  ../generated_pipelines/local/customer_churn/bronze/bronze_customer_emails_aggregated.py\n",
      "  ../generated_pipelines/local/customer_churn/silver/silver_merge.py\n",
      "  ../generated_pipelines/local/customer_churn/gold/gold_features.py\n",
      "  ../generated_pipelines/local/customer_churn/training/ml_experiment.py\n",
      "  ../generated_pipelines/local/customer_churn/pipeline_runner.py\n",
      "  ../generated_pipelines/local/customer_churn/workflow.json\n",
      "  ../generated_pipelines/local/customer_churn/feature_repo/feature_store.yaml\n",
      "  ../generated_pipelines/local/customer_churn/feature_repo/features.py\n",
      "  ../generated_pipelines/local/customer_churn/scoring/run_scoring.py\n",
      "  ../generated_pipelines/local/customer_churn/scoring/scoring_dashboard.ipynb\n"
     ]
    }
   ],
   "source": [
    "if GENERATION_TARGET == GenerationTarget.LOCAL_FEAST_MLFLOW:\n",
    "    from customer_retention.generators.spec_generator import MLflowPipelineGenerator, MLflowConfig\n",
    "    from customer_retention.generators.pipeline_generator import PipelineGenerator\n",
    "    \n",
    "    mlflow_config = MLflowConfig(\n",
    "        tracking_uri=\"./mlruns\",\n",
    "        experiment_name=PIPELINE_NAME,\n",
    "        log_data_quality=True,\n",
    "        nested_runs=True\n",
    "    )\n",
    "    \n",
    "    mlflow_gen = MLflowPipelineGenerator(mlflow_config=mlflow_config, output_dir=str(output_dir))\n",
    "    \n",
    "    if OUTPUT_FORMAT == OutputFormat.PYTHON:\n",
    "        saved = mlflow_gen.save_all(findings)\n",
    "        print(\"Generated MLflow pipeline files:\")\n",
    "        for f in saved:\n",
    "            print(f\"  {f}\")\n",
    "    \n",
    "    if multi_dataset:\n",
    "        pipeline_gen = PipelineGenerator(\n",
    "            findings_dir=str(FINDINGS_DIR),\n",
    "            output_dir=str(output_dir),\n",
    "            pipeline_name=PIPELINE_NAME\n",
    "        )\n",
    "        orch_files = pipeline_gen.generate()\n",
    "        print(\"\\nGenerated pipeline files (Bronze/Silver/Gold/Training):\")\n",
    "        for f in orch_files:\n",
    "            print(f\"  {f}\")\n",
    "else:\n",
    "    print(f\"Skipping Local generation (target is {GENERATION_TARGET.value})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Databricks (FS + MLFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Databricks generation (target is local)\n"
     ]
    }
   ],
   "source": [
    "if GENERATION_TARGET == GenerationTarget.DATABRICKS:\n",
    "    from customer_retention.generators.spec_generator import DatabricksSpecGenerator, PipelineSpec, SourceSpec\n",
    "    \n",
    "    spec = PipelineSpec(\n",
    "        name=PIPELINE_NAME,\n",
    "        version=\"1.0.0\",\n",
    "        sources=[SourceSpec(\n",
    "            name=findings.source_path.split(\"/\")[-1].replace(\".csv\", \"\"),\n",
    "            path=findings.source_path,\n",
    "            format=findings.source_format\n",
    "        )]\n",
    "    )\n",
    "    \n",
    "    if findings.target_column:\n",
    "        from customer_retention.generators.spec_generator import ModelSpec\n",
    "        spec.model_config = ModelSpec(\n",
    "            name=f\"{PIPELINE_NAME}_model\",\n",
    "            model_type=\"gradient_boosting\",\n",
    "            target_column=findings.target_column\n",
    "        )\n",
    "    \n",
    "    db_gen = DatabricksSpecGenerator(\n",
    "        catalog=DATABRICKS_CATALOG,\n",
    "        schema=DATABRICKS_SCHEMA,\n",
    "        output_dir=str(output_dir)\n",
    "    )\n",
    "    \n",
    "    saved = db_gen.save_all(spec)\n",
    "    print(\"Generated Databricks artifacts:\")\n",
    "    for f in saved:\n",
    "        print(f\"  {f}\")\n",
    "else:\n",
    "    print(f\"Skipping Databricks generation (target is {GENERATION_TARGET.value})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option C: LLM Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping LLM docs generation (target is local)\n"
     ]
    }
   ],
   "source": [
    "if GENERATION_TARGET == GenerationTarget.LLM_DOCS:\n",
    "    from customer_retention.analysis.auto_explorer import RecommendationEngine\n",
    "    \n",
    "    recommender = RecommendationEngine()\n",
    "    target_rec = recommender.recommend_target(findings)\n",
    "    feature_recs = recommender.recommend_features(findings)\n",
    "    cleaning_recs = recommender.recommend_cleaning(findings)\n",
    "    \n",
    "    docs_dir = output_dir / \"docs\"\n",
    "    docs_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 1. Overview\n",
    "    overview = f\"\"\"# {PIPELINE_NAME} Pipeline Overview\n",
    "\n",
    "## Data Source\n",
    "- **Path**: {findings.source_path}\n",
    "- **Format**: {findings.source_format}\n",
    "- **Rows**: {findings.row_count:,}\n",
    "- **Columns**: {findings.column_count}\n",
    "- **Quality Score**: {findings.overall_quality_score:.1f}/100\n",
    "\n",
    "## Target Variable\n",
    "- **Column**: {target_rec.column_name}\n",
    "- **Type**: {target_rec.target_type}\n",
    "- **Rationale**: {target_rec.rationale}\n",
    "\n",
    "## Column Types\n",
    "| Column | Type | Nulls | Unique |\n",
    "|--------|------|-------|--------|\n",
    "\"\"\"\n",
    "    for name, col in list(findings.columns.items())[:20]:\n",
    "        overview += f\"| {name} | {col.inferred_type.value} | {col.null_percentage:.1f}% | {col.unique_count} |\\n\"\n",
    "    (docs_dir / \"01_overview.md\").write_text(overview)\n",
    "    \n",
    "    # 2. Bronze layer - separate file per source\n",
    "    if registry and registry.sources:\n",
    "        for source_name, bronze_recs in registry.sources.items():\n",
    "            bronze_doc = f\"\"\"# Bronze Layer - {source_name}\n",
    "\n",
    "## Source File\n",
    "`{bronze_recs.source_file}`\n",
    "\n",
    "## Null Handling\n",
    "\"\"\"\n",
    "            for rec in bronze_recs.null_handling:\n",
    "                bronze_doc += f\"- `{rec.target_column}`: {rec.action} ({rec.parameters.get('strategy', '')}) - {rec.rationale}\\n\"\n",
    "            \n",
    "            bronze_doc += \"\\n## Outlier Handling\\n\"\n",
    "            for rec in bronze_recs.outlier_handling:\n",
    "                bronze_doc += f\"- `{rec.target_column}`: {rec.action} - {rec.rationale}\\n\"\n",
    "            \n",
    "            bronze_doc += \"\\n## Type Conversions\\n\"\n",
    "            for rec in bronze_recs.type_conversions:\n",
    "                bronze_doc += f\"- `{rec.target_column}`: {rec.action} - {rec.rationale}\\n\"\n",
    "            \n",
    "            bronze_doc += \"\\n## Deduplication\\n\"\n",
    "            for rec in bronze_recs.deduplication:\n",
    "                bronze_doc += f\"- `{rec.target_column}`: {rec.action} - {rec.rationale}\\n\"\n",
    "            \n",
    "            bronze_doc += \"\\n## Filtering\\n\"\n",
    "            for rec in bronze_recs.filtering:\n",
    "                bronze_doc += f\"- `{rec.target_column}`: {rec.action} - {rec.rationale}\\n\"\n",
    "            \n",
    "            bronze_doc += \"\\n## Text Processing\\n\"\n",
    "            for rec in bronze_recs.text_processing:\n",
    "                bronze_doc += f\"- `{rec.target_column}`: {rec.action} - {rec.rationale}\\n\"\n",
    "            \n",
    "            safe_name = source_name.replace(\" \", \"_\").lower()\n",
    "            (docs_dir / f\"02_bronze_cleaning_{safe_name}.md\").write_text(bronze_doc)\n",
    "    else:\n",
    "        bronze_doc = f\"\"\"# Bronze Layer - Data Cleaning\n",
    "\n",
    "## Cleaning Recommendations\n",
    "\"\"\"\n",
    "        for rec in cleaning_recs:\n",
    "            bronze_doc += f\"\\n### {rec.column_name}\\n- **Strategy**: {rec.strategy}\\n- **Severity**: {rec.severity}\\n- **Rationale**: {rec.rationale}\\n\"\n",
    "        (docs_dir / \"02_bronze_cleaning.md\").write_text(bronze_doc)\n",
    "    \n",
    "    # 3. Silver layer\n",
    "    silver_doc = \"\"\"# Silver Layer - Feature Engineering\n",
    "\n",
    "## Aggregations and Joins\n",
    "\"\"\"\n",
    "    if registry and registry.silver:\n",
    "        silver_doc += \"\\n### Joins\\n\"\n",
    "        for rec in registry.silver.joins:\n",
    "            silver_doc += f\"- {rec.parameters.get('left_source', '')} \u27f7 {rec.parameters.get('right_source', '')} on `{rec.parameters.get('join_keys', [])}`\\n\"\n",
    "        \n",
    "        silver_doc += \"\\n### Aggregations\\n\"\n",
    "        for rec in registry.silver.aggregations:\n",
    "            silver_doc += f\"- `{rec.target_column}`: {rec.action} - windows: {rec.parameters.get('windows', [])}\\n\"\n",
    "        \n",
    "        silver_doc += \"\\n### Derived Columns\\n\"\n",
    "        for rec in registry.silver.derived_columns:\n",
    "            silver_doc += f\"- `{rec.target_column}`: {rec.parameters.get('expression', rec.action)}\\n\"\n",
    "    else:\n",
    "        silver_doc += \"\\nNo silver-layer recommendations found.\\n\"\n",
    "    (docs_dir / \"03_silver_features.md\").write_text(silver_doc)\n",
    "    \n",
    "    # 4. Gold layer\n",
    "    gold_doc = \"\"\"# Gold Layer - ML Features\n",
    "\n",
    "## Feature Recommendations\n",
    "\"\"\"\n",
    "    for rec in feature_recs[:15]:\n",
    "        gold_doc += f\"\\n### {rec.feature_name}\\n- **Source**: {rec.source_column}\\n- **Type**: {rec.feature_type}\\n- **Description**: {rec.description}\\n\"\n",
    "    \n",
    "    if registry and registry.gold:\n",
    "        gold_doc += \"\\n## Encoding\\n\"\n",
    "        for rec in registry.gold.encoding:\n",
    "            gold_doc += f\"- `{rec.target_column}`: {rec.parameters.get('method', rec.action)}\\n\"\n",
    "        \n",
    "        gold_doc += \"\\n## Scaling\\n\"\n",
    "        for rec in registry.gold.scaling:\n",
    "            gold_doc += f\"- `{rec.target_column}`: {rec.parameters.get('method', rec.action)}\\n\"\n",
    "        \n",
    "        gold_doc += \"\\n## Feature Selection\\n\"\n",
    "        for rec in registry.gold.feature_selection:\n",
    "            gold_doc += f\"- `{rec.target_column}`: {rec.action} - {rec.rationale}\\n\"\n",
    "        \n",
    "        gold_doc += \"\\n## Transformations\\n\"\n",
    "        for rec in registry.gold.transformations:\n",
    "            gold_doc += f\"- `{rec.target_column}`: {rec.action} - {rec.parameters}\\n\"\n",
    "    (docs_dir / \"04_gold_ml_features.md\").write_text(gold_doc)\n",
    "    \n",
    "    # 5. Training\n",
    "    training_doc = f\"\"\"# Model Training\n",
    "\n",
    "## Target\n",
    "- **Column**: {target_rec.column_name}\n",
    "- **Type**: {target_rec.target_type}\n",
    "\n",
    "## Recommended Models\n",
    "1. **Gradient Boosting** - Good for tabular data with mixed types\n",
    "2. **Random Forest** - Robust baseline, handles missing values\n",
    "3. **Logistic Regression** - Interpretable, good for imbalanced data\n",
    "\n",
    "## Evaluation Metrics\n",
    "- ROC-AUC (primary)\n",
    "- Precision/Recall at threshold\n",
    "- F1 Score\n",
    "\"\"\"\n",
    "    (docs_dir / \"05_training.md\").write_text(training_doc)\n",
    "    \n",
    "    print(\"Generated LLM documentation:\")\n",
    "    for f in sorted(docs_dir.glob(\"*.md\")):\n",
    "        print(f\"  {f.name}\")\n",
    "else:\n",
    "    print(f\"Skipping LLM docs generation (target is {GENERATION_TARGET.value})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10.5 Convert to Notebooks (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output format is Python. Set OUTPUT_FORMAT = OutputFormat.NOTEBOOK to convert.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def py_to_notebook(py_path: Path):\n",
    "    content = py_path.read_text()\n",
    "    cells = []\n",
    "    current_lines = []\n",
    "    \n",
    "    for line in content.split(\"\\n\"):\n",
    "        if line.startswith(\"# %% \") or line.startswith(\"# %%\\n\"):\n",
    "            if current_lines:\n",
    "                cells.append({\"cell_type\": \"code\", \"metadata\": {}, \"source\": current_lines, \"outputs\": [], \"execution_count\": None})\n",
    "                current_lines = []\n",
    "            title = line.replace(\"# %% \", \"\").strip()\n",
    "            if title:\n",
    "                cells.append({\"cell_type\": \"markdown\", \"metadata\": {}, \"source\": [f\"## {title}\"]})\n",
    "        else:\n",
    "            current_lines.append(line + \"\\n\")\n",
    "    \n",
    "    if current_lines:\n",
    "        cells.append({\"cell_type\": \"code\", \"metadata\": {}, \"source\": current_lines, \"outputs\": [], \"execution_count\": None})\n",
    "    \n",
    "    notebook = {\n",
    "        \"cells\": cells,\n",
    "        \"metadata\": {\"kernelspec\": {\"display_name\": \"Python 3\", \"language\": \"python\", \"name\": \"python3\"}},\n",
    "        \"nbformat\": 4, \"nbformat_minor\": 4\n",
    "    }\n",
    "    \n",
    "    out_path = py_path.with_suffix(\".ipynb\")\n",
    "    out_path.write_text(json.dumps(notebook, indent=1))\n",
    "    return out_path\n",
    "\n",
    "if OUTPUT_FORMAT == OutputFormat.NOTEBOOK:\n",
    "    print(\"Converting Python files to notebooks...\")\n",
    "    for py_file in output_dir.rglob(\"*.py\"):\n",
    "        if py_file.name != \"__init__.py\":\n",
    "            nb_path = py_to_notebook(py_file)\n",
    "            print(f\"  {py_file.name} -> {nb_path.name}\")\n",
    "else:\n",
    "    print(\"Output format is Python. Set OUTPUT_FORMAT = OutputFormat.NOTEBOOK to convert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10.6 Run Pipeline\n",
    "\n",
    "Single command runs everything: Bronze (parallel) \u2192 Silver \u2192 Gold \u2192 Training \u2192 MLflow UI (auto-opens browser)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To run the complete pipeline:\n",
      "\n",
      "  cd ../generated_pipelines/local/customer_churn\n",
      "  python run_all.py\n",
      "\n",
      "This will:\n",
      "  1. Run Bronze layers (parallel)\n",
      "  2. Run Silver merge\n",
      "  3. Run Gold features\n",
      "  4. Train models with MLflow\n",
      "  5. Auto-start MLflow UI and open browser\n",
      "  6. Press Ctrl+C to stop MLflow UI when done\n"
     ]
    }
   ],
   "source": [
    "# Uncomment below to run the pipeline after generation\n",
    "# RUN_PIPELINE = True\n",
    "\n",
    "RUN_PIPELINE = False\n",
    "\n",
    "run_all_path = output_dir / \"run_all.py\"\n",
    "\n",
    "if RUN_PIPELINE and GENERATION_TARGET == GenerationTarget.LOCAL_FEAST_MLFLOW:\n",
    "    import subprocess\n",
    "    if run_all_path.exists():\n",
    "        print(f\"Running: python {run_all_path}\")\n",
    "        print(\"Pipeline will run and MLflow UI will open automatically...\")\n",
    "        subprocess.run([\"python\", str(run_all_path)], cwd=run_all_path.parent)\n",
    "    else:\n",
    "        print(f\"run_all.py not found. Generate first by running cells above.\")\n",
    "else:\n",
    "    print(\"To run the complete pipeline:\")\n",
    "    print(f\"\\n  cd {output_dir}\")\n",
    "    print(f\"  python run_all.py\")\n",
    "    print(f\"\\nThis will:\")\n",
    "    print(\"  1. Run Bronze layers (parallel)\")\n",
    "    print(\"  2. Run Silver merge\")\n",
    "    print(\"  3. Run Gold features\")\n",
    "    print(\"  4. Train models with MLflow\")\n",
    "    print(\"  5. Auto-start MLflow UI and open browser\")\n",
    "    print(\"  6. Press Ctrl+C to stop MLflow UI when done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10.7 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Artifacts Summary\n",
      "============================================================\n",
      "Pipeline: customer_churn\n",
      "Target: local\n",
      "Format: py\n",
      "Output: ../generated_pipelines/local/customer_churn\n",
      "\n",
      "\u251c\u2500\u2500 bronze/\n",
      "\u2502   \u2514\u2500\u2500 bronze_customer_emails_aggregated.py (769 bytes)\n",
      "\u251c\u2500\u2500 feature_repo/\n",
      "\u2502   \u251c\u2500\u2500 data/\n",
      "\u2502   \u251c\u2500\u2500 feature_store.yaml (188 bytes)\n",
      "\u2502   \u2514\u2500\u2500 features.py (1,112 bytes)\n",
      "\u251c\u2500\u2500 gold/\n",
      "\u2502   \u2514\u2500\u2500 gold_features.py (2,780 bytes)\n",
      "\u251c\u2500\u2500 scoring/\n",
      "\u2502   \u251c\u2500\u2500 run_scoring.py (6,071 bytes)\n",
      "\u2502   \u2514\u2500\u2500 scoring_dashboard.ipynb (15,645 bytes)\n",
      "\u251c\u2500\u2500 silver/\n",
      "\u2502   \u2514\u2500\u2500 silver_merge.py (692 bytes)\n",
      "\u251c\u2500\u2500 training/\n",
      "\u2502   \u2514\u2500\u2500 ml_experiment.py (9,523 bytes)\n",
      "\u251c\u2500\u2500 config.py (1,558 bytes)\n",
      "\u251c\u2500\u2500 pipeline.py (8,519 bytes)\n",
      "\u251c\u2500\u2500 pipeline_runner.py (845 bytes)\n",
      "\u251c\u2500\u2500 requirements.txt (111 bytes)\n",
      "\u251c\u2500\u2500 run_all.py (2,489 bytes)\n",
      "\u2514\u2500\u2500 workflow.json (968 bytes)\n"
     ]
    }
   ],
   "source": [
    "print(\"Generated Artifacts Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Pipeline: {PIPELINE_NAME}\")\n",
    "print(f\"Target: {GENERATION_TARGET.value}\")\n",
    "print(f\"Format: {OUTPUT_FORMAT.value}\")\n",
    "print(f\"Output: {output_dir}\")\n",
    "print()\n",
    "\n",
    "def show_tree(path: Path, prefix: str = \"\"):\n",
    "    items = sorted(path.iterdir(), key=lambda p: (p.is_file(), p.name))\n",
    "    for i, item in enumerate(items):\n",
    "        is_last = i == len(items) - 1\n",
    "        connector = \"\u2514\u2500\u2500 \" if is_last else \"\u251c\u2500\u2500 \"\n",
    "        if item.is_file():\n",
    "            size = item.stat().st_size\n",
    "            print(f\"{prefix}{connector}{item.name} ({size:,} bytes)\")\n",
    "        else:\n",
    "            print(f\"{prefix}{connector}{item.name}/\")\n",
    "            show_tree(item, prefix + (\"    \" if is_last else \"\u2502   \"))\n",
    "\n",
    "if output_dir.exists():\n",
    "    show_tree(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10.8 Recommendations Hash\n",
    "\n",
    "The recommendations hash is a unique identifier for the gold layer feature engineering configuration. It enables experiment tracking and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations Hash\n",
      "============================================================\n",
      "Hash: 9d2a86e3\n",
      "Full version tag: v1.0.0_9d2a86e3\n",
      "\n",
      "This hash uniquely identifies the gold layer configuration:\n",
      "  - Encodings: 2\n",
      "  - Scalings: 6\n",
      "  - Transformations: 100\n",
      "  - Feature selections: 187\n",
      "\n",
      "Recommendations by layer:\n",
      "  BRONZE: 50 recommendations\n",
      "  SILVER: 8 recommendations\n",
      "  GOLD: 295 recommendations\n",
      "    - [encoding] lifecycle_quadrant: one_hot\n",
      "    - [encoding] lifecycle_quadrant: onehot\n",
      "    - [scaling] send_hour_mean_180d: standard\n",
      "    ... and 292 more\n",
      "\n",
      "\u2713 Gold layer initialized (target: target)\n",
      "\n",
      "Use this hash to:\n",
      "  - Track MLflow experiments (tag: recommendations_hash)\n",
      "  - Version Feast feature views (tag in feature_store)\n",
      "  - Return to a specific feature engineering configuration\n"
     ]
    }
   ],
   "source": [
    "if registry:\n",
    "    recommendations_hash = registry.compute_recommendations_hash()\n",
    "    print(\"Recommendations Hash\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Hash: {recommendations_hash}\")\n",
    "    print(f\"Full version tag: v1.0.0_{recommendations_hash}\")\n",
    "    print()\n",
    "    print(\"This hash uniquely identifies the gold layer configuration:\")\n",
    "    print(f\"  - Encodings: {len(registry.gold.encoding) if registry.gold else 0}\")\n",
    "    print(f\"  - Scalings: {len(registry.gold.scaling) if registry.gold else 0}\")\n",
    "    print(f\"  - Transformations: {len(registry.gold.transformations) if registry.gold else 0}\")\n",
    "    print(f\"  - Feature selections: {len(registry.gold.feature_selection) if registry.gold else 0}\")\n",
    "    \n",
    "    # Show what's in each layer for debugging\n",
    "    print()\n",
    "    print(\"Recommendations by layer:\")\n",
    "    for layer in [\"bronze\", \"silver\", \"gold\"]:\n",
    "        recs = registry.get_by_layer(layer)\n",
    "        print(f\"  {layer.upper()}: {len(recs)} recommendations\")\n",
    "        if recs and layer == \"gold\":\n",
    "            for rec in recs[:3]:\n",
    "                print(f\"    - [{rec.category}] {rec.target_column}: {rec.action}\")\n",
    "            if len(recs) > 3:\n",
    "                print(f\"    ... and {len(recs) - 3} more\")\n",
    "    \n",
    "    # Check if gold layer exists but is empty\n",
    "    if registry.gold:\n",
    "        print(f\"\\n\u2713 Gold layer initialized (target: {registry.gold.target_column})\")\n",
    "    else:\n",
    "        print(\"\\n\u26a0 Gold layer not initialized - run step 06 first\")\n",
    "    \n",
    "    print()\n",
    "    print(\"Use this hash to:\")\n",
    "    print(\"  - Track MLflow experiments (tag: recommendations_hash)\")\n",
    "    print(\"  - Version Feast feature views (tag in feature_store)\")\n",
    "    print(\"  - Return to a specific feature engineering configuration\")\n",
    "else:\n",
    "    print(\"No recommendations loaded - hash not available\")\n",
    "    print(\"Run notebooks 02-07 first, then re-run this notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10.9 Feast Feature Store Validation\n",
    "\n",
    "Check what's registered in Feast after running the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10.10 Next Steps\n",
    "\n",
    "### Run Pipeline (Single Command)\n",
    "```bash\n",
    "cd ../generated_pipelines/local/customer_churn\n",
    "python run_all.py\n",
    "```\n",
    "\n",
    "This single command:\n",
    "1. Runs Bronze layers in **parallel**\n",
    "2. Runs Silver merge\n",
    "3. Runs Gold features  \n",
    "4. Trains models with MLflow tracking\n",
    "5. **Auto-starts MLflow UI** and opens browser\n",
    "6. Press `Ctrl+C` to stop when done\n",
    "\n",
    "### Generated Structure\n",
    "```\n",
    "generated_pipelines/local/{pipeline}/\n",
    "\u251c\u2500\u2500 run_all.py          # Single entry point\n",
    "\u251c\u2500\u2500 config.py           # Configuration (includes RECOMMENDATIONS_HASH)\n",
    "\u251c\u2500\u2500 bronze/\n",
    "\u2502   \u2514\u2500\u2500 bronze_*.py     # Parallel execution\n",
    "\u251c\u2500\u2500 silver/\n",
    "\u2502   \u2514\u2500\u2500 silver_merge.py\n",
    "\u251c\u2500\u2500 gold/\n",
    "\u2502   \u2514\u2500\u2500 gold_features.py  # Includes feature version tag\n",
    "\u251c\u2500\u2500 training/\n",
    "\u2502   \u2514\u2500\u2500 ml_experiment.py  # MLflow tags with recommendations_hash\n",
    "\u251c\u2500\u2500 pipeline.py         # Standalone pipeline script\n",
    "\u2514\u2500\u2500 requirements.txt\n",
    "```\n",
    "\n",
    "### Tracking Your Experiment\n",
    "After running, you can find your experiment by:\n",
    "- **MLflow UI**: Filter by tag `recommendations_hash = <your_hash>`\n",
    "- **Feast**: Check feature view tags for `recommendations_hash`\n",
    "- **Return to config**: The hash uniquely identifies the gold layer settings\n",
    "\n",
    "---\n",
    "\n",
    "## Complete!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}