{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: Feature Opportunities\n",
    "\n",
    "**Purpose:** Identify and implement feature engineering opportunities to improve model performance.\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to derive time-based features (tenure, recency, active period)\n",
    "- How to create composite engagement scores\n",
    "- How to segment customers based on behavior patterns\n",
    "- How to encode categorical variables effectively\n",
    "\n",
    "**Outputs:**\n",
    "- Derived feature recommendations with code examples\n",
    "- Composite score formulas (engagement, service adoption)\n",
    "- Customer segmentation rules\n",
    "- Categorical encoding strategies\n",
    "\n",
    "---\n",
    "\n",
    "## Why Feature Engineering Matters\n",
    "\n",
    "| Feature Type | Business Meaning | Predictive Power |\n",
    "|-------------|-----------------|------------------|\n",
    "| **Tenure** | How long customer has been with us | Loyalty indicator |\n",
    "| **Recency** | Days since last order | Engagement/churn signal |\n",
    "| **Engagement Score** | Combined email metrics | Overall engagement level |\n",
    "| **Segments** | High/Low value \u00d7 Frequent/Infrequent | Risk stratification |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from customer_retention.analysis.auto_explorer import ExplorationFindings, RecommendationEngine, RecommendationRegistry\n",
    "from customer_retention.analysis.visualization import ChartBuilder, display_figure, display_table\n",
    "from customer_retention.core.config.column_config import ColumnType\n",
    "from customer_retention.stages.features import CustomerSegmenter, SegmentationType\n",
    "from customer_retention.stages.profiling import FeatureCapacityAnalyzer\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from customer_retention.core.config.experiments import FINDINGS_DIR, EXPERIMENTS_DIR, OUTPUT_DIR, setup_experiments_structure\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 aggregated findings file(s)\n",
      "Using: ../experiments/findings/customer_emails_408768_aggregated_d24886_findings.yaml\n",
      "   (Skipping 1 event-level findings)\n",
      "Loaded existing recommendations: 293 total\n",
      "\n",
      "Loaded 4,998 rows from: aggregated:customer_emails_408768_aggregated.parquet\n"
     ]
    }
   ],
   "source": [
    "# === CONFIGURATION ===\n",
    "# Option 1: Set the exact path from notebook 01 output\n",
    "# FINDINGS_PATH = \"../experiments/findings/customer_retention_retail_abc123_findings.yaml\"\n",
    "\n",
    "# Option 2: Auto-discover the most recent findings file\n",
    "from pathlib import Path\n",
    "\n",
    "# FINDINGS_DIR imported from customer_retention.core.config.experiments\n",
    "\n",
    "findings_files = [f for f in FINDINGS_DIR.glob(\"*_findings.yaml\") if \"multi_dataset\" not in f.name]\n",
    "if not findings_files:\n",
    "    raise FileNotFoundError(f\"No findings files found in {FINDINGS_DIR}. Run notebook 01 first.\")\n",
    "\n",
    "# Prefer aggregated findings (from 01d) over event-level findings\n",
    "# Pattern: *_aggregated* in filename indicates aggregated data\n",
    "aggregated_files = [f for f in findings_files if \"_aggregated\" in f.name]\n",
    "non_aggregated_files = [f for f in findings_files if \"_aggregated\" not in f.name]\n",
    "\n",
    "if aggregated_files:\n",
    "    # Use most recent aggregated file\n",
    "    aggregated_files.sort(key=lambda f: f.stat().st_mtime, reverse=True)\n",
    "    FINDINGS_PATH = str(aggregated_files[0])\n",
    "    print(f\"Found {len(aggregated_files)} aggregated findings file(s)\")\n",
    "    print(f\"Using: {FINDINGS_PATH}\")\n",
    "    if non_aggregated_files:\n",
    "        print(f\"   (Skipping {len(non_aggregated_files)} event-level findings)\")\n",
    "else:\n",
    "    # Fall back to most recent non-aggregated file\n",
    "    non_aggregated_files.sort(key=lambda f: f.stat().st_mtime, reverse=True)\n",
    "    FINDINGS_PATH = str(non_aggregated_files[0])\n",
    "    print(f\"Found {len(findings_files)} findings file(s)\")\n",
    "    print(f\"Using: {FINDINGS_PATH}\")\n",
    "\n",
    "RECOMMENDATIONS_PATH = FINDINGS_PATH.replace(\"_findings.yaml\", \"_recommendations.yaml\")\n",
    "\n",
    "findings = ExplorationFindings.load(FINDINGS_PATH)\n",
    "\n",
    "# Load data - handle aggregated vs standard paths\n",
    "from customer_retention.stages.temporal import load_data_with_snapshot_preference, TEMPORAL_METADATA_COLS\n",
    "\n",
    "# For aggregated data, load directly from the parquet source\n",
    "if \"_aggregated\" in FINDINGS_PATH and findings.source_path.endswith('.parquet'):\n",
    "    source_path = Path(findings.source_path)\n",
    "    # Handle relative path from notebook directory\n",
    "    if not source_path.is_absolute():\n",
    "        # The source_path in findings is relative to project root\n",
    "        if str(source_path).startswith(\"experiments\"):\n",
    "            source_path = Path(\"..\") / source_path\n",
    "        else:\n",
    "            source_path = FINDINGS_DIR / source_path.name\n",
    "    df = pd.read_parquet(source_path)\n",
    "    data_source = f\"aggregated:{source_path.name}\"\n",
    "else:\n",
    "    # Standard loading for event-level or entity-level data\n",
    "    df, data_source = load_data_with_snapshot_preference(findings, output_dir=str(FINDINGS_DIR))\n",
    "\n",
    "charts = ChartBuilder()\n",
    "\n",
    "if Path(RECOMMENDATIONS_PATH).exists():\n",
    "    with open(RECOMMENDATIONS_PATH, \"r\") as f:\n",
    "        registry = RecommendationRegistry.from_dict(yaml.safe_load(f))\n",
    "    print(f\"Loaded existing recommendations: {len(registry.all_recommendations)} total\")\n",
    "else:\n",
    "    registry = RecommendationRegistry()\n",
    "    print(\"Initialized new recommendation registry\")\n",
    "\n",
    "# Ensure all layers are initialized (even if loaded from file)\n",
    "if not registry.bronze:\n",
    "    registry.init_bronze(findings.source_path)\n",
    "if not registry.silver:\n",
    "    registry.init_silver(findings.entity_column or \"entity_id\")\n",
    "if not registry.gold:\n",
    "    registry.init_gold(findings.target_column or \"target\")\n",
    "    print(\"  Initialized gold layer for feature engineering recommendations\")\n",
    "\n",
    "print(f\"\\nLoaded {len(df):,} rows from: {data_source}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Automated Feature Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 107 feature engineering opportunities:\n",
      "\n",
      "event_count_180d_binned\n",
      "  Source: event_count_180d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of event_count_180d\n",
      "\n",
      "event_count_180d_log\n",
      "  Source: event_count_180d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of event_count_180d (high skewness)\n",
      "\n",
      "event_count_365d_binned\n",
      "  Source: event_count_365d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of event_count_365d\n",
      "\n",
      "event_count_365d_log\n",
      "  Source: event_count_365d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of event_count_365d (high skewness)\n",
      "\n",
      "event_count_all_time_binned\n",
      "  Source: event_count_all_time\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of event_count_all_time\n",
      "\n",
      "event_count_all_time_log\n",
      "  Source: event_count_all_time\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of event_count_all_time (high skewness)\n",
      "\n",
      "time_to_open_hours_sum_180d_binned\n",
      "  Source: time_to_open_hours_sum_180d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of time_to_open_hours_sum_180d\n",
      "\n",
      "time_to_open_hours_sum_180d_log\n",
      "  Source: time_to_open_hours_sum_180d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of time_to_open_hours_sum_180d (high skewness)\n",
      "\n",
      "time_to_open_hours_mean_180d_binned\n",
      "  Source: time_to_open_hours_mean_180d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of time_to_open_hours_mean_180d\n",
      "\n",
      "time_to_open_hours_mean_180d_log\n",
      "  Source: time_to_open_hours_mean_180d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of time_to_open_hours_mean_180d (high skewness)\n",
      "\n",
      "time_to_open_hours_max_180d_binned\n",
      "  Source: time_to_open_hours_max_180d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of time_to_open_hours_max_180d\n",
      "\n",
      "time_to_open_hours_max_180d_log\n",
      "  Source: time_to_open_hours_max_180d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of time_to_open_hours_max_180d (high skewness)\n",
      "\n",
      "time_to_open_hours_count_180d_binned\n",
      "  Source: time_to_open_hours_count_180d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of time_to_open_hours_count_180d\n",
      "\n",
      "time_to_open_hours_count_180d_log\n",
      "  Source: time_to_open_hours_count_180d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of time_to_open_hours_count_180d (high skewness)\n",
      "\n",
      "send_hour_sum_180d_binned\n",
      "  Source: send_hour_sum_180d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of send_hour_sum_180d\n",
      "\n",
      "send_hour_sum_180d_log\n",
      "  Source: send_hour_sum_180d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of send_hour_sum_180d (high skewness)\n",
      "\n",
      "send_hour_mean_180d_binned\n",
      "  Source: send_hour_mean_180d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of send_hour_mean_180d\n",
      "\n",
      "send_hour_max_180d_binned\n",
      "  Source: send_hour_max_180d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of send_hour_max_180d\n",
      "\n",
      "send_hour_count_180d_binned\n",
      "  Source: send_hour_count_180d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of send_hour_count_180d\n",
      "\n",
      "send_hour_count_180d_log\n",
      "  Source: send_hour_count_180d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of send_hour_count_180d (high skewness)\n",
      "\n",
      "opened_sum_180d_binned\n",
      "  Source: opened_sum_180d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of opened_sum_180d\n",
      "\n",
      "opened_sum_180d_log\n",
      "  Source: opened_sum_180d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of opened_sum_180d (high skewness)\n",
      "\n",
      "opened_mean_180d_binned\n",
      "  Source: opened_mean_180d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of opened_mean_180d\n",
      "\n",
      "opened_mean_180d_log\n",
      "  Source: opened_mean_180d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of opened_mean_180d (high skewness)\n",
      "\n",
      "opened_count_180d_binned\n",
      "  Source: opened_count_180d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of opened_count_180d\n",
      "\n",
      "opened_count_180d_log\n",
      "  Source: opened_count_180d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of opened_count_180d (high skewness)\n",
      "\n",
      "clicked_sum_180d_binned\n",
      "  Source: clicked_sum_180d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of clicked_sum_180d\n",
      "\n",
      "clicked_sum_180d_log\n",
      "  Source: clicked_sum_180d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of clicked_sum_180d (high skewness)\n",
      "\n",
      "clicked_mean_180d_binned\n",
      "  Source: clicked_mean_180d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of clicked_mean_180d\n",
      "\n",
      "clicked_mean_180d_log\n",
      "  Source: clicked_mean_180d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of clicked_mean_180d (high skewness)\n",
      "\n",
      "clicked_count_180d_binned\n",
      "  Source: clicked_count_180d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of clicked_count_180d\n",
      "\n",
      "clicked_count_180d_log\n",
      "  Source: clicked_count_180d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of clicked_count_180d (high skewness)\n",
      "\n",
      "bounced_sum_180d_binned\n",
      "  Source: bounced_sum_180d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of bounced_sum_180d\n",
      "\n",
      "bounced_sum_180d_log\n",
      "  Source: bounced_sum_180d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of bounced_sum_180d (high skewness)\n",
      "\n",
      "bounced_mean_180d_binned\n",
      "  Source: bounced_mean_180d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of bounced_mean_180d\n",
      "\n",
      "bounced_mean_180d_log\n",
      "  Source: bounced_mean_180d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of bounced_mean_180d (high skewness)\n",
      "\n",
      "bounced_count_180d_binned\n",
      "  Source: bounced_count_180d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of bounced_count_180d\n",
      "\n",
      "bounced_count_180d_log\n",
      "  Source: bounced_count_180d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of bounced_count_180d (high skewness)\n",
      "\n",
      "time_to_open_hours_sum_365d_binned\n",
      "  Source: time_to_open_hours_sum_365d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of time_to_open_hours_sum_365d\n",
      "\n",
      "time_to_open_hours_sum_365d_log\n",
      "  Source: time_to_open_hours_sum_365d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of time_to_open_hours_sum_365d (high skewness)\n",
      "\n",
      "time_to_open_hours_mean_365d_binned\n",
      "  Source: time_to_open_hours_mean_365d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of time_to_open_hours_mean_365d\n",
      "\n",
      "time_to_open_hours_mean_365d_log\n",
      "  Source: time_to_open_hours_mean_365d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of time_to_open_hours_mean_365d (high skewness)\n",
      "\n",
      "time_to_open_hours_max_365d_binned\n",
      "  Source: time_to_open_hours_max_365d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of time_to_open_hours_max_365d\n",
      "\n",
      "time_to_open_hours_max_365d_log\n",
      "  Source: time_to_open_hours_max_365d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of time_to_open_hours_max_365d (high skewness)\n",
      "\n",
      "time_to_open_hours_count_365d_binned\n",
      "  Source: time_to_open_hours_count_365d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of time_to_open_hours_count_365d\n",
      "\n",
      "time_to_open_hours_count_365d_log\n",
      "  Source: time_to_open_hours_count_365d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of time_to_open_hours_count_365d (high skewness)\n",
      "\n",
      "send_hour_sum_365d_binned\n",
      "  Source: send_hour_sum_365d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of send_hour_sum_365d\n",
      "\n",
      "send_hour_sum_365d_log\n",
      "  Source: send_hour_sum_365d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of send_hour_sum_365d (high skewness)\n",
      "\n",
      "send_hour_mean_365d_binned\n",
      "  Source: send_hour_mean_365d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of send_hour_mean_365d\n",
      "\n",
      "send_hour_max_365d_binned\n",
      "  Source: send_hour_max_365d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of send_hour_max_365d\n",
      "\n",
      "send_hour_count_365d_binned\n",
      "  Source: send_hour_count_365d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of send_hour_count_365d\n",
      "\n",
      "send_hour_count_365d_log\n",
      "  Source: send_hour_count_365d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of send_hour_count_365d (high skewness)\n",
      "\n",
      "opened_sum_365d_binned\n",
      "  Source: opened_sum_365d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of opened_sum_365d\n",
      "\n",
      "opened_sum_365d_log\n",
      "  Source: opened_sum_365d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of opened_sum_365d (high skewness)\n",
      "\n",
      "opened_mean_365d_binned\n",
      "  Source: opened_mean_365d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of opened_mean_365d\n",
      "\n",
      "opened_mean_365d_log\n",
      "  Source: opened_mean_365d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of opened_mean_365d (high skewness)\n",
      "\n",
      "opened_count_365d_binned\n",
      "  Source: opened_count_365d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of opened_count_365d\n",
      "\n",
      "opened_count_365d_log\n",
      "  Source: opened_count_365d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of opened_count_365d (high skewness)\n",
      "\n",
      "clicked_sum_365d_binned\n",
      "  Source: clicked_sum_365d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of clicked_sum_365d\n",
      "\n",
      "clicked_sum_365d_log\n",
      "  Source: clicked_sum_365d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of clicked_sum_365d (high skewness)\n",
      "\n",
      "clicked_mean_365d_binned\n",
      "  Source: clicked_mean_365d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of clicked_mean_365d\n",
      "\n",
      "clicked_mean_365d_log\n",
      "  Source: clicked_mean_365d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of clicked_mean_365d (high skewness)\n",
      "\n",
      "clicked_count_365d_binned\n",
      "  Source: clicked_count_365d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of clicked_count_365d\n",
      "\n",
      "clicked_count_365d_log\n",
      "  Source: clicked_count_365d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of clicked_count_365d (high skewness)\n",
      "\n",
      "bounced_sum_365d_binned\n",
      "  Source: bounced_sum_365d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of bounced_sum_365d\n",
      "\n",
      "bounced_sum_365d_log\n",
      "  Source: bounced_sum_365d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of bounced_sum_365d (high skewness)\n",
      "\n",
      "bounced_mean_365d_binned\n",
      "  Source: bounced_mean_365d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of bounced_mean_365d\n",
      "\n",
      "bounced_mean_365d_log\n",
      "  Source: bounced_mean_365d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of bounced_mean_365d (high skewness)\n",
      "\n",
      "bounced_count_365d_binned\n",
      "  Source: bounced_count_365d\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of bounced_count_365d\n",
      "\n",
      "bounced_count_365d_log\n",
      "  Source: bounced_count_365d\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of bounced_count_365d (high skewness)\n",
      "\n",
      "time_to_open_hours_sum_all_time_binned\n",
      "  Source: time_to_open_hours_sum_all_time\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of time_to_open_hours_sum_all_time\n",
      "\n",
      "time_to_open_hours_sum_all_time_log\n",
      "  Source: time_to_open_hours_sum_all_time\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of time_to_open_hours_sum_all_time (high skewness)\n",
      "\n",
      "time_to_open_hours_mean_all_time_binned\n",
      "  Source: time_to_open_hours_mean_all_time\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of time_to_open_hours_mean_all_time\n",
      "\n",
      "time_to_open_hours_mean_all_time_log\n",
      "  Source: time_to_open_hours_mean_all_time\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of time_to_open_hours_mean_all_time (high skewness)\n",
      "\n",
      "time_to_open_hours_max_all_time_binned\n",
      "  Source: time_to_open_hours_max_all_time\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of time_to_open_hours_max_all_time\n",
      "\n",
      "time_to_open_hours_max_all_time_log\n",
      "  Source: time_to_open_hours_max_all_time\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of time_to_open_hours_max_all_time (high skewness)\n",
      "\n",
      "time_to_open_hours_count_all_time_binned\n",
      "  Source: time_to_open_hours_count_all_time\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of time_to_open_hours_count_all_time\n",
      "\n",
      "time_to_open_hours_count_all_time_log\n",
      "  Source: time_to_open_hours_count_all_time\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of time_to_open_hours_count_all_time (high skewness)\n",
      "\n",
      "send_hour_sum_all_time_binned\n",
      "  Source: send_hour_sum_all_time\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of send_hour_sum_all_time\n",
      "\n",
      "send_hour_sum_all_time_log\n",
      "  Source: send_hour_sum_all_time\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of send_hour_sum_all_time (high skewness)\n",
      "\n",
      "send_hour_mean_all_time_binned\n",
      "  Source: send_hour_mean_all_time\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of send_hour_mean_all_time\n",
      "\n",
      "send_hour_max_all_time_binned\n",
      "  Source: send_hour_max_all_time\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of send_hour_max_all_time\n",
      "\n",
      "send_hour_max_all_time_log\n",
      "  Source: send_hour_max_all_time\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of send_hour_max_all_time (high skewness)\n",
      "\n",
      "send_hour_count_all_time_binned\n",
      "  Source: send_hour_count_all_time\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of send_hour_count_all_time\n",
      "\n",
      "send_hour_count_all_time_log\n",
      "  Source: send_hour_count_all_time\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of send_hour_count_all_time (high skewness)\n",
      "\n",
      "opened_sum_all_time_binned\n",
      "  Source: opened_sum_all_time\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of opened_sum_all_time\n",
      "\n",
      "opened_sum_all_time_log\n",
      "  Source: opened_sum_all_time\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of opened_sum_all_time (high skewness)\n",
      "\n",
      "opened_mean_all_time_binned\n",
      "  Source: opened_mean_all_time\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of opened_mean_all_time\n",
      "\n",
      "opened_count_all_time_binned\n",
      "  Source: opened_count_all_time\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of opened_count_all_time\n",
      "\n",
      "opened_count_all_time_log\n",
      "  Source: opened_count_all_time\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of opened_count_all_time (high skewness)\n",
      "\n",
      "clicked_sum_all_time_binned\n",
      "  Source: clicked_sum_all_time\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of clicked_sum_all_time\n",
      "\n",
      "clicked_sum_all_time_log\n",
      "  Source: clicked_sum_all_time\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of clicked_sum_all_time (high skewness)\n",
      "\n",
      "clicked_mean_all_time_binned\n",
      "  Source: clicked_mean_all_time\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of clicked_mean_all_time\n",
      "\n",
      "clicked_mean_all_time_log\n",
      "  Source: clicked_mean_all_time\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of clicked_mean_all_time (high skewness)\n",
      "\n",
      "clicked_count_all_time_binned\n",
      "  Source: clicked_count_all_time\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of clicked_count_all_time\n",
      "\n",
      "clicked_count_all_time_log\n",
      "  Source: clicked_count_all_time\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of clicked_count_all_time (high skewness)\n",
      "\n",
      "bounced_sum_all_time_binned\n",
      "  Source: bounced_sum_all_time\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of bounced_sum_all_time\n",
      "\n",
      "bounced_sum_all_time_log\n",
      "  Source: bounced_sum_all_time\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of bounced_sum_all_time (high skewness)\n",
      "\n",
      "bounced_mean_all_time_binned\n",
      "  Source: bounced_mean_all_time\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of bounced_mean_all_time\n",
      "\n",
      "bounced_mean_all_time_log\n",
      "  Source: bounced_mean_all_time\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of bounced_mean_all_time (high skewness)\n",
      "\n",
      "bounced_count_all_time_binned\n",
      "  Source: bounced_count_all_time\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of bounced_count_all_time\n",
      "\n",
      "bounced_count_all_time_log\n",
      "  Source: bounced_count_all_time\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of bounced_count_all_time (high skewness)\n",
      "\n",
      "days_since_last_event_binned\n",
      "  Source: days_since_last_event\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of days_since_last_event\n",
      "\n",
      "days_since_last_event_log\n",
      "  Source: days_since_last_event\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of days_since_last_event (high skewness)\n",
      "\n",
      "days_since_first_event_binned\n",
      "  Source: days_since_first_event\n",
      "  Type: numeric\n",
      "  Priority: low\n",
      "  Description: Binned version of days_since_first_event\n",
      "\n",
      "days_since_first_event_log\n",
      "  Source: days_since_first_event\n",
      "  Type: numeric\n",
      "  Priority: high\n",
      "  Description: Log transform of days_since_first_event (high skewness)\n",
      "\n",
      "lifecycle_quadrant_encoded\n",
      "  Source: lifecycle_quadrant\n",
      "  Type: categorical\n",
      "  Priority: high\n",
      "  Description: One-hot encoded lifecycle_quadrant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommender = RecommendationEngine()\n",
    "feature_recs = recommender.recommend_features(findings)\n",
    "\n",
    "print(f\"Found {len(feature_recs)} feature engineering opportunities:\\n\")\n",
    "\n",
    "for rec in feature_recs:\n",
    "    print(f\"{rec.feature_name}\")\n",
    "    print(f\"  Source: {rec.source_column}\")\n",
    "    print(f\"  Type: {rec.feature_type}\")\n",
    "    print(f\"  Priority: {rec.priority}\")\n",
    "    print(f\"  Description: {rec.description}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Feature Capacity Analysis\n",
    "\n",
    "**\ud83d\udcd6 Understanding Feature-to-Data Ratios**\n",
    "\n",
    "Before creating new features, it's critical to understand how many features your data can reliably support. This analysis uses the **Events Per Variable (EPV)** principle:\n",
    "\n",
    "| EPV Level | Risk Level | Recommendations |\n",
    "|-----------|------------|-----------------|\n",
    "| **EPV \u2265 20** | Low risk | Stable coefficients, reliable inference |\n",
    "| **EPV = 10-20** | Moderate | Standard practice, consider regularization |\n",
    "| **EPV = 5-10** | Elevated | Strong regularization required (L1/Lasso) |\n",
    "| **EPV < 5** | High risk | Reduce features or collect more data |\n",
    "\n",
    "**Key Assumptions:**\n",
    "1. **Minority class drives capacity**: For classification, the smaller class limits feature count\n",
    "2. **Correlated features are redundant**: Highly correlated features (r > 0.8) count as ~1 effective feature\n",
    "3. **Model type matters**: Tree models are more flexible than linear models\n",
    "4. **Regularization helps**: L1/L2 penalties allow more features with less data\n",
    "\n",
    "**\ud83d\udcca What This Analysis Provides:**\n",
    "- Recommended feature counts (conservative/moderate/aggressive)\n",
    "- Effective feature count after removing redundancy\n",
    "- Model complexity guidance (linear vs tree-based)\n",
    "- Segment-specific capacity for multi-model strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FEATURE CAPACITY ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "\ud83d\udcca DATA SUMMARY:\n",
      "   Total samples: 4,998\n",
      "   Minority class samples: 1,973\n",
      "   Minority class rate: 39.5%\n",
      "   Current numeric features: 56\n",
      "\n",
      "\ud83d\udcc8 FEATURE CAPACITY METRICS:\n",
      "   Events Per Variable (EPV): 35.2\n",
      "   Samples Per Feature: 89.2\n",
      "   Capacity Status: ADEQUATE\n",
      "\n",
      "\ud83c\udfaf RECOMMENDED FEATURE COUNTS:\n",
      "   Conservative (EPV=20): 98 features\n",
      "   Moderate (EPV=10):     197 features\n",
      "   Aggressive (EPV=5):    394 features\n",
      "\n",
      "\ud83d\udd0d EFFECTIVE FEATURES (accounting for correlation):\n",
      "   Total features analyzed: 56\n",
      "   Effective independent features: 16.0\n",
      "   Redundant features identified: 29\n",
      "\n",
      "   \u26a0\ufe0f Redundant features (highly correlated):\n",
      "      \u2022 bounced_mean_365d\n",
      "      \u2022 clicked_count_180d\n",
      "      \u2022 time_to_open_hours_count_all_time\n",
      "      \u2022 opened_sum_365d\n",
      "      \u2022 send_hour_sum_all_time\n",
      "\n",
      "   \ud83d\udce6 Correlated feature clusters (12):\n",
      "      Cluster 1: event_count_180d, event_count_365d, send_hour_sum_180d, send_hour_count_180d\n",
      "                  ... and 7 more\n",
      "      Cluster 2: event_count_all_time, send_hour_sum_all_time, send_hour_count_all_time, opened_count_all_time\n",
      "                  ... and 2 more\n",
      "      Cluster 3: time_to_open_hours_sum_180d, time_to_open_hours_mean_180d, time_to_open_hours_max_180d\n",
      "\n",
      "\u2705 Persisted feature capacity recommendation to registry\n"
     ]
    }
   ],
   "source": [
    "# Feature Capacity Analysis\n",
    "capacity_analyzer = FeatureCapacityAnalyzer()\n",
    "\n",
    "# Get all potential feature columns (excluding target and identifiers)\n",
    "feature_cols = [\n",
    "    name for name, col in findings.columns.items()\n",
    "    if col.inferred_type in [\n",
    "        ColumnType.NUMERIC_CONTINUOUS, ColumnType.NUMERIC_DISCRETE,\n",
    "        ColumnType.CATEGORICAL_NOMINAL, ColumnType.CATEGORICAL_ORDINAL,\n",
    "        ColumnType.BINARY\n",
    "    ] and name != findings.target_column\n",
    "    and name not in TEMPORAL_METADATA_COLS\n",
    "]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE CAPACITY ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if findings.target_column:\n",
    "    # Analyze capacity with current features\n",
    "    numeric_features = [\n",
    "        name for name, col in findings.columns.items()\n",
    "        if col.inferred_type in [ColumnType.NUMERIC_CONTINUOUS, ColumnType.NUMERIC_DISCRETE]\n",
    "        and name != findings.target_column\n",
    "    ]\n",
    "    \n",
    "    capacity_result = capacity_analyzer.analyze(\n",
    "        df,\n",
    "        feature_cols=numeric_features,\n",
    "        target_col=findings.target_column,\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n\ud83d\udcca DATA SUMMARY:\")\n",
    "    print(f\"   Total samples: {capacity_result.total_samples:,}\")\n",
    "    print(f\"   Minority class samples: {capacity_result.minority_class_samples:,}\")\n",
    "    print(f\"   Minority class rate: {capacity_result.minority_class_samples/capacity_result.total_samples:.1%}\")\n",
    "    print(f\"   Current numeric features: {capacity_result.total_features}\")\n",
    "    \n",
    "    print(f\"\\n\ud83d\udcc8 FEATURE CAPACITY METRICS:\")\n",
    "    print(f\"   Events Per Variable (EPV): {capacity_result.events_per_variable:.1f}\")\n",
    "    print(f\"   Samples Per Feature: {capacity_result.samples_per_feature:.1f}\")\n",
    "    print(f\"   Capacity Status: {capacity_result.capacity_status.upper()}\")\n",
    "    \n",
    "    # Capacity status visualization\n",
    "    status_colors = {\"adequate\": \"#2ecc71\", \"limited\": \"#f39c12\", \"inadequate\": \"#e74c3c\"}\n",
    "    status_color = status_colors.get(capacity_result.capacity_status, \"#95a5a6\")\n",
    "    \n",
    "    print(f\"\\n\ud83c\udfaf RECOMMENDED FEATURE COUNTS:\")\n",
    "    print(f\"   Conservative (EPV=20): {capacity_result.recommended_features_conservative} features\")\n",
    "    print(f\"   Moderate (EPV=10):     {capacity_result.recommended_features_moderate} features\")\n",
    "    print(f\"   Aggressive (EPV=5):    {capacity_result.recommended_features_aggressive} features\")\n",
    "    \n",
    "    # Effective features analysis\n",
    "    if capacity_result.effective_features_result:\n",
    "        eff = capacity_result.effective_features_result\n",
    "        print(f\"\\n\ud83d\udd0d EFFECTIVE FEATURES (accounting for correlation):\")\n",
    "        print(f\"   Total features analyzed: {eff.total_count}\")\n",
    "        print(f\"   Effective independent features: {eff.effective_count:.1f}\")\n",
    "        print(f\"   Redundant features identified: {len(eff.redundant_features)}\")\n",
    "        \n",
    "        if eff.redundant_features:\n",
    "            print(f\"\\n   \u26a0\ufe0f Redundant features (highly correlated):\")\n",
    "            for feat in eff.redundant_features[:5]:\n",
    "                print(f\"      \u2022 {feat}\")\n",
    "        \n",
    "        if eff.feature_clusters:\n",
    "            print(f\"\\n   \ud83d\udce6 Correlated feature clusters ({len(eff.feature_clusters)}):\")\n",
    "            for i, cluster in enumerate(eff.feature_clusters[:3]):\n",
    "                print(f\"      Cluster {i+1}: {', '.join(cluster[:4])}\")\n",
    "                if len(cluster) > 4:\n",
    "                    print(f\"                  ... and {len(cluster)-4} more\")\n",
    "    \n",
    "    # Persist feature capacity to registry\n",
    "    registry.add_bronze_feature_capacity(\n",
    "        epv=capacity_result.events_per_variable,\n",
    "        capacity_status=capacity_result.capacity_status,\n",
    "        recommended_features=capacity_result.recommended_features_moderate,\n",
    "        current_features=capacity_result.total_features,\n",
    "        rationale=f\"EPV={capacity_result.events_per_variable:.1f}, status={capacity_result.capacity_status}\",\n",
    "        source_notebook=\"06_feature_opportunities\"\n",
    "    )\n",
    "    print(f\"\\n\u2705 Persisted feature capacity recommendation to registry\")\n",
    "    \n",
    "    # Store capacity info in findings\n",
    "    findings.metadata[\"feature_capacity\"] = capacity_result.to_dict()\n",
    "else:\n",
    "    print(\"\\n\u26a0\ufe0f No target column detected. Capacity analysis requires a target variable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1 Model Complexity Guidance\n",
    "\n",
    "Based on your data capacity, here's guidance on model complexity and feature limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODEL COMPLEXITY GUIDANCE\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly",
        "responsive": false
       },
       "data": [
        {
         "marker": {
          "color": [
           "#2ecc71",
           "#2ecc71",
           "#2ecc71"
          ]
         },
         "name": "Max Features",
         "text": [
          "197",
          "394",
          "166"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "Linear\n(no regularization)",
          "Regularized\n(L1/L2)",
          "Tree-based\n(RF/XGBoost)"
         ],
         "y": [
          197,
          394,
          166
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "Current: 56",
          "x": 1,
          "xanchor": "left",
          "xref": "x domain",
          "y": 56,
          "yanchor": "middle",
          "yref": "y"
         }
        ],
        "height": 400,
        "shapes": [
         {
          "line": {
           "color": "#3498db",
           "dash": "dash"
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x domain",
          "y0": 56,
          "y1": 56,
          "yref": "y"
         }
        ],
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Maximum Recommended Features by Model Type"
        },
        "xaxis": {
         "title": {
          "text": "Model Type"
         }
        },
        "yaxis": {
         "range": [
          0,
          453.09999999999997
         ],
         "title": {
          "text": "Max Features"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\ud83c\udfaf RECOMMENDED MODEL TYPE: Linear\n",
      "\n",
      "\ud83d\udccb MODEL-SPECIFIC RECOMMENDATIONS:\n",
      "   \u2022 Adequate data for standard logistic regression\n",
      "   \u2022 Can use all features without regularization\n",
      "   \u2022 Consider tree models for comparison\n",
      "\n",
      "\ud83d\udca1 GENERAL GUIDANCE:\n",
      "   Adequate: EPV=35.2. Sufficient data for robust modeling.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "FEATURE BUDGET SUMMARY:\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Max Features</th>\n",
       "      <th>Current</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear (no regularization)</td>\n",
       "      <td>197</td>\n",
       "      <td>56</td>\n",
       "      <td>\u2705 OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Regularized (L1/L2)</td>\n",
       "      <td>394</td>\n",
       "      <td>56</td>\n",
       "      <td>\u2705 OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tree-based</td>\n",
       "      <td>166</td>\n",
       "      <td>56</td>\n",
       "      <td>\u2705 OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model Type  Max Features  Current Status\n",
       "0  Linear (no regularization)           197       56   \u2705 OK\n",
       "1         Regularized (L1/L2)           394       56   \u2705 OK\n",
       "2                  Tree-based           166       56   \u2705 OK"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u2705 Persisted model type recommendation to registry: linear\n"
     ]
    }
   ],
   "source": [
    "# Model Complexity Guidance\n",
    "if findings.target_column and 'capacity_result' in dir():\n",
    "    guidance = capacity_result.complexity_guidance\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"MODEL COMPLEXITY GUIDANCE\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Create visualization of feature limits by model type\n",
    "    model_types = [\"Linear\\n(no regularization)\", \"Regularized\\n(L1/L2)\", \"Tree-based\\n(RF/XGBoost)\"]\n",
    "    max_features = [guidance.max_features_linear, guidance.max_features_regularized, guidance.max_features_tree]\n",
    "    current_features = capacity_result.total_features\n",
    "    \n",
    "    colors = ['#e74c3c' if m < current_features else '#2ecc71' for m in max_features]\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        x=model_types,\n",
    "        y=max_features,\n",
    "        marker_color=colors,\n",
    "        text=[f\"{m}\" for m in max_features],\n",
    "        textposition='outside',\n",
    "        name='Max Features'\n",
    "    ))\n",
    "    \n",
    "    # Add horizontal line for current feature count\n",
    "    fig.add_hline(\n",
    "        y=current_features,\n",
    "        line_dash=\"dash\",\n",
    "        line_color=\"#3498db\",\n",
    "        annotation_text=f\"Current: {current_features}\",\n",
    "        annotation_position=\"right\"\n",
    "    )\n",
    "    \n",
    "    # Calculate y-axis range to fit labels\n",
    "    max_val = max(max_features)\n",
    "    fig.update_layout(\n",
    "        title=\"Maximum Recommended Features by Model Type\",\n",
    "        xaxis_title=\"Model Type\",\n",
    "        yaxis_title=\"Max Features\",\n",
    "        yaxis_range=[0, max_val * 1.15],  # Add 15% headroom for labels\n",
    "        template='plotly_white',\n",
    "        height=400,\n",
    "        showlegend=False,\n",
    "    )\n",
    "    \n",
    "    display_figure(fig)\n",
    "    \n",
    "    print(f\"\\n\ud83c\udfaf RECOMMENDED MODEL TYPE: {guidance.recommended_model_type.replace('_', ' ').title()}\")\n",
    "    \n",
    "    print(\"\\n\ud83d\udccb MODEL-SPECIFIC RECOMMENDATIONS:\")\n",
    "    for rec in guidance.model_recommendations:\n",
    "        print(f\"   \u2022 {rec}\")\n",
    "    \n",
    "    print(\"\\n\ud83d\udca1 GENERAL GUIDANCE:\")\n",
    "    for rec in guidance.recommendations:\n",
    "        print(f\"   {rec}\")\n",
    "    \n",
    "    # Summary table\n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(\"FEATURE BUDGET SUMMARY:\")\n",
    "    print(\"-\" * 70)\n",
    "    summary_data = {\n",
    "        \"Model Type\": [\"Linear (no regularization)\", \"Regularized (L1/L2)\", \"Tree-based\"],\n",
    "        \"Max Features\": [guidance.max_features_linear, guidance.max_features_regularized, guidance.max_features_tree],\n",
    "        \"Current\": [current_features] * 3,\n",
    "        \"Status\": [\n",
    "            \"\u2705 OK\" if guidance.max_features_linear >= current_features else \"\u26a0\ufe0f Reduce\",\n",
    "            \"\u2705 OK\" if guidance.max_features_regularized >= current_features else \"\u26a0\ufe0f Reduce\", \n",
    "            \"\u2705 OK\" if guidance.max_features_tree >= current_features else \"\u26a0\ufe0f Reduce\"\n",
    "        ]\n",
    "    }\n",
    "    display(pd.DataFrame(summary_data))\n",
    "    \n",
    "    # Persist model type recommendation to registry\n",
    "    registry.add_bronze_model_type(\n",
    "        model_type=guidance.recommended_model_type,\n",
    "        max_features_linear=guidance.max_features_linear,\n",
    "        max_features_regularized=guidance.max_features_regularized,\n",
    "        max_features_tree=guidance.max_features_tree,\n",
    "        rationale=f\"Recommended: {guidance.recommended_model_type}\",\n",
    "        source_notebook=\"06_feature_opportunities\"\n",
    "    )\n",
    "    print(f\"\\n\u2705 Persisted model type recommendation to registry: {guidance.recommended_model_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 Segment-Specific Capacity (for Multi-Model Strategy)\n",
    "\n",
    "When considering **separate models per customer segment**, each segment must have sufficient data to support the feature set. This analysis shows whether segmented modeling is viable.\n",
    "\n",
    "**\ud83d\udcd6 Single Model vs Segment Models:**\n",
    "\n",
    "| Approach | When to Use | Pros | Cons |\n",
    "|----------|------------|------|------|\n",
    "| **Single Model** | Small data, uniform segments | More data per model, simpler | May miss segment-specific patterns |\n",
    "| **Segment Models** | Large data, distinct segments | Tailored patterns | Need sufficient data per segment |\n",
    "| **Hybrid** | Mixed segment sizes | Best of both | More complex to maintain |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SEGMENT CAPACITY ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "\ud83d\udcca Analyzing segments by: lifecycle_quadrant\n",
      "   Features to evaluate: 56\n",
      "\n",
      "\ud83c\udfaf RECOMMENDED STRATEGY: Single Model\n",
      "   Reason: No segments have adequate data for separate models.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segment</th>\n",
       "      <th>Samples</th>\n",
       "      <th>Minority Events</th>\n",
       "      <th>EPV</th>\n",
       "      <th>Max Features (EPV=10)</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Occasional &amp; Loyal</td>\n",
       "      <td>1631</td>\n",
       "      <td>126</td>\n",
       "      <td>2.2</td>\n",
       "      <td>12</td>\n",
       "      <td>Inadequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intense &amp; Brief</td>\n",
       "      <td>1627</td>\n",
       "      <td>355</td>\n",
       "      <td>6.3</td>\n",
       "      <td>35</td>\n",
       "      <td>Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steady &amp; Loyal</td>\n",
       "      <td>873</td>\n",
       "      <td>62</td>\n",
       "      <td>1.1</td>\n",
       "      <td>6</td>\n",
       "      <td>Inadequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One-shot</td>\n",
       "      <td>867</td>\n",
       "      <td>354</td>\n",
       "      <td>6.3</td>\n",
       "      <td>35</td>\n",
       "      <td>Limited</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Segment  Samples  Minority Events  EPV  Max Features (EPV=10)  \\\n",
       "3  Occasional & Loyal     1631              126  2.2                     12   \n",
       "0     Intense & Brief     1627              355  6.3                     35   \n",
       "2      Steady & Loyal      873               62  1.1                      6   \n",
       "1            One-shot      867              354  6.3                     35   \n",
       "\n",
       "       Status  \n",
       "3  Inadequate  \n",
       "0     Limited  \n",
       "2  Inadequate  \n",
       "1     Limited  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly",
        "responsive": false
       },
       "data": [
        {
         "marker": {
          "color": "#f39c12"
         },
         "name": "Intense & Brief",
         "text": [
          "EPV=6.3"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "Intense & Brief"
         ],
         "y": [
          355
         ]
        },
        {
         "marker": {
          "color": "#f39c12"
         },
         "name": "One-shot",
         "text": [
          "EPV=6.3"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "One-shot"
         ],
         "y": [
          354
         ]
        },
        {
         "marker": {
          "color": "#e74c3c"
         },
         "name": "Steady & Loyal",
         "text": [
          "EPV=1.1"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "Steady & Loyal"
         ],
         "y": [
          62
         ]
        },
        {
         "marker": {
          "color": "#e74c3c"
         },
         "name": "Occasional & Loyal",
         "text": [
          "EPV=2.2"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "Occasional & Loyal"
         ],
         "y": [
          126
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "Min events for 56 features (EPV=10)",
          "x": 1,
          "xanchor": "left",
          "xref": "x domain",
          "y": 560,
          "yanchor": "middle",
          "yref": "y"
         }
        ],
        "height": 400,
        "shapes": [
         {
          "line": {
           "color": "#3498db",
           "dash": "dash"
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x domain",
          "y0": 560,
          "y1": 560,
          "yref": "y"
         }
        ],
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Minority Class Events by Segment (lifecycle_quadrant)"
        },
        "xaxis": {
         "title": {
          "text": "Segment"
         }
        },
        "yaxis": {
         "range": [
          0,
          644
         ],
         "title": {
          "text": "Minority Class Events"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\ud83d\udccb SEGMENT RECOMMENDATIONS:\n",
      "   Small segments (Intense & Brief, One-shot, Steady & Loyal, Occasional & Loyal) have 897 total events.\n",
      "   Use a single model with segment as a feature for stratification.\n",
      "   \u26a0\ufe0f Insufficient data: Intense & Brief, One-shot, Steady & Loyal, Occasional & Loyal\n"
     ]
    }
   ],
   "source": [
    "# Segment Capacity Analysis\n",
    "categorical_cols = [\n",
    "    name for name, col in findings.columns.items()\n",
    "    if col.inferred_type in [ColumnType.CATEGORICAL_NOMINAL, ColumnType.CATEGORICAL_ORDINAL]\n",
    "    and name not in TEMPORAL_METADATA_COLS\n",
    "]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SEGMENT CAPACITY ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if findings.target_column and categorical_cols and 'numeric_features' in dir():\n",
    "    # Analyze the first categorical column as potential segment\n",
    "    segment_col = categorical_cols[0]\n",
    "    \n",
    "    print(f\"\\n\ud83d\udcca Analyzing segments by: {segment_col}\")\n",
    "    print(f\"   Features to evaluate: {len(numeric_features)}\")\n",
    "    \n",
    "    segment_result = capacity_analyzer.analyze_segment_capacity(\n",
    "        df,\n",
    "        feature_cols=numeric_features,\n",
    "        target_col=findings.target_column,\n",
    "        segment_col=segment_col,\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n\ud83c\udfaf RECOMMENDED STRATEGY: {segment_result.recommended_strategy.replace('_', ' ').title()}\")\n",
    "    print(f\"   Reason: {segment_result.strategy_reason}\")\n",
    "    \n",
    "    # Segment details table\n",
    "    segment_data = []\n",
    "    for seg_name, cap in segment_result.segment_capacities.items():\n",
    "        segment_data.append({\n",
    "            \"Segment\": seg_name,\n",
    "            \"Samples\": cap.total_samples,\n",
    "            \"Minority Events\": cap.minority_class_samples,\n",
    "            \"EPV\": f\"{cap.events_per_variable:.1f}\",\n",
    "            \"Max Features (EPV=10)\": cap.recommended_features_moderate,\n",
    "            \"Status\": cap.capacity_status.title()\n",
    "        })\n",
    "    \n",
    "    segment_df = pd.DataFrame(segment_data)\n",
    "    segment_df = segment_df.sort_values(\"Samples\", ascending=False)\n",
    "    display(segment_df)\n",
    "    \n",
    "    # Visualization\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    max_events = 0\n",
    "    for seg_name, cap in segment_result.segment_capacities.items():\n",
    "        color = \"#2ecc71\" if cap.capacity_status == \"adequate\" else \"#f39c12\" if cap.capacity_status == \"limited\" else \"#e74c3c\"\n",
    "        fig.add_trace(go.Bar(\n",
    "            name=seg_name,\n",
    "            x=[seg_name],\n",
    "            y=[cap.minority_class_samples],\n",
    "            marker_color=color,\n",
    "            text=[f\"EPV={cap.events_per_variable:.1f}\"],\n",
    "            textposition='outside'\n",
    "        ))\n",
    "        max_events = max(max_events, cap.minority_class_samples)\n",
    "    \n",
    "    # Add threshold line\n",
    "    threshold_events = len(numeric_features) * 10  # EPV=10 threshold\n",
    "    fig.add_hline(\n",
    "        y=threshold_events,\n",
    "        line_dash=\"dash\",\n",
    "        line_color=\"#3498db\",\n",
    "        annotation_text=f\"Min events for {len(numeric_features)} features (EPV=10)\",\n",
    "        annotation_position=\"right\"\n",
    "    )\n",
    "    \n",
    "    # Calculate y-axis range to fit labels\n",
    "    y_max = max(max_events, threshold_events)\n",
    "    fig.update_layout(\n",
    "        title=f\"Minority Class Events by Segment ({segment_col})\",\n",
    "        xaxis_title=\"Segment\",\n",
    "        yaxis_title=\"Minority Class Events\",\n",
    "        yaxis_range=[0, y_max * 1.15],  # Add 15% headroom for labels\n",
    "        template='plotly_white',\n",
    "        height=400,\n",
    "        showlegend=False,\n",
    "    )\n",
    "    display_figure(fig)\n",
    "    \n",
    "    print(\"\\n\ud83d\udccb SEGMENT RECOMMENDATIONS:\")\n",
    "    for rec in segment_result.recommendations:\n",
    "        print(f\"   {rec}\")\n",
    "    \n",
    "    if segment_result.viable_segments:\n",
    "        print(f\"\\n   \u2705 Viable for separate models: {', '.join(segment_result.viable_segments)}\")\n",
    "    if segment_result.insufficient_segments:\n",
    "        print(f\"   \u26a0\ufe0f Insufficient data: {', '.join(segment_result.insufficient_segments)}\")\n",
    "    \n",
    "    # Store in findings\n",
    "    findings.metadata[\"segment_capacity\"] = segment_result.to_dict()\n",
    "else:\n",
    "    print(\"\\n\u26a0\ufe0f No categorical columns available for segment analysis.\")\n",
    "    print(\"   Segment capacity analysis requires at least one categorical column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.3 Feature Capacity Action Items\n",
    "\n",
    "Based on the analysis above, here are the key considerations for feature engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FEATURE CAPACITY ACTION ITEMS\n",
      "======================================================================\n",
      "\n",
      "\ud83d\udccb BASED ON YOUR DATA CAPACITY:\n",
      "\n",
      "\u2705 ADEQUATE CAPACITY - You have room to add features\n",
      "   \u2022 Current features: 56\n",
      "   \u2022 Can add up to: 141 more features (EPV=10)\n",
      "   \u2022 Consider: Creating derived features from datetime and categorical columns\n",
      "\n",
      "\ud83d\udd04 REDUNDANT FEATURES TO CONSIDER REMOVING:\n",
      "   These features are highly correlated with others and add little new information:\n",
      "   \u2022 bounced_mean_365d\n",
      "   \u2022 clicked_count_180d\n",
      "   \u2022 time_to_open_hours_count_all_time\n",
      "   \u2022 opened_sum_365d\n",
      "   \u2022 send_hour_sum_all_time\n",
      "   ... and 24 more\n",
      "\n",
      "\ud83d\udcb0 FEATURE BUDGET FOR NEW FEATURES:\n",
      "   You can safely add 141 new features\n",
      "   Prioritize:\n",
      "   \u2022 Recency features (days_since_last_activity)\n",
      "   \u2022 Tenure features (days_since_created)\n",
      "   \u2022 Engagement composites (email_engagement_score)\n",
      "\n",
      "\ud83c\udfaf RECOMMENDED MODELING APPROACH:\n",
      "   Model type: Linear\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Feature Capacity Action Items Summary\n",
    "if findings.target_column and 'capacity_result' in dir():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"FEATURE CAPACITY ACTION ITEMS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\\n\ud83d\udccb BASED ON YOUR DATA CAPACITY:\")\n",
    "    \n",
    "    # Action items based on capacity status\n",
    "    if capacity_result.capacity_status == \"adequate\":\n",
    "        print(\"\\n\u2705 ADEQUATE CAPACITY - You have room to add features\")\n",
    "        print(f\"   \u2022 Current features: {capacity_result.total_features}\")\n",
    "        print(f\"   \u2022 Can add up to: {capacity_result.recommended_features_moderate - capacity_result.total_features} more features (EPV=10)\")\n",
    "        print(f\"   \u2022 Consider: Creating derived features from datetime and categorical columns\")\n",
    "    elif capacity_result.capacity_status == \"limited\":\n",
    "        print(\"\\n\u26a0\ufe0f LIMITED CAPACITY - Be selective with new features\")\n",
    "        print(f\"   \u2022 Current features: {capacity_result.total_features}\")\n",
    "        print(f\"   \u2022 Recommended max: {capacity_result.recommended_features_moderate} features (EPV=10)\")\n",
    "        print(f\"   \u2022 Action: Remove {max(0, capacity_result.total_features - capacity_result.recommended_features_moderate)} redundant features before adding new ones\")\n",
    "        print(f\"   \u2022 Consider: Using regularization (L1/Lasso) if keeping all features\")\n",
    "    else:\n",
    "        print(\"\\n\ud83d\udd34 INADEQUATE CAPACITY - Reduce features or get more data\")\n",
    "        print(f\"   \u2022 Current features: {capacity_result.total_features}\")\n",
    "        print(f\"   \u2022 Recommended max: {capacity_result.recommended_features_moderate} features (EPV=10)\")\n",
    "        print(f\"   \u2022 CRITICAL: Reduce to {capacity_result.recommended_features_conservative} features for stable estimates\")\n",
    "        print(f\"   \u2022 Options: (1) Feature selection, (2) PCA, (3) Collect more data\")\n",
    "    \n",
    "    # Redundancy recommendations\n",
    "    if capacity_result.effective_features_result and capacity_result.effective_features_result.redundant_features:\n",
    "        redundant = capacity_result.effective_features_result.redundant_features\n",
    "        print(f\"\\n\ud83d\udd04 REDUNDANT FEATURES TO CONSIDER REMOVING:\")\n",
    "        print(f\"   These features are highly correlated with others and add little new information:\")\n",
    "        for feat in redundant[:5]:\n",
    "            print(f\"   \u2022 {feat}\")\n",
    "        if len(redundant) > 5:\n",
    "            print(f\"   ... and {len(redundant) - 5} more\")\n",
    "    \n",
    "    # New feature budget\n",
    "    print(\"\\n\ud83d\udcb0 FEATURE BUDGET FOR NEW FEATURES:\")\n",
    "    remaining_budget = capacity_result.recommended_features_moderate - capacity_result.total_features\n",
    "    if remaining_budget > 0:\n",
    "        print(f\"   You can safely add {remaining_budget} new features\")\n",
    "        print(\"   Prioritize:\")\n",
    "        print(\"   \u2022 Recency features (days_since_last_activity)\")\n",
    "        print(\"   \u2022 Tenure features (days_since_created)\")\n",
    "        print(\"   \u2022 Engagement composites (email_engagement_score)\")\n",
    "    else:\n",
    "        print(f\"   \u26a0\ufe0f At or over capacity. Remove {-remaining_budget} features before adding new ones.\")\n",
    "    \n",
    "    # Model selection summary\n",
    "    print(\"\\n\ud83c\udfaf RECOMMENDED MODELING APPROACH:\")\n",
    "    if capacity_result.complexity_guidance:\n",
    "        print(f\"   Model type: {capacity_result.complexity_guidance.recommended_model_type.replace('_', ' ').title()}\")\n",
    "        if \"regularized\" in capacity_result.complexity_guidance.recommended_model_type:\n",
    "            print(\"   \u2192 Use Lasso (L1) for automatic feature selection\")\n",
    "            print(\"   \u2192 Use Ridge (L2) if you want to keep all features\")\n",
    "        elif \"tree\" in capacity_result.complexity_guidance.recommended_model_type:\n",
    "            print(\"   \u2192 Random Forest or XGBoost recommended\")\n",
    "            print(\"   \u2192 Trees handle correlated features naturally\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Datetime Feature Opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No datetime columns found.\n"
     ]
    }
   ],
   "source": [
    "datetime_cols = [\n",
    "    name for name, col in findings.columns.items()\n",
    "    if col.inferred_type == ColumnType.DATETIME\n",
    "]\n",
    "\n",
    "if datetime_cols:\n",
    "    print(\"Datetime Feature Opportunities:\")\n",
    "    print(\"=\"*50)\n",
    "    for col in datetime_cols:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  - {col}_year: Extract year\")\n",
    "        print(f\"  - {col}_month: Extract month\")\n",
    "        print(f\"  - {col}_day: Extract day of month\")\n",
    "        print(f\"  - {col}_dayofweek: Extract day of week (0-6)\")\n",
    "        print(f\"  - {col}_is_weekend: Is weekend flag\")\n",
    "        print(f\"  - days_since_{col}: Days since date\")\n",
    "else:\n",
    "    print(\"No datetime columns found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Business-Driven Derived Features\n",
    "\n",
    "These features are based on domain knowledge from the reference analysis (my_take Phase 1).\n",
    "\n",
    "**\ud83d\udcd6 Key Derived Features:**\n",
    "- **Tenure Days**: Days from account creation to analysis date\n",
    "- **Days Since Last Order**: Recency indicator (critical for churn)\n",
    "- **Active Period Days**: Duration of customer activity\n",
    "- **Email Engagement Score**: Composite of open rate and click rate\n",
    "- **Click-to-Open Ratio**: Quality of email engagement\n",
    "- **Service Adoption Score**: Sum of service flags (paperless, refill, doorstep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CREATING DERIVED FEATURES\n",
      "======================================================================\n",
      "\n",
      "Reference date: 2026-01-26 05:35:01.625374\n",
      "\n",
      "\ud83d\udcc5 TIME-BASED FEATURES:\n",
      "\n",
      "\ud83d\udce7 ENGAGEMENT FEATURES:\n",
      "\n",
      "\ud83d\udd27 SERVICE ADOPTION:\n",
      "  \u2713 service_adoption_score from ['opened_max_180d', 'clicked_max_180d', 'bounced_max_180d', 'opened_max_365d', 'clicked_max_365d', 'bounced_max_365d', 'opened_max_all_time', 'clicked_max_all_time', 'bounced_max_all_time']\n",
      "\n",
      "\ud83d\udcb0 VALUE FEATURES:\n",
      "\n",
      "\u2713 Created 1 new features (total: 69)\n",
      "\u2705 Persisted 1 derived feature recommendations to registry\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"CREATING DERIVED FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "segmenter = CustomerSegmenter()\n",
    "df_features = df.copy()\n",
    "\n",
    "datetime_cols = [name for name, col in findings.columns.items() \n",
    "                 if col.inferred_type == ColumnType.DATETIME\n",
    "                 and name not in TEMPORAL_METADATA_COLS]\n",
    "binary_cols = [name for name, col in findings.columns.items() \n",
    "               if col.inferred_type == ColumnType.BINARY\n",
    "               and name not in TEMPORAL_METADATA_COLS]\n",
    "numeric_cols = [name for name, col in findings.columns.items() \n",
    "                if col.inferred_type in [ColumnType.NUMERIC_CONTINUOUS, ColumnType.NUMERIC_DISCRETE]]\n",
    "\n",
    "for col in datetime_cols:\n",
    "    df_features[col] = pd.to_datetime(df_features[col], errors='coerce', format='mixed')\n",
    "\n",
    "reference_date = pd.Timestamp.now()\n",
    "if datetime_cols:\n",
    "    last_dates = [df_features[col].max() for col in datetime_cols if df_features[col].notna().any()]\n",
    "    if last_dates:\n",
    "        reference_date = max(last_dates)\n",
    "print(f\"\\nReference date: {reference_date}\")\n",
    "\n",
    "print(\"\\n\ud83d\udcc5 TIME-BASED FEATURES:\")\n",
    "created_cols = [c for c in datetime_cols if 'creat' in c.lower() or 'signup' in c.lower() or 'register' in c.lower()]\n",
    "if created_cols:\n",
    "    created_col = created_cols[0]\n",
    "    df_features = segmenter.create_tenure_features(df_features, created_column=created_col, reference_date=reference_date)\n",
    "    print(f\"  \u2713 tenure_days from {created_col}\")\n",
    "    registry.add_silver_derived(\n",
    "        column=\"tenure_days\",\n",
    "        expression=f\"(reference_date - {created_col}).days\",\n",
    "        feature_type=\"tenure\",\n",
    "        rationale=f\"Customer tenure in days from {created_col}\",\n",
    "        source_notebook=\"06_feature_opportunities\"\n",
    "    )\n",
    "\n",
    "activity_cols = [c for c in datetime_cols if 'last' in c.lower() or 'recent' in c.lower()]\n",
    "if activity_cols:\n",
    "    activity_col = activity_cols[0]\n",
    "    df_features = segmenter.create_recency_features(df_features, last_activity_column=activity_col, \n",
    "                                                     reference_date=reference_date, output_column='days_since_last_activity')\n",
    "    print(f\"  \u2713 days_since_last_activity from {activity_col}\")\n",
    "    registry.add_silver_derived(\n",
    "        column=\"days_since_last_activity\",\n",
    "        expression=f\"(reference_date - {activity_col}).days\",\n",
    "        feature_type=\"recency\",\n",
    "        rationale=f\"Days since last activity from {activity_col}\",\n",
    "        source_notebook=\"06_feature_opportunities\"\n",
    "    )\n",
    "\n",
    "print(\"\\n\ud83d\udce7 ENGAGEMENT FEATURES:\")\n",
    "rate_cols = [c for c in numeric_cols if 'rate' in c.lower() or 'pct' in c.lower() or 'percent' in c.lower()]\n",
    "open_rate_cols = [c for c in rate_cols if 'open' in c.lower()]\n",
    "click_rate_cols = [c for c in rate_cols if 'click' in c.lower()]\n",
    "\n",
    "if open_rate_cols and click_rate_cols:\n",
    "    open_col, click_col = open_rate_cols[0], click_rate_cols[0]\n",
    "    df_features = segmenter.create_engagement_score(df_features, open_rate_column=open_col, \n",
    "                                                     click_rate_column=click_col, output_column='email_engagement_score')\n",
    "    print(f\"  \u2713 email_engagement_score from {open_col}, {click_col}\")\n",
    "    registry.add_silver_derived(\n",
    "        column=\"email_engagement_score\",\n",
    "        expression=f\"0.6 * {open_col} + 0.4 * {click_col}\",\n",
    "        feature_type=\"composite\",\n",
    "        rationale=f\"Weighted engagement score from {open_col} and {click_col}\",\n",
    "        source_notebook=\"06_feature_opportunities\"\n",
    "    )\n",
    "    \n",
    "    df_features['click_to_open_rate'] = np.where(df_features[open_col] > 0, df_features[click_col] / df_features[open_col], 0)\n",
    "    print(f\"  \u2713 click_to_open_rate\")\n",
    "    registry.add_silver_ratio(\n",
    "        column=\"click_to_open_rate\",\n",
    "        numerator=click_col,\n",
    "        denominator=open_col,\n",
    "        rationale=f\"Click-to-open ratio: {click_col} / {open_col}\",\n",
    "        source_notebook=\"06_feature_opportunities\"\n",
    "    )\n",
    "\n",
    "print(\"\\n\ud83d\udd27 SERVICE ADOPTION:\")\n",
    "if binary_cols:\n",
    "    service_binary = [c for c in binary_cols if c != findings.target_column]\n",
    "    if service_binary:\n",
    "        df_features['service_adoption_score'] = df_features[service_binary].sum(axis=1)\n",
    "        print(f\"  \u2713 service_adoption_score from {service_binary}\")\n",
    "        registry.add_silver_derived(\n",
    "            column=\"service_adoption_score\",\n",
    "            expression=f\"sum([{', '.join(service_binary)}])\",\n",
    "            feature_type=\"composite\",\n",
    "            rationale=f\"Service adoption count from {len(service_binary)} binary flags\",\n",
    "            source_notebook=\"06_feature_opportunities\"\n",
    "        )\n",
    "\n",
    "print(\"\\n\ud83d\udcb0 VALUE FEATURES:\")\n",
    "value_cols = [c for c in numeric_cols if 'order' in c.lower() or 'amount' in c.lower() or 'value' in c.lower() or 'avg' in c.lower()]\n",
    "freq_cols = [c for c in numeric_cols if 'freq' in c.lower() or 'count' in c.lower()]\n",
    "if value_cols and freq_cols:\n",
    "    df_features['value_frequency_product'] = df_features[value_cols[0]] * df_features[freq_cols[0]]\n",
    "    print(f\"  \u2713 value_frequency_product from {value_cols[0]}, {freq_cols[0]}\")\n",
    "    registry.add_silver_interaction(\n",
    "        column=\"value_frequency_product\",\n",
    "        features=[value_cols[0], freq_cols[0]],\n",
    "        rationale=f\"Value-frequency interaction: {value_cols[0]} \u00d7 {freq_cols[0]}\",\n",
    "        source_notebook=\"06_feature_opportunities\"\n",
    "    )\n",
    "\n",
    "new_cols = len(df_features.columns) - len(df.columns)\n",
    "print(f\"\\n\u2713 Created {new_cols} new features (total: {len(df_features.columns)})\")\n",
    "print(f\"\u2705 Persisted {len([c for c in ['tenure_days', 'days_since_last_activity', 'email_engagement_score', 'click_to_open_rate', 'service_adoption_score', 'value_frequency_product'] if c in df_features.columns])} derived feature recommendations to registry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 Customer Segmentation Features\n",
    "\n",
    "Create business-meaningful segments for analysis and modeling.\n",
    "\n",
    "**\ud83d\udcd6 Segmentation Strategy:**\n",
    "- **Value Dimension**: High vs Low (based on avgorder median)\n",
    "- **Frequency Dimension**: Frequent vs Infrequent (based on ordfreq median)\n",
    "- **Recency Buckets**: Active, Recent, Lapsing, Dormant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CUSTOMER SEGMENTATION\n",
      "======================================================================\n",
      "\n",
      "\ud83c\udfaf VALUE-FREQUENCY SEGMENTS:\n",
      "  No suitable value/frequency columns found\n",
      "\n",
      "\ud83d\udcc5 RECENCY SEGMENTS:\n",
      "  No recency column available\n",
      "\n",
      "\ud83d\udce7 ENGAGEMENT SEGMENTS:\n",
      "  No engagement score available\n",
      "\n",
      "\u2713 Created 0 segmentation features\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"CUSTOMER SEGMENTATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n\ud83c\udfaf VALUE-FREQUENCY SEGMENTS:\")\n",
    "value_cols = [c for c in numeric_cols if 'order' in c.lower() or 'amount' in c.lower() or 'value' in c.lower() or 'avg' in c.lower()]\n",
    "freq_cols = [c for c in numeric_cols if 'freq' in c.lower() or 'count' in c.lower()]\n",
    "\n",
    "if value_cols and freq_cols:\n",
    "    df_features, vf_result = segmenter.segment_by_value_frequency(\n",
    "        df_features, value_column=value_cols[0], frequency_column=freq_cols[0])\n",
    "    print(f\"  Using {value_cols[0]} \u00d7 {freq_cols[0]}\")\n",
    "    for seg in vf_result.segments:\n",
    "        print(f\"    {seg.name}: {seg.count:,} ({seg.percentage:.1f}%)\")\n",
    "else:\n",
    "    print(\"  No suitable value/frequency columns found\")\n",
    "\n",
    "print(\"\\n\ud83d\udcc5 RECENCY SEGMENTS:\")\n",
    "if 'days_since_last_activity' in df_features.columns:\n",
    "    df_features, recency_result = segmenter.segment_by_recency(df_features, days_since_column='days_since_last_activity')\n",
    "    for seg in recency_result.segments:\n",
    "        print(f\"    {seg.name}: {seg.count:,} ({seg.percentage:.1f}%)\")\n",
    "else:\n",
    "    print(\"  No recency column available\")\n",
    "\n",
    "print(\"\\n\ud83d\udce7 ENGAGEMENT SEGMENTS:\")\n",
    "if 'email_engagement_score' in df_features.columns:\n",
    "    max_score = df_features['email_engagement_score'].max()\n",
    "    if max_score > 0:\n",
    "        df_features['engagement_normalized'] = df_features['email_engagement_score'] / max_score\n",
    "        df_features, eng_result = segmenter.segment_by_engagement(df_features, engagement_column='engagement_normalized')\n",
    "        for seg in eng_result.segments:\n",
    "            print(f\"    {seg.name}: {seg.count:,} ({seg.percentage:.1f}%)\")\n",
    "        df_features = df_features.drop(columns=['engagement_normalized'])\n",
    "else:\n",
    "    print(\"  No engagement score available\")\n",
    "\n",
    "if 'customer_segment' in df_features.columns and findings.target_column and findings.target_column in df_features.columns:\n",
    "    target = findings.target_column\n",
    "    segment_retention = df_features.groupby('customer_segment')[target].mean() * 100\n",
    "    \n",
    "    max_rate = segment_retention.max()\n",
    "    fig = go.Figure(go.Bar(\n",
    "        x=segment_retention.index, y=segment_retention.values,\n",
    "        marker_color=['#2ca02c' if r > 70 else '#ffbb00' if r > 50 else '#d62728' for r in segment_retention.values],\n",
    "        text=[f'{r:.1f}%' for r in segment_retention.values], textposition='outside'))\n",
    "    fig.update_layout(\n",
    "        title='Retention Rate by Customer Segment', \n",
    "        xaxis_title='Segment', \n",
    "        yaxis_title='Retention Rate (%)',\n",
    "        yaxis_range=[0, max_rate * 1.15],  # Add 15% headroom for labels\n",
    "        template='plotly_white', \n",
    "        height=400,\n",
    "    )\n",
    "    display_figure(fig)\n",
    "\n",
    "segment_cols = [c for c in df_features.columns if 'segment' in c.lower() or 'bucket' in c.lower()]\n",
    "print(f\"\\n\u2713 Created {len(segment_cols)} segmentation features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 Numeric Transformation Opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Transformation Opportunities:\n",
      "==================================================\n",
      "\n",
      "event_count_180d:\n",
      "  Skewness: 2.14\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "event_count_365d:\n",
      "  Skewness: 1.95\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "event_count_all_time:\n",
      "  Skewness: 2.95\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for event_count_all_time_binned\n",
      "\n",
      "time_to_open_hours_sum_180d:\n",
      "  Skewness: 5.47\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for time_to_open_hours_sum_180d_binned\n",
      "\n",
      "time_to_open_hours_mean_180d:\n",
      "  Skewness: 2.03\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for time_to_open_hours_mean_180d_binned\n",
      "\n",
      "time_to_open_hours_max_180d:\n",
      "  Skewness: 1.80\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for time_to_open_hours_max_180d_binned\n",
      "\n",
      "time_to_open_hours_count_180d:\n",
      "  Skewness: 3.31\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "send_hour_sum_180d:\n",
      "  Skewness: 2.25\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for send_hour_sum_180d_binned\n",
      "\n",
      "send_hour_mean_180d:\n",
      "  Skewness: 0.05\n",
      "  Recommendation: Standard scaling sufficient\n",
      "  Binning: Consider creating bins for send_hour_mean_180d_binned\n",
      "\n",
      "send_hour_max_180d:\n",
      "  Skewness: -0.17\n",
      "  Recommendation: Standard scaling sufficient\n",
      "\n",
      "send_hour_count_180d:\n",
      "  Skewness: 2.14\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "opened_sum_180d:\n",
      "  Skewness: 3.31\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "opened_mean_180d:\n",
      "  Skewness: 1.36\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "opened_count_180d:\n",
      "  Skewness: 2.14\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "clicked_sum_180d:\n",
      "  Skewness: 4.79\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "clicked_mean_180d:\n",
      "  Skewness: 3.46\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "clicked_count_180d:\n",
      "  Skewness: 2.14\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "bounced_sum_180d:\n",
      "  Skewness: 7.50\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "bounced_mean_180d:\n",
      "  Skewness: 6.04\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "bounced_count_180d:\n",
      "  Skewness: 2.14\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "time_to_open_hours_sum_365d:\n",
      "  Skewness: 4.85\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for time_to_open_hours_sum_365d_binned\n",
      "\n",
      "time_to_open_hours_mean_365d:\n",
      "  Skewness: 1.93\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for time_to_open_hours_mean_365d_binned\n",
      "\n",
      "time_to_open_hours_max_365d:\n",
      "  Skewness: 1.81\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for time_to_open_hours_max_365d_binned\n",
      "\n",
      "time_to_open_hours_count_365d:\n",
      "  Skewness: 2.98\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "send_hour_sum_365d:\n",
      "  Skewness: 1.94\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for send_hour_sum_365d_binned\n",
      "\n",
      "send_hour_mean_365d:\n",
      "  Skewness: 0.06\n",
      "  Recommendation: Standard scaling sufficient\n",
      "  Binning: Consider creating bins for send_hour_mean_365d_binned\n",
      "\n",
      "send_hour_max_365d:\n",
      "  Skewness: -0.35\n",
      "  Recommendation: Standard scaling sufficient\n",
      "\n",
      "send_hour_count_365d:\n",
      "  Skewness: 1.95\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "opened_sum_365d:\n",
      "  Skewness: 2.98\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "opened_mean_365d:\n",
      "  Skewness: 1.33\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for opened_mean_365d_binned\n",
      "\n",
      "opened_count_365d:\n",
      "  Skewness: 1.95\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "clicked_sum_365d:\n",
      "  Skewness: 3.71\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "clicked_mean_365d:\n",
      "  Skewness: 3.28\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for clicked_mean_365d_binned\n",
      "\n",
      "clicked_count_365d:\n",
      "  Skewness: 1.95\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "bounced_sum_365d:\n",
      "  Skewness: 5.40\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "bounced_mean_365d:\n",
      "  Skewness: 5.94\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "bounced_count_365d:\n",
      "  Skewness: 1.95\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "time_to_open_hours_sum_all_time:\n",
      "  Skewness: 2.32\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for time_to_open_hours_sum_all_time_binned\n",
      "\n",
      "time_to_open_hours_mean_all_time:\n",
      "  Skewness: 1.98\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for time_to_open_hours_mean_all_time_binned\n",
      "\n",
      "time_to_open_hours_max_all_time:\n",
      "  Skewness: 1.32\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for time_to_open_hours_max_all_time_binned\n",
      "\n",
      "time_to_open_hours_count_all_time:\n",
      "  Skewness: 2.33\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for time_to_open_hours_count_all_time_binned\n",
      "\n",
      "send_hour_sum_all_time:\n",
      "  Skewness: 2.86\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for send_hour_sum_all_time_binned\n",
      "\n",
      "send_hour_mean_all_time:\n",
      "  Skewness: -0.24\n",
      "  Recommendation: Standard scaling sufficient\n",
      "  Binning: Consider creating bins for send_hour_mean_all_time_binned\n",
      "\n",
      "send_hour_max_all_time:\n",
      "  Skewness: -1.31\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "send_hour_count_all_time:\n",
      "  Skewness: 2.95\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for send_hour_count_all_time_binned\n",
      "\n",
      "opened_sum_all_time:\n",
      "  Skewness: 2.33\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for opened_sum_all_time_binned\n",
      "\n",
      "opened_mean_all_time:\n",
      "  Skewness: 0.41\n",
      "  Recommendation: Standard scaling sufficient\n",
      "  Binning: Consider creating bins for opened_mean_all_time_binned\n",
      "\n",
      "opened_count_all_time:\n",
      "  Skewness: 2.95\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for opened_count_all_time_binned\n",
      "\n",
      "clicked_sum_all_time:\n",
      "  Skewness: 2.07\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "clicked_mean_all_time:\n",
      "  Skewness: 1.24\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for clicked_mean_all_time_binned\n",
      "\n",
      "clicked_count_all_time:\n",
      "  Skewness: 2.95\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for clicked_count_all_time_binned\n",
      "\n",
      "bounced_sum_all_time:\n",
      "  Skewness: 2.02\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "\n",
      "bounced_mean_all_time:\n",
      "  Skewness: 6.85\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for bounced_mean_all_time_binned\n",
      "\n",
      "bounced_count_all_time:\n",
      "  Skewness: 2.95\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for bounced_count_all_time_binned\n",
      "\n",
      "days_since_last_event:\n",
      "  Skewness: 1.22\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for days_since_last_event_binned\n",
      "\n",
      "days_since_first_event:\n",
      "  Skewness: -1.88\n",
      "  Recommendation: Apply log transform (highly skewed)\n",
      "  Binning: Consider creating bins for days_since_first_event_binned\n",
      "\n",
      "\u2705 Persisted 56 transformation recommendations to registry\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = [\n",
    "    name for name, col in findings.columns.items()\n",
    "    if col.inferred_type in [ColumnType.NUMERIC_CONTINUOUS, ColumnType.NUMERIC_DISCRETE]\n",
    "    and name not in TEMPORAL_METADATA_COLS\n",
    "]\n",
    "\n",
    "transform_count = 0\n",
    "if numeric_cols:\n",
    "    print(\"Numeric Transformation Opportunities:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for col_name in numeric_cols:\n",
    "        col_info = findings.columns[col_name]\n",
    "        series = df[col_name].dropna()\n",
    "        skewness = series.skew()\n",
    "        \n",
    "        print(f\"\\n{col_name}:\")\n",
    "        print(f\"  Skewness: {skewness:.2f}\")\n",
    "        \n",
    "        if abs(skewness) > 1:\n",
    "            print(f\"  Recommendation: Apply log transform (highly skewed)\")\n",
    "            registry.add_gold_transformation(\n",
    "                column=col_name,\n",
    "                transform=\"log\",\n",
    "                parameters={\"skewness\": float(skewness), \"reason\": \"highly_skewed\"},\n",
    "                rationale=f\"Log transform for highly skewed distribution (skewness={skewness:.2f})\",\n",
    "                source_notebook=\"06_feature_opportunities\"\n",
    "            )\n",
    "            transform_count += 1\n",
    "        elif abs(skewness) > 0.5:\n",
    "            print(f\"  Recommendation: Consider sqrt transform (moderately skewed)\")\n",
    "            registry.add_gold_transformation(\n",
    "                column=col_name,\n",
    "                transform=\"sqrt\",\n",
    "                parameters={\"skewness\": float(skewness), \"reason\": \"moderately_skewed\"},\n",
    "                rationale=f\"Sqrt transform for moderately skewed distribution (skewness={skewness:.2f})\",\n",
    "                source_notebook=\"06_feature_opportunities\"\n",
    "            )\n",
    "            transform_count += 1\n",
    "        else:\n",
    "            print(f\"  Recommendation: Standard scaling sufficient\")\n",
    "            registry.add_gold_scaling(\n",
    "                column=col_name,\n",
    "                method=\"standard\",\n",
    "                rationale=f\"Standard scaling for normally distributed column (skewness={skewness:.2f})\",\n",
    "                source_notebook=\"06_feature_opportunities\"\n",
    "            )\n",
    "            transform_count += 1\n",
    "        \n",
    "        if col_info.inferred_type == ColumnType.NUMERIC_CONTINUOUS:\n",
    "            print(f\"  Binning: Consider creating bins for {col_name}_binned\")\n",
    "    \n",
    "    print(f\"\\n\u2705 Persisted {transform_count} transformation recommendations to registry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.8 Categorical Encoding Opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Encoding Recommendations:\n",
      "==================================================\n",
      "\n",
      "lifecycle_quadrant: (4 unique values)\n",
      "  Recommendation: One-hot encoding\n",
      "\n",
      "\u2705 Persisted 1 encoding recommendations to registry\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = [\n",
    "    name for name, col in findings.columns.items()\n",
    "    if col.inferred_type in [ColumnType.CATEGORICAL_NOMINAL, ColumnType.CATEGORICAL_ORDINAL]\n",
    "    and name not in TEMPORAL_METADATA_COLS\n",
    "]\n",
    "\n",
    "encoding_count = 0\n",
    "if categorical_cols:\n",
    "    print(\"Categorical Encoding Recommendations:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for col_name in categorical_cols:\n",
    "        col_info = findings.columns[col_name]\n",
    "        distinct = col_info.universal_metrics.get(\"distinct_count\", 0)\n",
    "        \n",
    "        print(f\"\\n{col_name}: ({distinct} unique values)\")\n",
    "        \n",
    "        if distinct <= 5:\n",
    "            print(f\"  Recommendation: One-hot encoding\")\n",
    "            registry.add_gold_encoding(\n",
    "                column=col_name,\n",
    "                method=\"onehot\",\n",
    "                rationale=f\"One-hot encoding for low cardinality ({distinct} unique values)\",\n",
    "                source_notebook=\"06_feature_opportunities\"\n",
    "            )\n",
    "            encoding_count += 1\n",
    "        elif distinct <= 20:\n",
    "            print(f\"  Recommendation: Target encoding or one-hot with frequency threshold\")\n",
    "            registry.add_gold_encoding(\n",
    "                column=col_name,\n",
    "                method=\"target\",\n",
    "                rationale=f\"Target encoding for medium cardinality ({distinct} unique values)\",\n",
    "                source_notebook=\"06_feature_opportunities\"\n",
    "            )\n",
    "            encoding_count += 1\n",
    "        else:\n",
    "            print(f\"  Recommendation: Target encoding or embedding (high cardinality)\")\n",
    "            registry.add_gold_encoding(\n",
    "                column=col_name,\n",
    "                method=\"target\",\n",
    "                rationale=f\"Target encoding for high cardinality ({distinct} unique values)\",\n",
    "                source_notebook=\"06_feature_opportunities\"\n",
    "            )\n",
    "            encoding_count += 1\n",
    "        \n",
    "        if col_info.inferred_type == ColumnType.CATEGORICAL_ORDINAL:\n",
    "            print(f\"  Note: Consider ordinal encoding to preserve order\")\n",
    "    \n",
    "    print(f\"\\n\u2705 Persisted {encoding_count} encoding recommendations to registry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: What We Learned\n",
    "\n",
    "In this notebook, we identified feature engineering opportunities and analyzed data capacity:\n",
    "\n",
    "### Feature Capacity Analysis\n",
    "1. **Events Per Variable (EPV)** - Calculated the data's capacity to support features\n",
    "2. **Effective Features** - Identified redundant features due to high correlation\n",
    "3. **Model Complexity Guidance** - Determined appropriate model types based on data size\n",
    "4. **Segment Capacity** - Evaluated whether segmented modeling is viable\n",
    "\n",
    "### Feature Engineering\n",
    "5. **Automated Recommendations** - Framework suggested feature opportunities\n",
    "6. **Time-Based Features** - Created tenure, recency, active period metrics\n",
    "7. **Engagement Scores** - Built composite email engagement metrics\n",
    "8. **Customer Segments** - Created value-frequency and recency-based segments\n",
    "9. **Encoding Strategies** - Identified optimal encoding for each categorical\n",
    "\n",
    "## Feature Capacity Key Concepts\n",
    "\n",
    "| Metric | What It Means | Rule of Thumb |\n",
    "|--------|---------------|---------------|\n",
    "| **EPV \u2265 20** | Stable, reliable estimates | Conservative, regulatory-grade |\n",
    "| **EPV = 10-20** | Standard practice | Use for most applications |\n",
    "| **EPV = 5-10** | Limited capacity | Requires strong regularization |\n",
    "| **EPV < 5** | High risk | Reduce features or get more data |\n",
    "\n",
    "## Key Derived Features Created\n",
    "\n",
    "| Feature | Formula | Business Meaning |\n",
    "|---------|---------|-----------------|\n",
    "| `tenure_days` | reference_date - created | Customer longevity |\n",
    "| `days_since_last_order` | reference_date - lastorder | Recency/engagement |\n",
    "| `email_engagement_score` | 0.6\u00d7openrate + 0.4\u00d7clickrate | Overall engagement |\n",
    "| `service_adoption_score` | paperless + refill + doorstep | Service utilization |\n",
    "| `customer_segment` | Value \u00d7 Frequency quadrant | Customer type |\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Continue to **07_modeling_readiness.ipynb** to:\n",
    "- Validate data is ready for modeling\n",
    "- Check for data leakage\n",
    "- Assess class imbalance\n",
    "- Review feature completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential Interaction Features:\n",
      "==================================================\n",
      "\n",
      "Numeric Interactions:\n",
      "  - event_count_180d_x_event_count_365d: Multiplication\n",
      "  - event_count_180d_div_event_count_365d: Division (if event_count_365d > 0)\n",
      "  - event_count_180d_x_event_count_all_time: Multiplication\n",
      "  - event_count_180d_div_event_count_all_time: Division (if event_count_all_time > 0)\n",
      "  - event_count_180d_x_time_to_open_hours_sum_180d: Multiplication\n",
      "  - event_count_180d_div_time_to_open_hours_sum_180d: Division (if time_to_open_hours_sum_180d > 0)\n",
      "  - event_count_365d_x_event_count_all_time: Multiplication\n",
      "  - event_count_365d_div_event_count_all_time: Division (if event_count_all_time > 0)\n",
      "  - event_count_365d_x_time_to_open_hours_sum_180d: Multiplication\n",
      "  - event_count_365d_div_time_to_open_hours_sum_180d: Division (if time_to_open_hours_sum_180d > 0)\n",
      "  - event_count_all_time_x_time_to_open_hours_sum_180d: Multiplication\n",
      "  - event_count_all_time_div_time_to_open_hours_sum_180d: Division (if time_to_open_hours_sum_180d > 0)\n",
      "\n",
      "Categorical-Numeric Interactions:\n",
      "  - event_count_180d_by_lifecycle_quadrant_mean: Group mean\n",
      "  - event_count_180d_by_lifecycle_quadrant_std: Group std\n",
      "  - event_count_365d_by_lifecycle_quadrant_mean: Group mean\n",
      "  - event_count_365d_by_lifecycle_quadrant_std: Group std\n"
     ]
    }
   ],
   "source": [
    "print(\"Potential Interaction Features:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if len(numeric_cols) >= 2:\n",
    "    print(\"\\nNumeric Interactions:\")\n",
    "    for i, col1 in enumerate(numeric_cols[:3]):\n",
    "        for col2 in numeric_cols[i+1:4]:\n",
    "            print(f\"  - {col1}_x_{col2}: Multiplication\")\n",
    "            print(f\"  - {col1}_div_{col2}: Division (if {col2} > 0)\")\n",
    "\n",
    "if categorical_cols and numeric_cols:\n",
    "    print(\"\\nCategorical-Numeric Interactions:\")\n",
    "    for cat_col in categorical_cols[:2]:\n",
    "        for num_col in numeric_cols[:2]:\n",
    "            print(f\"  - {num_col}_by_{cat_col}_mean: Group mean\")\n",
    "            print(f\"  - {num_col}_by_{cat_col}_std: Group std\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.9 Feature Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Name</th>\n",
       "      <th>Source</th>\n",
       "      <th>Type</th>\n",
       "      <th>Priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>event_count_180d_binned</td>\n",
       "      <td>event_count_180d</td>\n",
       "      <td>numeric</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>event_count_180d_log</td>\n",
       "      <td>event_count_180d</td>\n",
       "      <td>numeric</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>event_count_365d_binned</td>\n",
       "      <td>event_count_365d</td>\n",
       "      <td>numeric</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>event_count_365d_log</td>\n",
       "      <td>event_count_365d</td>\n",
       "      <td>numeric</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>event_count_all_time_binned</td>\n",
       "      <td>event_count_all_time</td>\n",
       "      <td>numeric</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>days_since_last_event_binned</td>\n",
       "      <td>days_since_last_event</td>\n",
       "      <td>numeric</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>days_since_last_event_log</td>\n",
       "      <td>days_since_last_event</td>\n",
       "      <td>numeric</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>days_since_first_event_binned</td>\n",
       "      <td>days_since_first_event</td>\n",
       "      <td>numeric</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>days_since_first_event_log</td>\n",
       "      <td>days_since_first_event</td>\n",
       "      <td>numeric</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>lifecycle_quadrant_encoded</td>\n",
       "      <td>lifecycle_quadrant</td>\n",
       "      <td>categorical</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows \u00d7 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Feature Name                  Source         Type  \\\n",
       "0          event_count_180d_binned        event_count_180d      numeric   \n",
       "1             event_count_180d_log        event_count_180d      numeric   \n",
       "2          event_count_365d_binned        event_count_365d      numeric   \n",
       "3             event_count_365d_log        event_count_365d      numeric   \n",
       "4      event_count_all_time_binned    event_count_all_time      numeric   \n",
       "..                             ...                     ...          ...   \n",
       "102   days_since_last_event_binned   days_since_last_event      numeric   \n",
       "103      days_since_last_event_log   days_since_last_event      numeric   \n",
       "104  days_since_first_event_binned  days_since_first_event      numeric   \n",
       "105     days_since_first_event_log  days_since_first_event      numeric   \n",
       "106     lifecycle_quadrant_encoded      lifecycle_quadrant  categorical   \n",
       "\n",
       "    Priority  \n",
       "0        low  \n",
       "1       high  \n",
       "2        low  \n",
       "3       high  \n",
       "4        low  \n",
       "..       ...  \n",
       "102      low  \n",
       "103     high  \n",
       "104      low  \n",
       "105     high  \n",
       "106     high  \n",
       "\n",
       "[107 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_summary = []\n",
    "for rec in feature_recs:\n",
    "    feature_summary.append({\n",
    "        \"Feature Name\": rec.feature_name,\n",
    "        \"Source\": rec.source_column,\n",
    "        \"Type\": rec.feature_type,\n",
    "        \"Priority\": rec.priority\n",
    "    })\n",
    "\n",
    "if feature_summary:\n",
    "    summary_df = pd.DataFrame(feature_summary)\n",
    "    display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Continue to **07_modeling_readiness.ipynb** to validate data is ready for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Saved 353 recommendations to ../experiments/findings/customer_emails_408768_aggregated_d24886_recommendations.yaml\n",
      "\n",
      "Recommendations by layer:\n",
      "  BRONZE: 50\n",
      "  SILVER: 8\n",
      "  GOLD: 295\n"
     ]
    }
   ],
   "source": [
    "# Save recommendations\n",
    "with open(RECOMMENDATIONS_PATH, \"w\") as f:\n",
    "    yaml.dump(registry.to_dict(), f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f\"\u2705 Saved {len(registry.all_recommendations)} recommendations to {RECOMMENDATIONS_PATH}\")\n",
    "print(f\"\\nRecommendations by layer:\")\n",
    "for layer in [\"bronze\", \"silver\", \"gold\"]:\n",
    "    recs = registry.get_by_layer(layer)\n",
    "    print(f\"  {layer.upper()}: {len(recs)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}